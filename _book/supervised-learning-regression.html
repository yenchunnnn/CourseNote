<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 20 Supervised Learning: Regression | Data Scientist with R</title>
  <meta name="description" content="This is a notebook about the data science courses took from the datacamp." />
  <meta name="generator" content="bookdown 0.37 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 20 Supervised Learning: Regression | Data Scientist with R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a notebook about the data science courses took from the datacamp." />
  <meta name="github-repo" content="yenchunnnn/CourseNote" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 20 Supervised Learning: Regression | Data Scientist with R" />
  
  <meta name="twitter:description" content="This is a notebook about the data science courses took from the datacamp." />
  

<meta name="author" content="Yen Chun Chen" />


<meta name="date" content="2024-01-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="supervised-learning-classification.html"/>
<link rel="next" href="unsupervised-learning.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Scientist with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About</a></li>
<li class="chapter" data-level="1" data-path="introduction-to-r.html"><a href="introduction-to-r.html"><i class="fa fa-check"></i><b>1</b> Introduction to R</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction-to-r.html"><a href="introduction-to-r.html#basic-arithmetic"><i class="fa fa-check"></i><b>1.1</b> Basic arithmetic</a></li>
<li class="chapter" data-level="1.2" data-path="introduction-to-r.html"><a href="introduction-to-r.html#basic-data-types"><i class="fa fa-check"></i><b>1.2</b> Basic data types</a></li>
<li class="chapter" data-level="1.3" data-path="introduction-to-r.html"><a href="introduction-to-r.html#vector"><i class="fa fa-check"></i><b>1.3</b> Vector</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="introduction-to-r.html"><a href="introduction-to-r.html#useful-function"><i class="fa fa-check"></i><b>1.3.1</b> Useful function</a></li>
<li class="chapter" data-level="1.3.2" data-path="introduction-to-r.html"><a href="introduction-to-r.html#selection---by-brackets-or-names"><i class="fa fa-check"></i><b>1.3.2</b> Selection - by brackets or names</a></li>
<li class="chapter" data-level="1.3.3" data-path="introduction-to-r.html"><a href="introduction-to-r.html#selection---by-comparison---operators"><i class="fa fa-check"></i><b>1.3.3</b> Selection - by comparison - operators</a></li>
<li class="chapter" data-level="1.3.4" data-path="introduction-to-r.html"><a href="introduction-to-r.html#selection---by-comparison---values"><i class="fa fa-check"></i><b>1.3.4</b> Selection - by comparison - values</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introduction-to-r.html"><a href="introduction-to-r.html#matrix"><i class="fa fa-check"></i><b>1.4</b> Matrix</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="introduction-to-r.html"><a href="introduction-to-r.html#construct-function"><i class="fa fa-check"></i><b>1.4.1</b> Construct function</a></li>
<li class="chapter" data-level="1.4.2" data-path="introduction-to-r.html"><a href="introduction-to-r.html#construct-by-vector"><i class="fa fa-check"></i><b>1.4.2</b> Construct by vector</a></li>
<li class="chapter" data-level="1.4.3" data-path="introduction-to-r.html"><a href="introduction-to-r.html#naming-a-matrix"><i class="fa fa-check"></i><b>1.4.3</b> Naming a matrix</a></li>
<li class="chapter" data-level="1.4.4" data-path="introduction-to-r.html"><a href="introduction-to-r.html#manipulating---sum-of-each-row-column"><i class="fa fa-check"></i><b>1.4.4</b> Manipulating - sum of each row &amp; column</a></li>
<li class="chapter" data-level="1.4.5" data-path="introduction-to-r.html"><a href="introduction-to-r.html#manipulating---add-columns"><i class="fa fa-check"></i><b>1.4.5</b> Manipulating - add columns</a></li>
<li class="chapter" data-level="1.4.6" data-path="introduction-to-r.html"><a href="introduction-to-r.html#manipulating---add-rows"><i class="fa fa-check"></i><b>1.4.6</b> Manipulating - add rows</a></li>
<li class="chapter" data-level="1.4.7" data-path="introduction-to-r.html"><a href="introduction-to-r.html#selection-of-matrix-elements"><i class="fa fa-check"></i><b>1.4.7</b> Selection of matrix elements</a></li>
<li class="chapter" data-level="1.4.8" data-path="introduction-to-r.html"><a href="introduction-to-r.html#arithmetic---1"><i class="fa fa-check"></i><b>1.4.8</b> Arithmetic - 1</a></li>
<li class="chapter" data-level="1.4.9" data-path="introduction-to-r.html"><a href="introduction-to-r.html#arithmetic---2"><i class="fa fa-check"></i><b>1.4.9</b> Arithmetic - 2</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="introduction-to-r.html"><a href="introduction-to-r.html#factor"><i class="fa fa-check"></i><b>1.5</b> Factor</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="introduction-to-r.html"><a href="introduction-to-r.html#useful-function-1"><i class="fa fa-check"></i><b>1.5.1</b> Useful function</a></li>
<li class="chapter" data-level="1.5.2" data-path="introduction-to-r.html"><a href="introduction-to-r.html#nominal-ordinal-categorical-variable"><i class="fa fa-check"></i><b>1.5.2</b> Nominal &amp; Ordinal categorical variable</a></li>
<li class="chapter" data-level="1.5.3" data-path="introduction-to-r.html"><a href="introduction-to-r.html#factor-levels"><i class="fa fa-check"></i><b>1.5.3</b> Factor levels</a></li>
<li class="chapter" data-level="1.5.4" data-path="introduction-to-r.html"><a href="introduction-to-r.html#summarizing-a-factor"><i class="fa fa-check"></i><b>1.5.4</b> Summarizing a factor</a></li>
<li class="chapter" data-level="1.5.5" data-path="introduction-to-r.html"><a href="introduction-to-r.html#ordered-factors"><i class="fa fa-check"></i><b>1.5.5</b> Ordered factors</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="introduction-to-r.html"><a href="introduction-to-r.html#data-frame"><i class="fa fa-check"></i><b>1.6</b> Data Frame</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="introduction-to-r.html"><a href="introduction-to-r.html#quick-look-at-dataset"><i class="fa fa-check"></i><b>1.6.1</b> Quick look at dataset</a></li>
<li class="chapter" data-level="1.6.2" data-path="introduction-to-r.html"><a href="introduction-to-r.html#creating-a-data-frame"><i class="fa fa-check"></i><b>1.6.2</b> Creating a data frame</a></li>
<li class="chapter" data-level="1.6.3" data-path="introduction-to-r.html"><a href="introduction-to-r.html#selection---brackets"><i class="fa fa-check"></i><b>1.6.3</b> Selection - brackets</a></li>
<li class="chapter" data-level="1.6.4" data-path="introduction-to-r.html"><a href="introduction-to-r.html#selection---names"><i class="fa fa-check"></i><b>1.6.4</b> Selection - names</a></li>
<li class="chapter" data-level="1.6.5" data-path="introduction-to-r.html"><a href="introduction-to-r.html#selection--"><i class="fa fa-check"></i><b>1.6.5</b> Selection - $</a></li>
<li class="chapter" data-level="1.6.6" data-path="introduction-to-r.html"><a href="introduction-to-r.html#selection---subset"><i class="fa fa-check"></i><b>1.6.6</b> Selection - subset</a></li>
<li class="chapter" data-level="1.6.7" data-path="introduction-to-r.html"><a href="introduction-to-r.html#sorting"><i class="fa fa-check"></i><b>1.6.7</b> Sorting</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="introduction-to-r.html"><a href="introduction-to-r.html#list"><i class="fa fa-check"></i><b>1.7</b> List</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="introduction-to-r.html"><a href="introduction-to-r.html#creating-a-list"><i class="fa fa-check"></i><b>1.7.1</b> Creating a list</a></li>
<li class="chapter" data-level="1.7.2" data-path="introduction-to-r.html"><a href="introduction-to-r.html#creating-a-named-list"><i class="fa fa-check"></i><b>1.7.2</b> Creating a named list</a></li>
<li class="chapter" data-level="1.7.3" data-path="introduction-to-r.html"><a href="introduction-to-r.html#selection"><i class="fa fa-check"></i><b>1.7.3</b> Selection</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="introduction-to-r.html"><a href="introduction-to-r.html#bring-it-all-together"><i class="fa fa-check"></i><b>1.8</b> Bring it all together</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intermediate-r.html"><a href="intermediate-r.html"><i class="fa fa-check"></i><b>2</b> Intermediate R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="intermediate-r.html"><a href="intermediate-r.html#conditionals-and-control-flow"><i class="fa fa-check"></i><b>2.1</b> Conditionals and Control Flow</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="intermediate-r.html"><a href="intermediate-r.html#relational-operators"><i class="fa fa-check"></i><b>2.1.1</b> Relational operators</a></li>
<li class="chapter" data-level="2.1.2" data-path="intermediate-r.html"><a href="intermediate-r.html#conditional-statements"><i class="fa fa-check"></i><b>2.1.2</b> Conditional statements</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="intermediate-r.html"><a href="intermediate-r.html#loops"><i class="fa fa-check"></i><b>2.2</b> Loops</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="intermediate-r.html"><a href="intermediate-r.html#while-loop"><i class="fa fa-check"></i><b>2.2.1</b> While loop</a></li>
<li class="chapter" data-level="2.2.2" data-path="intermediate-r.html"><a href="intermediate-r.html#for-loop"><i class="fa fa-check"></i><b>2.2.2</b> For loop</a></li>
<li class="chapter" data-level="2.2.3" data-path="intermediate-r.html"><a href="intermediate-r.html#bring-it-all-together-1"><i class="fa fa-check"></i><b>2.2.3</b> Bring it all together</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="intermediate-r.html"><a href="intermediate-r.html#function"><i class="fa fa-check"></i><b>2.3</b> Function</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="intermediate-r.html"><a href="intermediate-r.html#introduction-to-function"><i class="fa fa-check"></i><b>2.3.1</b> Introduction to function</a></li>
<li class="chapter" data-level="2.3.2" data-path="intermediate-r.html"><a href="intermediate-r.html#writing-functions"><i class="fa fa-check"></i><b>2.3.2</b> Writing functions</a></li>
<li class="chapter" data-level="2.3.3" data-path="intermediate-r.html"><a href="intermediate-r.html#packages"><i class="fa fa-check"></i><b>2.3.3</b> Packages</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="intermediate-r.html"><a href="intermediate-r.html#the-apply-family"><i class="fa fa-check"></i><b>2.4</b> The apply family</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="intermediate-r.html"><a href="intermediate-r.html#lapply"><i class="fa fa-check"></i><b>2.4.1</b> lapply</a></li>
<li class="chapter" data-level="2.4.2" data-path="intermediate-r.html"><a href="intermediate-r.html#sapply"><i class="fa fa-check"></i><b>2.4.2</b> sapply</a></li>
<li class="chapter" data-level="2.4.3" data-path="intermediate-r.html"><a href="intermediate-r.html#vapply"><i class="fa fa-check"></i><b>2.4.3</b> vapply</a></li>
<li class="chapter" data-level="2.4.4" data-path="intermediate-r.html"><a href="intermediate-r.html#lapply-vs-sapply-vs-vapply"><i class="fa fa-check"></i><b>2.4.4</b> lapply vs sapply vs vapply</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="intermediate-r.html"><a href="intermediate-r.html#utilities"><i class="fa fa-check"></i><b>2.5</b> Utilities</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="intermediate-r.html"><a href="intermediate-r.html#mathematical-utilities"><i class="fa fa-check"></i><b>2.5.1</b> Mathematical utilities</a></li>
<li class="chapter" data-level="2.5.2" data-path="intermediate-r.html"><a href="intermediate-r.html#data-structures-utilities"><i class="fa fa-check"></i><b>2.5.2</b> Data structures utilities</a></li>
<li class="chapter" data-level="2.5.3" data-path="intermediate-r.html"><a href="intermediate-r.html#regular-expressions"><i class="fa fa-check"></i><b>2.5.3</b> Regular Expressions</a></li>
<li class="chapter" data-level="2.5.4" data-path="intermediate-r.html"><a href="intermediate-r.html#dates-times"><i class="fa fa-check"></i><b>2.5.4</b> Dates &amp; Times</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introduction-to-the-tidyverse.html"><a href="introduction-to-the-tidyverse.html"><i class="fa fa-check"></i><b>3</b> Introduction to the Tidyverse</a>
<ul>
<li class="chapter" data-level="3.1" data-path="introduction-to-the-tidyverse.html"><a href="introduction-to-the-tidyverse.html#data-wrangling"><i class="fa fa-check"></i><b>3.1</b> Data wrangling</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="introduction-to-the-tidyverse.html"><a href="introduction-to-the-tidyverse.html#load-dataset"><i class="fa fa-check"></i><b>3.1.1</b> Load dataset</a></li>
<li class="chapter" data-level="3.1.2" data-path="introduction-to-the-tidyverse.html"><a href="introduction-to-the-tidyverse.html#filtering"><i class="fa fa-check"></i><b>3.1.2</b> Filtering</a></li>
<li class="chapter" data-level="3.1.3" data-path="introduction-to-the-tidyverse.html"><a href="introduction-to-the-tidyverse.html#arrange"><i class="fa fa-check"></i><b>3.1.3</b> Arrange</a></li>
<li class="chapter" data-level="3.1.4" data-path="introduction-to-the-tidyverse.html"><a href="introduction-to-the-tidyverse.html#mutate"><i class="fa fa-check"></i><b>3.1.4</b> Mutate</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="introduction-to-the-tidyverse.html"><a href="introduction-to-the-tidyverse.html#data-visualization"><i class="fa fa-check"></i><b>3.2</b> Data visualization</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="introduction-to-the-tidyverse.html"><a href="introduction-to-the-tidyverse.html#subset-df-variable"><i class="fa fa-check"></i><b>3.2.1</b> Subset df variable</a></li>
<li class="chapter" data-level="3.2.2" data-path="introduction-to-the-tidyverse.html"><a href="introduction-to-the-tidyverse.html#ggplot-aesthetics"><i class="fa fa-check"></i><b>3.2.2</b> ggplot aesthetics</a></li>
<li class="chapter" data-level="3.2.3" data-path="introduction-to-the-tidyverse.html"><a href="introduction-to-the-tidyverse.html#faceting"><i class="fa fa-check"></i><b>3.2.3</b> Faceting</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="introduction-to-the-tidyverse.html"><a href="introduction-to-the-tidyverse.html#grouping-summarizing"><i class="fa fa-check"></i><b>3.3</b> Grouping &amp; summarizing</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="introduction-to-the-tidyverse.html"><a href="introduction-to-the-tidyverse.html#summarize"><i class="fa fa-check"></i><b>3.3.1</b> Summarize</a></li>
<li class="chapter" data-level="3.3.2" data-path="introduction-to-the-tidyverse.html"><a href="introduction-to-the-tidyverse.html#group-by"><i class="fa fa-check"></i><b>3.3.2</b> Group by</a></li>
<li class="chapter" data-level="3.3.3" data-path="introduction-to-the-tidyverse.html"><a href="introduction-to-the-tidyverse.html#visualizing-summarized-data"><i class="fa fa-check"></i><b>3.3.3</b> Visualizing summarized data</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="introduction-to-the-tidyverse.html"><a href="introduction-to-the-tidyverse.html#types-of-visualizations"><i class="fa fa-check"></i><b>3.4</b> Types of visualizations</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="introduction-to-the-tidyverse.html"><a href="introduction-to-the-tidyverse.html#line-plots"><i class="fa fa-check"></i><b>3.4.1</b> Line plots</a></li>
<li class="chapter" data-level="3.4.2" data-path="introduction-to-the-tidyverse.html"><a href="introduction-to-the-tidyverse.html#bar-plots"><i class="fa fa-check"></i><b>3.4.2</b> Bar plots</a></li>
<li class="chapter" data-level="3.4.3" data-path="introduction-to-the-tidyverse.html"><a href="introduction-to-the-tidyverse.html#histograms"><i class="fa fa-check"></i><b>3.4.3</b> Histograms</a></li>
<li class="chapter" data-level="3.4.4" data-path="introduction-to-the-tidyverse.html"><a href="introduction-to-the-tidyverse.html#box-plots"><i class="fa fa-check"></i><b>3.4.4</b> Box plots</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-manipulation.html"><a href="data-manipulation.html"><i class="fa fa-check"></i><b>4</b> Data Manipulation</a>
<ul>
<li class="chapter" data-level="4.1" data-path="data-manipulation.html"><a href="data-manipulation.html#transforming-data"><i class="fa fa-check"></i><b>4.1</b> Transforming Data</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="data-manipulation.html"><a href="data-manipulation.html#exploring-data"><i class="fa fa-check"></i><b>4.1.1</b> Exploring data</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="data-manipulation.html"><a href="data-manipulation.html#aggregating-data"><i class="fa fa-check"></i><b>4.2</b> Aggregating Data</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="data-manipulation.html"><a href="data-manipulation.html#count"><i class="fa fa-check"></i><b>4.2.1</b> Count</a></li>
<li class="chapter" data-level="4.2.2" data-path="data-manipulation.html"><a href="data-manipulation.html#group_by-summarize-ungroup"><i class="fa fa-check"></i><b>4.2.2</b> group_by, summarize, ungroup</a></li>
<li class="chapter" data-level="4.2.3" data-path="data-manipulation.html"><a href="data-manipulation.html#slice_min-slice_max"><i class="fa fa-check"></i><b>4.2.3</b> slice_min, slice_max</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="data-manipulation.html"><a href="data-manipulation.html#selecting-and-transforming-data"><i class="fa fa-check"></i><b>4.3</b> Selecting and Transforming Data</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="data-manipulation.html"><a href="data-manipulation.html#select"><i class="fa fa-check"></i><b>4.3.1</b> Select</a></li>
<li class="chapter" data-level="4.3.2" data-path="data-manipulation.html"><a href="data-manipulation.html#rename"><i class="fa fa-check"></i><b>4.3.2</b> Rename</a></li>
<li class="chapter" data-level="4.3.3" data-path="data-manipulation.html"><a href="data-manipulation.html#transmute"><i class="fa fa-check"></i><b>4.3.3</b> Transmute</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="data-manipulation.html"><a href="data-manipulation.html#case-study-the-babynames-dataset"><i class="fa fa-check"></i><b>4.4</b> Case Study: The babynames Dataset</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="data-manipulation.html"><a href="data-manipulation.html#load-dataset-1"><i class="fa fa-check"></i><b>4.4.1</b> Load dataset</a></li>
<li class="chapter" data-level="4.4.2" data-path="data-manipulation.html"><a href="data-manipulation.html#exploring-data-1"><i class="fa fa-check"></i><b>4.4.2</b> Exploring data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="joining-data.html"><a href="joining-data.html"><i class="fa fa-check"></i><b>5</b> Joining Data</a>
<ul>
<li class="chapter" data-level="5.1" data-path="joining-data.html"><a href="joining-data.html#inner-join"><i class="fa fa-check"></i><b>5.1</b> Inner join</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="joining-data.html"><a href="joining-data.html#join-by-keys"><i class="fa fa-check"></i><b>5.1.1</b> Join by keys</a></li>
<li class="chapter" data-level="5.1.2" data-path="joining-data.html"><a href="joining-data.html#join-with-a-one-to-many-relationship"><i class="fa fa-check"></i><b>5.1.2</b> Join with a one-to-many relationship</a></li>
<li class="chapter" data-level="5.1.3" data-path="joining-data.html"><a href="joining-data.html#join-in-either-direction"><i class="fa fa-check"></i><b>5.1.3</b> Join in either direction</a></li>
<li class="chapter" data-level="5.1.4" data-path="joining-data.html"><a href="joining-data.html#join-three-or-more-tables"><i class="fa fa-check"></i><b>5.1.4</b> Join three or more tables</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="joining-data.html"><a href="joining-data.html#left-right-joins"><i class="fa fa-check"></i><b>5.2</b> Left &amp; Right Joins</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="joining-data.html"><a href="joining-data.html#left-join"><i class="fa fa-check"></i><b>5.2.1</b> Left join</a></li>
<li class="chapter" data-level="5.2.2" data-path="joining-data.html"><a href="joining-data.html#right-join"><i class="fa fa-check"></i><b>5.2.2</b> Right join</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="joining-data.html"><a href="joining-data.html#full-semi-anti-joins"><i class="fa fa-check"></i><b>5.3</b> Full, Semi &amp; Anti Joins</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="joining-data.html"><a href="joining-data.html#full-join"><i class="fa fa-check"></i><b>5.3.1</b> Full join</a></li>
<li class="chapter" data-level="5.3.2" data-path="joining-data.html"><a href="joining-data.html#semi-anti-joins"><i class="fa fa-check"></i><b>5.3.2</b> Semi &amp; Anti joins</a></li>
<li class="chapter" data-level="5.3.3" data-path="joining-data.html"><a href="joining-data.html#visualizing-set-differences"><i class="fa fa-check"></i><b>5.3.3</b> Visualizing set differences</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="joining-data.html"><a href="joining-data.html#case-study-joins-on-stack-overflow-data"><i class="fa fa-check"></i><b>5.4</b> Case study: Joins on Stack Overflow Data</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="joining-data.html"><a href="joining-data.html#load-dataset-2"><i class="fa fa-check"></i><b>5.4.1</b> Load dataset</a></li>
<li class="chapter" data-level="5.4.2" data-path="joining-data.html"><a href="joining-data.html#stack-overflow-questions"><i class="fa fa-check"></i><b>5.4.2</b> Stack Overflow questions</a></li>
<li class="chapter" data-level="5.4.3" data-path="joining-data.html"><a href="joining-data.html#joining-questions-and-answers"><i class="fa fa-check"></i><b>5.4.3</b> Joining questions and answers</a></li>
<li class="chapter" data-level="5.4.4" data-path="joining-data.html"><a href="joining-data.html#the-bind_rows-verb"><i class="fa fa-check"></i><b>5.4.4</b> The bind_rows verb</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html"><i class="fa fa-check"></i><b>6</b> Introduction to Statistics</a>
<ul>
<li class="chapter" data-level="6.1" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#summary-statistics"><i class="fa fa-check"></i><b>6.1</b> Summary Statistics</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#measures-of-center"><i class="fa fa-check"></i><b>6.1.1</b> Measures of center</a></li>
<li class="chapter" data-level="6.1.2" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#measures-of-spread"><i class="fa fa-check"></i><b>6.1.2</b> Measures of spread</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#random-numbers-and-probability"><i class="fa fa-check"></i><b>6.2</b> Random Numbers and Probability</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#chances"><i class="fa fa-check"></i><b>6.2.1</b> Chances</a></li>
<li class="chapter" data-level="6.2.2" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#discrete-distributions"><i class="fa fa-check"></i><b>6.2.2</b> Discrete distributions</a></li>
<li class="chapter" data-level="6.2.3" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#continuous-distributions"><i class="fa fa-check"></i><b>6.2.3</b> Continuous distributions</a></li>
<li class="chapter" data-level="6.2.4" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#binomial-distribution"><i class="fa fa-check"></i><b>6.2.4</b> Binomial distribution</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#more-distributions-central-limit-theorem"><i class="fa fa-check"></i><b>6.3</b> More Distributions &amp; Central Limit Theorem</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#normal-distribution"><i class="fa fa-check"></i><b>6.3.1</b> Normal distribution</a></li>
<li class="chapter" data-level="6.3.2" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#central-limit-theorem"><i class="fa fa-check"></i><b>6.3.2</b> Central limit theorem</a></li>
<li class="chapter" data-level="6.3.3" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#poisson-distribution"><i class="fa fa-check"></i><b>6.3.3</b> Poisson distribution</a></li>
<li class="chapter" data-level="6.3.4" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#exponential-distribution"><i class="fa fa-check"></i><b>6.3.4</b> Exponential distribution</a></li>
<li class="chapter" data-level="6.3.5" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#students-t-distribution"><i class="fa fa-check"></i><b>6.3.5</b> (Student’s) t-distribution</a></li>
<li class="chapter" data-level="6.3.6" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#log-normal-distribution"><i class="fa fa-check"></i><b>6.3.6</b> Log-normal distribution</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#correlation-and-experimental-design"><i class="fa fa-check"></i><b>6.4</b> Correlation and Experimental Design</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#correlation"><i class="fa fa-check"></i><b>6.4.1</b> Correlation</a></li>
<li class="chapter" data-level="6.4.2" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#correlation-caveats"><i class="fa fa-check"></i><b>6.4.2</b> Correlation caveats</a></li>
<li class="chapter" data-level="6.4.3" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#design-of-experiments"><i class="fa fa-check"></i><b>6.4.3</b> Design of experiments</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="introduction-to-data-visualization-with-ggplot2.html"><a href="introduction-to-data-visualization-with-ggplot2.html"><i class="fa fa-check"></i><b>7</b> Introduction to Data Visualization with ggplot2</a>
<ul>
<li class="chapter" data-level="7.1" data-path="introduction-to-data-visualization-with-ggplot2.html"><a href="introduction-to-data-visualization-with-ggplot2.html#introduction"><i class="fa fa-check"></i><b>7.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="introduction-to-data-visualization-with-ggplot2.html"><a href="introduction-to-data-visualization-with-ggplot2.html#data-columns-types-affect-plot-types"><i class="fa fa-check"></i><b>7.1.1</b> Data columns types affect plot types</a></li>
<li class="chapter" data-level="7.1.2" data-path="introduction-to-data-visualization-with-ggplot2.html"><a href="introduction-to-data-visualization-with-ggplot2.html#the-grammar-of-graphics"><i class="fa fa-check"></i><b>7.1.2</b> The grammar of graphics</a></li>
<li class="chapter" data-level="7.1.3" data-path="introduction-to-data-visualization-with-ggplot2.html"><a href="introduction-to-data-visualization-with-ggplot2.html#ggplot2-layers"><i class="fa fa-check"></i><b>7.1.3</b> ggplot2 layers</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="introduction-to-data-visualization-with-ggplot2.html"><a href="introduction-to-data-visualization-with-ggplot2.html#aesthetics"><i class="fa fa-check"></i><b>7.2</b> Aesthetics</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="introduction-to-data-visualization-with-ggplot2.html"><a href="introduction-to-data-visualization-with-ggplot2.html#visible-aesthetics"><i class="fa fa-check"></i><b>7.2.1</b> Visible aesthetics</a></li>
<li class="chapter" data-level="7.2.2" data-path="introduction-to-data-visualization-with-ggplot2.html"><a href="introduction-to-data-visualization-with-ggplot2.html#using-attributes"><i class="fa fa-check"></i><b>7.2.2</b> Using attributes</a></li>
<li class="chapter" data-level="7.2.3" data-path="introduction-to-data-visualization-with-ggplot2.html"><a href="introduction-to-data-visualization-with-ggplot2.html#modifying-aesthetics"><i class="fa fa-check"></i><b>7.2.3</b> Modifying aesthetics</a></li>
<li class="chapter" data-level="7.2.4" data-path="introduction-to-data-visualization-with-ggplot2.html"><a href="introduction-to-data-visualization-with-ggplot2.html#aesthetics-best-practices"><i class="fa fa-check"></i><b>7.2.4</b> Aesthetics best practices</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="introduction-to-data-visualization-with-ggplot2.html"><a href="introduction-to-data-visualization-with-ggplot2.html#geometries"><i class="fa fa-check"></i><b>7.3</b> Geometries</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="introduction-to-data-visualization-with-ggplot2.html"><a href="introduction-to-data-visualization-with-ggplot2.html#scatter-plots"><i class="fa fa-check"></i><b>7.3.1</b> Scatter plots</a></li>
<li class="chapter" data-level="7.3.2" data-path="introduction-to-data-visualization-with-ggplot2.html"><a href="introduction-to-data-visualization-with-ggplot2.html#histograms-1"><i class="fa fa-check"></i><b>7.3.2</b> Histograms</a></li>
<li class="chapter" data-level="7.3.3" data-path="introduction-to-data-visualization-with-ggplot2.html"><a href="introduction-to-data-visualization-with-ggplot2.html#bar-plots-1"><i class="fa fa-check"></i><b>7.3.3</b> Bar plots</a></li>
<li class="chapter" data-level="7.3.4" data-path="introduction-to-data-visualization-with-ggplot2.html"><a href="introduction-to-data-visualization-with-ggplot2.html#line-plots-1"><i class="fa fa-check"></i><b>7.3.4</b> Line plots</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="introduction-to-data-visualization-with-ggplot2.html"><a href="introduction-to-data-visualization-with-ggplot2.html#themes"><i class="fa fa-check"></i><b>7.4</b> Themes</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="introduction-to-data-visualization-with-ggplot2.html"><a href="introduction-to-data-visualization-with-ggplot2.html#themes-from-scratch"><i class="fa fa-check"></i><b>7.4.1</b> Themes from scratch</a></li>
<li class="chapter" data-level="7.4.2" data-path="introduction-to-data-visualization-with-ggplot2.html"><a href="introduction-to-data-visualization-with-ggplot2.html#theme-flexibility"><i class="fa fa-check"></i><b>7.4.2</b> Theme flexibility</a></li>
<li class="chapter" data-level="7.4.3" data-path="introduction-to-data-visualization-with-ggplot2.html"><a href="introduction-to-data-visualization-with-ggplot2.html#effective-explanatory-plots"><i class="fa fa-check"></i><b>7.4.3</b> Effective explanatory plots</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="intermediate-data-visualization-with-ggplot2.html"><a href="intermediate-data-visualization-with-ggplot2.html"><i class="fa fa-check"></i><b>8</b> Intermediate Data Visualization with ggplot2</a>
<ul>
<li class="chapter" data-level="8.1" data-path="intermediate-data-visualization-with-ggplot2.html"><a href="intermediate-data-visualization-with-ggplot2.html#statistics"><i class="fa fa-check"></i><b>8.1</b> Statistics</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="intermediate-data-visualization-with-ggplot2.html"><a href="intermediate-data-visualization-with-ggplot2.html#stats-with-geoms"><i class="fa fa-check"></i><b>8.1.1</b> Stats with geoms</a></li>
<li class="chapter" data-level="8.1.2" data-path="intermediate-data-visualization-with-ggplot2.html"><a href="intermediate-data-visualization-with-ggplot2.html#stats-sum-quantile"><i class="fa fa-check"></i><b>8.1.2</b> Stats: sum &amp; quantile</a></li>
<li class="chapter" data-level="8.1.3" data-path="intermediate-data-visualization-with-ggplot2.html"><a href="intermediate-data-visualization-with-ggplot2.html#stats-outside-geoms"><i class="fa fa-check"></i><b>8.1.3</b> Stats outside geoms</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="intermediate-data-visualization-with-ggplot2.html"><a href="intermediate-data-visualization-with-ggplot2.html#coordinates"><i class="fa fa-check"></i><b>8.2</b> Coordinates</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="intermediate-data-visualization-with-ggplot2.html"><a href="intermediate-data-visualization-with-ggplot2.html#coordinates-layer"><i class="fa fa-check"></i><b>8.2.1</b> Coordinates layer</a></li>
<li class="chapter" data-level="8.2.2" data-path="intermediate-data-visualization-with-ggplot2.html"><a href="intermediate-data-visualization-with-ggplot2.html#coordinates-vs.-scales"><i class="fa fa-check"></i><b>8.2.2</b> Coordinates vs. scales</a></li>
<li class="chapter" data-level="8.2.3" data-path="intermediate-data-visualization-with-ggplot2.html"><a href="intermediate-data-visualization-with-ggplot2.html#double-flipped-axes"><i class="fa fa-check"></i><b>8.2.3</b> Double &amp; flipped axes</a></li>
<li class="chapter" data-level="8.2.4" data-path="intermediate-data-visualization-with-ggplot2.html"><a href="intermediate-data-visualization-with-ggplot2.html#polar-coordinates"><i class="fa fa-check"></i><b>8.2.4</b> Polar coordinates</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="intermediate-data-visualization-with-ggplot2.html"><a href="intermediate-data-visualization-with-ggplot2.html#facets"><i class="fa fa-check"></i><b>8.3</b> Facets</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="intermediate-data-visualization-with-ggplot2.html"><a href="intermediate-data-visualization-with-ggplot2.html#the-facets-layer"><i class="fa fa-check"></i><b>8.3.1</b> The facets layer</a></li>
<li class="chapter" data-level="8.3.2" data-path="intermediate-data-visualization-with-ggplot2.html"><a href="intermediate-data-visualization-with-ggplot2.html#facet-labels-order"><i class="fa fa-check"></i><b>8.3.2</b> Facet labels &amp; order</a></li>
<li class="chapter" data-level="8.3.3" data-path="intermediate-data-visualization-with-ggplot2.html"><a href="intermediate-data-visualization-with-ggplot2.html#facet-plotting-spaces"><i class="fa fa-check"></i><b>8.3.3</b> Facet plotting spaces</a></li>
<li class="chapter" data-level="8.3.4" data-path="intermediate-data-visualization-with-ggplot2.html"><a href="intermediate-data-visualization-with-ggplot2.html#facet-wrap-margins"><i class="fa fa-check"></i><b>8.3.4</b> Facet wrap &amp; margins</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="intermediate-data-visualization-with-ggplot2.html"><a href="intermediate-data-visualization-with-ggplot2.html#best-practices"><i class="fa fa-check"></i><b>8.4</b> Best Practices</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="intermediate-data-visualization-with-ggplot2.html"><a href="intermediate-data-visualization-with-ggplot2.html#bar-plots-2"><i class="fa fa-check"></i><b>8.4.1</b> Bar plots</a></li>
<li class="chapter" data-level="8.4.2" data-path="intermediate-data-visualization-with-ggplot2.html"><a href="intermediate-data-visualization-with-ggplot2.html#heatmaps-use-case-scenario"><i class="fa fa-check"></i><b>8.4.2</b> Heatmaps use case scenario</a></li>
<li class="chapter" data-level="8.4.3" data-path="intermediate-data-visualization-with-ggplot2.html"><a href="intermediate-data-visualization-with-ggplot2.html#when-good-data-makes-bad-plots"><i class="fa fa-check"></i><b>8.4.3</b> When good data makes bad plots</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="introduction-to-importing-data-in-r.html"><a href="introduction-to-importing-data-in-r.html"><i class="fa fa-check"></i><b>9</b> Introduction to Importing Data in R</a>
<ul>
<li class="chapter" data-level="9.1" data-path="introduction-to-importing-data-in-r.html"><a href="introduction-to-importing-data-in-r.html#flat-files-with-utils"><i class="fa fa-check"></i><b>9.1</b> Flat files with utils</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="introduction-to-importing-data-in-r.html"><a href="introduction-to-importing-data-in-r.html#read.csv"><i class="fa fa-check"></i><b>9.1.1</b> read.csv</a></li>
<li class="chapter" data-level="9.1.2" data-path="introduction-to-importing-data-in-r.html"><a href="introduction-to-importing-data-in-r.html#read.delim"><i class="fa fa-check"></i><b>9.1.2</b> read.delim</a></li>
<li class="chapter" data-level="9.1.3" data-path="introduction-to-importing-data-in-r.html"><a href="introduction-to-importing-data-in-r.html#read.table"><i class="fa fa-check"></i><b>9.1.3</b> read.table</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="introduction-to-importing-data-in-r.html"><a href="introduction-to-importing-data-in-r.html#readr-data.table"><i class="fa fa-check"></i><b>9.2</b> readr &amp; data.table</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="introduction-to-importing-data-in-r.html"><a href="introduction-to-importing-data-in-r.html#readr"><i class="fa fa-check"></i><b>9.2.1</b> readr</a></li>
<li class="chapter" data-level="9.2.2" data-path="introduction-to-importing-data-in-r.html"><a href="introduction-to-importing-data-in-r.html#data.table"><i class="fa fa-check"></i><b>9.2.2</b> data.table</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="introduction-to-importing-data-in-r.html"><a href="introduction-to-importing-data-in-r.html#excel-data"><i class="fa fa-check"></i><b>9.3</b> Excel data</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="introduction-to-importing-data-in-r.html"><a href="introduction-to-importing-data-in-r.html#list-the-sheets-of-xls-file"><i class="fa fa-check"></i><b>9.3.1</b> List the sheets of xls file</a></li>
<li class="chapter" data-level="9.3.2" data-path="introduction-to-importing-data-in-r.html"><a href="introduction-to-importing-data-in-r.html#import-an-excel-sheet"><i class="fa fa-check"></i><b>9.3.2</b> Import an Excel sheet</a></li>
<li class="chapter" data-level="9.3.3" data-path="introduction-to-importing-data-in-r.html"><a href="introduction-to-importing-data-in-r.html#col_names-skip-argument"><i class="fa fa-check"></i><b>9.3.3</b> col_names &amp; skip argument</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="introduction-to-importing-data-in-r.html"><a href="introduction-to-importing-data-in-r.html#reproducible-excel-work---xlconnect"><i class="fa fa-check"></i><b>9.4</b> Reproducible Excel work - XLConnect</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="introduction-to-importing-data-in-r.html"><a href="introduction-to-importing-data-in-r.html#adapting-sheets"><i class="fa fa-check"></i><b>9.4.1</b> Adapting sheets</a></li>
<li class="chapter" data-level="9.4.2" data-path="introduction-to-importing-data-in-r.html"><a href="introduction-to-importing-data-in-r.html#adapting-sheets-1"><i class="fa fa-check"></i><b>9.4.2</b> Adapting sheets</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="cleaning-data-in-r.html"><a href="cleaning-data-in-r.html"><i class="fa fa-check"></i><b>10</b> Cleaning Data in R</a>
<ul>
<li class="chapter" data-level="10.1" data-path="cleaning-data-in-r.html"><a href="cleaning-data-in-r.html#common-data-problems"><i class="fa fa-check"></i><b>10.1</b> Common Data Problems</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="cleaning-data-in-r.html"><a href="cleaning-data-in-r.html#data-type-constraints"><i class="fa fa-check"></i><b>10.1.1</b> Data type constraints</a></li>
<li class="chapter" data-level="10.1.2" data-path="cleaning-data-in-r.html"><a href="cleaning-data-in-r.html#range-constraints"><i class="fa fa-check"></i><b>10.1.2</b> Range constraints</a></li>
<li class="chapter" data-level="10.1.3" data-path="cleaning-data-in-r.html"><a href="cleaning-data-in-r.html#uniqueness-constraints"><i class="fa fa-check"></i><b>10.1.3</b> Uniqueness constraints</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="cleaning-data-in-r.html"><a href="cleaning-data-in-r.html#categorical-and-text-data"><i class="fa fa-check"></i><b>10.2</b> Categorical and Text Data</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="cleaning-data-in-r.html"><a href="cleaning-data-in-r.html#checking-membership"><i class="fa fa-check"></i><b>10.2.1</b> Checking membership</a></li>
<li class="chapter" data-level="10.2.2" data-path="cleaning-data-in-r.html"><a href="cleaning-data-in-r.html#categorical-data-problems"><i class="fa fa-check"></i><b>10.2.2</b> Categorical data problems</a></li>
<li class="chapter" data-level="10.2.3" data-path="cleaning-data-in-r.html"><a href="cleaning-data-in-r.html#cleaning-text-data"><i class="fa fa-check"></i><b>10.2.3</b> Cleaning text data</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="cleaning-data-in-r.html"><a href="cleaning-data-in-r.html#advanced-data-problems"><i class="fa fa-check"></i><b>10.3</b> Advanced Data Problems</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="cleaning-data-in-r.html"><a href="cleaning-data-in-r.html#uniformity"><i class="fa fa-check"></i><b>10.3.1</b> Uniformity</a></li>
<li class="chapter" data-level="10.3.2" data-path="cleaning-data-in-r.html"><a href="cleaning-data-in-r.html#cross-field-validation"><i class="fa fa-check"></i><b>10.3.2</b> Cross field validation</a></li>
<li class="chapter" data-level="10.3.3" data-path="cleaning-data-in-r.html"><a href="cleaning-data-in-r.html#completeness"><i class="fa fa-check"></i><b>10.3.3</b> Completeness</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="cleaning-data-in-r.html"><a href="cleaning-data-in-r.html#record-linkage"><i class="fa fa-check"></i><b>10.4</b> Record Linkage</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="cleaning-data-in-r.html"><a href="cleaning-data-in-r.html#comparing-strings"><i class="fa fa-check"></i><b>10.4.1</b> Comparing strings</a></li>
<li class="chapter" data-level="10.4.2" data-path="cleaning-data-in-r.html"><a href="cleaning-data-in-r.html#generating-and-comparing-pairs"><i class="fa fa-check"></i><b>10.4.2</b> Generating and comparing pairs</a></li>
<li class="chapter" data-level="10.4.3" data-path="cleaning-data-in-r.html"><a href="cleaning-data-in-r.html#scoring-and-linking"><i class="fa fa-check"></i><b>10.4.3</b> Scoring and linking</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="working-with-dates-and-times-in-r.html"><a href="working-with-dates-and-times-in-r.html"><i class="fa fa-check"></i><b>11</b> Working with Dates and Times in R</a>
<ul>
<li class="chapter" data-level="11.1" data-path="working-with-dates-and-times-in-r.html"><a href="working-with-dates-and-times-in-r.html#dates-and-times-in-r"><i class="fa fa-check"></i><b>11.1</b> Dates and Times in R</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="working-with-dates-and-times-in-r.html"><a href="working-with-dates-and-times-in-r.html#introduction-to-dates"><i class="fa fa-check"></i><b>11.1.1</b> Introduction to dates</a></li>
<li class="chapter" data-level="11.1.2" data-path="working-with-dates-and-times-in-r.html"><a href="working-with-dates-and-times-in-r.html#why-use-dates"><i class="fa fa-check"></i><b>11.1.2</b> Why use dates?</a></li>
<li class="chapter" data-level="11.1.3" data-path="working-with-dates-and-times-in-r.html"><a href="working-with-dates-and-times-in-r.html#what-about-times"><i class="fa fa-check"></i><b>11.1.3</b> What about times?</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="working-with-dates-and-times-in-r.html"><a href="working-with-dates-and-times-in-r.html#parsing-manipulating-with-lubridate"><i class="fa fa-check"></i><b>11.2</b> Parsing &amp; Manipulating with lubridate</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="working-with-dates-and-times-in-r.html"><a href="working-with-dates-and-times-in-r.html#parsing-dates"><i class="fa fa-check"></i><b>11.2.1</b> Parsing dates</a></li>
<li class="chapter" data-level="11.2.2" data-path="working-with-dates-and-times-in-r.html"><a href="working-with-dates-and-times-in-r.html#manipulating-dates"><i class="fa fa-check"></i><b>11.2.2</b> Manipulating dates</a></li>
<li class="chapter" data-level="11.2.3" data-path="working-with-dates-and-times-in-r.html"><a href="working-with-dates-and-times-in-r.html#extracting-parts-of-a-datetime"><i class="fa fa-check"></i><b>11.2.3</b> Extracting parts of a datetime</a></li>
<li class="chapter" data-level="11.2.4" data-path="working-with-dates-and-times-in-r.html"><a href="working-with-dates-and-times-in-r.html#rounding-datetimes"><i class="fa fa-check"></i><b>11.2.4</b> Rounding datetimes</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="working-with-dates-and-times-in-r.html"><a href="working-with-dates-and-times-in-r.html#arithmetic-with-dates-and-times"><i class="fa fa-check"></i><b>11.3</b> Arithmetic with Dates and Times</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="working-with-dates-and-times-in-r.html"><a href="working-with-dates-and-times-in-r.html#taking-differences-of-datetimes"><i class="fa fa-check"></i><b>11.3.1</b> Taking differences of datetimes</a></li>
<li class="chapter" data-level="11.3.2" data-path="working-with-dates-and-times-in-r.html"><a href="working-with-dates-and-times-in-r.html#time-spans"><i class="fa fa-check"></i><b>11.3.2</b> Time spans</a></li>
<li class="chapter" data-level="11.3.3" data-path="working-with-dates-and-times-in-r.html"><a href="working-with-dates-and-times-in-r.html#intervals"><i class="fa fa-check"></i><b>11.3.3</b> Intervals</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="working-with-dates-and-times-in-r.html"><a href="working-with-dates-and-times-in-r.html#problems-in-practice"><i class="fa fa-check"></i><b>11.4</b> Problems in practice</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="working-with-dates-and-times-in-r.html"><a href="working-with-dates-and-times-in-r.html#time-zones"><i class="fa fa-check"></i><b>11.4.1</b> Time zones</a></li>
<li class="chapter" data-level="11.4.2" data-path="working-with-dates-and-times-in-r.html"><a href="working-with-dates-and-times-in-r.html#more-on-import-and-export-datetimes"><i class="fa fa-check"></i><b>11.4.2</b> More on import and export datetimes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="introduction-to-writing-functions.html"><a href="introduction-to-writing-functions.html"><i class="fa fa-check"></i><b>12</b> Introduction to Writing Functions</a>
<ul>
<li class="chapter" data-level="12.1" data-path="introduction-to-writing-functions.html"><a href="introduction-to-writing-functions.html#write-a-function"><i class="fa fa-check"></i><b>12.1</b> Write a Function</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="introduction-to-writing-functions.html"><a href="introduction-to-writing-functions.html#why-write-function"><i class="fa fa-check"></i><b>12.1.1</b> Why write function?</a></li>
<li class="chapter" data-level="12.1.2" data-path="introduction-to-writing-functions.html"><a href="introduction-to-writing-functions.html#convert-scripts-into-functions"><i class="fa fa-check"></i><b>12.1.2</b> Convert scripts into functions</a></li>
<li class="chapter" data-level="12.1.3" data-path="introduction-to-writing-functions.html"><a href="introduction-to-writing-functions.html#readable-code"><i class="fa fa-check"></i><b>12.1.3</b> Readable code</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="introduction-to-writing-functions.html"><a href="introduction-to-writing-functions.html#all-about-arguments"><i class="fa fa-check"></i><b>12.2</b> All About Arguments</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="introduction-to-writing-functions.html"><a href="introduction-to-writing-functions.html#default-arguments"><i class="fa fa-check"></i><b>12.2.1</b> Default arguments</a></li>
<li class="chapter" data-level="12.2.2" data-path="introduction-to-writing-functions.html"><a href="introduction-to-writing-functions.html#pass-arguments-between-functions"><i class="fa fa-check"></i><b>12.2.2</b> Pass arguments between functions</a></li>
<li class="chapter" data-level="12.2.3" data-path="introduction-to-writing-functions.html"><a href="introduction-to-writing-functions.html#checking-arguments"><i class="fa fa-check"></i><b>12.2.3</b> Checking arguments</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="introduction-to-writing-functions.html"><a href="introduction-to-writing-functions.html#return-values-and-scope"><i class="fa fa-check"></i><b>12.3</b> Return Values and Scope</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="introduction-to-writing-functions.html"><a href="introduction-to-writing-functions.html#returning-values"><i class="fa fa-check"></i><b>12.3.1</b> Returning values</a></li>
<li class="chapter" data-level="12.3.2" data-path="introduction-to-writing-functions.html"><a href="introduction-to-writing-functions.html#return-multiple-values"><i class="fa fa-check"></i><b>12.3.2</b> Return multiple values</a></li>
<li class="chapter" data-level="12.3.3" data-path="introduction-to-writing-functions.html"><a href="introduction-to-writing-functions.html#environments"><i class="fa fa-check"></i><b>12.3.3</b> Environments</a></li>
<li class="chapter" data-level="12.3.4" data-path="introduction-to-writing-functions.html"><a href="introduction-to-writing-functions.html#scope-and-precedence"><i class="fa fa-check"></i><b>12.3.4</b> Scope and precedence</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="introduction-to-writing-functions.html"><a href="introduction-to-writing-functions.html#case-study-on-grain-yields"><i class="fa fa-check"></i><b>12.4</b> Case Study on Grain Yields</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="introduction-to-writing-functions.html"><a href="introduction-to-writing-functions.html#grain-yields-unit-conversion"><i class="fa fa-check"></i><b>12.4.1</b> Grain yields &amp; unit conversion</a></li>
<li class="chapter" data-level="12.4.2" data-path="introduction-to-writing-functions.html"><a href="introduction-to-writing-functions.html#visualizing-grain-yields"><i class="fa fa-check"></i><b>12.4.2</b> Visualizing grain yields</a></li>
<li class="chapter" data-level="12.4.3" data-path="introduction-to-writing-functions.html"><a href="introduction-to-writing-functions.html#modeling-grain-yields"><i class="fa fa-check"></i><b>12.4.3</b> Modeling grain yields</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="exploratory-data-analysis-in-r.html"><a href="exploratory-data-analysis-in-r.html"><i class="fa fa-check"></i><b>13</b> Exploratory Data Analysis in R</a>
<ul>
<li class="chapter" data-level="13.1" data-path="exploratory-data-analysis-in-r.html"><a href="exploratory-data-analysis-in-r.html#exploring-categorical-data"><i class="fa fa-check"></i><b>13.1</b> Exploring Categorical Data</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="exploratory-data-analysis-in-r.html"><a href="exploratory-data-analysis-in-r.html#categorical-data"><i class="fa fa-check"></i><b>13.1.1</b> Categorical data</a></li>
<li class="chapter" data-level="13.1.2" data-path="exploratory-data-analysis-in-r.html"><a href="exploratory-data-analysis-in-r.html#counts-vs.-proportions"><i class="fa fa-check"></i><b>13.1.2</b> Counts vs. proportions</a></li>
<li class="chapter" data-level="13.1.3" data-path="exploratory-data-analysis-in-r.html"><a href="exploratory-data-analysis-in-r.html#distribution-of-one-variable"><i class="fa fa-check"></i><b>13.1.3</b> Distribution of one variable</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="exploratory-data-analysis-in-r.html"><a href="exploratory-data-analysis-in-r.html#exploring-numerical-data"><i class="fa fa-check"></i><b>13.2</b> Exploring numerical data</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="exploratory-data-analysis-in-r.html"><a href="exploratory-data-analysis-in-r.html#numerical-data"><i class="fa fa-check"></i><b>13.2.1</b> Numerical Data</a></li>
<li class="chapter" data-level="13.2.2" data-path="exploratory-data-analysis-in-r.html"><a href="exploratory-data-analysis-in-r.html#distribution-of-one-variable-1"><i class="fa fa-check"></i><b>13.2.2</b> Distribution of one variable</a></li>
<li class="chapter" data-level="13.2.3" data-path="exploratory-data-analysis-in-r.html"><a href="exploratory-data-analysis-in-r.html#box-plots-1"><i class="fa fa-check"></i><b>13.2.3</b> Box plots</a></li>
<li class="chapter" data-level="13.2.4" data-path="exploratory-data-analysis-in-r.html"><a href="exploratory-data-analysis-in-r.html#visual-in-higher-dimensions"><i class="fa fa-check"></i><b>13.2.4</b> Visual in higher dimensions</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="exploratory-data-analysis-in-r.html"><a href="exploratory-data-analysis-in-r.html#numerical-summaries"><i class="fa fa-check"></i><b>13.3</b> Numerical Summaries</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="exploratory-data-analysis-in-r.html"><a href="exploratory-data-analysis-in-r.html#measures-of-center-1"><i class="fa fa-check"></i><b>13.3.1</b> Measures of center</a></li>
<li class="chapter" data-level="13.3.2" data-path="exploratory-data-analysis-in-r.html"><a href="exploratory-data-analysis-in-r.html#measures-of-variability"><i class="fa fa-check"></i><b>13.3.2</b> Measures of variability</a></li>
<li class="chapter" data-level="13.3.3" data-path="exploratory-data-analysis-in-r.html"><a href="exploratory-data-analysis-in-r.html#shape-transformations"><i class="fa fa-check"></i><b>13.3.3</b> Shape &amp; transformations</a></li>
<li class="chapter" data-level="13.3.4" data-path="exploratory-data-analysis-in-r.html"><a href="exploratory-data-analysis-in-r.html#outliers"><i class="fa fa-check"></i><b>13.3.4</b> Outliers</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="exploratory-data-analysis-in-r.html"><a href="exploratory-data-analysis-in-r.html#case-study"><i class="fa fa-check"></i><b>13.4</b> Case Study</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="exploratory-data-analysis-in-r.html"><a href="exploratory-data-analysis-in-r.html#new-data"><i class="fa fa-check"></i><b>13.4.1</b> New data</a></li>
<li class="chapter" data-level="13.4.2" data-path="exploratory-data-analysis-in-r.html"><a href="exploratory-data-analysis-in-r.html#check-in-1"><i class="fa fa-check"></i><b>13.4.2</b> Check-in 1</a></li>
<li class="chapter" data-level="13.4.3" data-path="exploratory-data-analysis-in-r.html"><a href="exploratory-data-analysis-in-r.html#check-in-2"><i class="fa fa-check"></i><b>13.4.3</b> Check-in 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="introduction-to-regression.html"><a href="introduction-to-regression.html"><i class="fa fa-check"></i><b>14</b> Introduction to Regression</a>
<ul>
<li class="chapter" data-level="14.1" data-path="introduction-to-regression.html"><a href="introduction-to-regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>14.1</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="introduction-to-regression.html"><a href="introduction-to-regression.html#tale-of-two-variables"><i class="fa fa-check"></i><b>14.1.1</b> Tale of two variables</a></li>
<li class="chapter" data-level="14.1.2" data-path="introduction-to-regression.html"><a href="introduction-to-regression.html#fitting-a-linear-regression"><i class="fa fa-check"></i><b>14.1.2</b> Fitting a linear regression</a></li>
<li class="chapter" data-level="14.1.3" data-path="introduction-to-regression.html"><a href="introduction-to-regression.html#categorical-explanatory-variables"><i class="fa fa-check"></i><b>14.1.3</b> Categorical explanatory variables</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="introduction-to-regression.html"><a href="introduction-to-regression.html#predictions-model-objects"><i class="fa fa-check"></i><b>14.2</b> Predictions &amp; model objects</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="introduction-to-regression.html"><a href="introduction-to-regression.html#making-predictions"><i class="fa fa-check"></i><b>14.2.1</b> Making predictions</a></li>
<li class="chapter" data-level="14.2.2" data-path="introduction-to-regression.html"><a href="introduction-to-regression.html#working-with-model-objects"><i class="fa fa-check"></i><b>14.2.2</b> Working with model objects</a></li>
<li class="chapter" data-level="14.2.3" data-path="introduction-to-regression.html"><a href="introduction-to-regression.html#regression-to-the-mean"><i class="fa fa-check"></i><b>14.2.3</b> Regression to the mean</a></li>
<li class="chapter" data-level="14.2.4" data-path="introduction-to-regression.html"><a href="introduction-to-regression.html#transforming-variables"><i class="fa fa-check"></i><b>14.2.4</b> Transforming variables</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="introduction-to-regression.html"><a href="introduction-to-regression.html#assessing-model-fit"><i class="fa fa-check"></i><b>14.3</b> Assessing model fit</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="introduction-to-regression.html"><a href="introduction-to-regression.html#quantifying-model-fit"><i class="fa fa-check"></i><b>14.3.1</b> Quantifying model fit</a></li>
<li class="chapter" data-level="14.3.2" data-path="introduction-to-regression.html"><a href="introduction-to-regression.html#visualizing-model-fit"><i class="fa fa-check"></i><b>14.3.2</b> Visualizing model fit</a></li>
<li class="chapter" data-level="14.3.3" data-path="introduction-to-regression.html"><a href="introduction-to-regression.html#outliers-leverage-influence"><i class="fa fa-check"></i><b>14.3.3</b> Outliers, leverage, influence</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="introduction-to-regression.html"><a href="introduction-to-regression.html#simple-logistic-regression"><i class="fa fa-check"></i><b>14.4</b> Simple logistic regression</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="introduction-to-regression.html"><a href="introduction-to-regression.html#why-need-logistic-regression"><i class="fa fa-check"></i><b>14.4.1</b> Why need logistic regression</a></li>
<li class="chapter" data-level="14.4.2" data-path="introduction-to-regression.html"><a href="introduction-to-regression.html#predictions-odds-ratios"><i class="fa fa-check"></i><b>14.4.2</b> Predictions &amp; odds ratios</a></li>
<li class="chapter" data-level="14.4.3" data-path="introduction-to-regression.html"><a href="introduction-to-regression.html#quantify-logistic-regression-fit"><i class="fa fa-check"></i><b>14.4.3</b> Quantify logistic regression fit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="intermediate-regression.html"><a href="intermediate-regression.html"><i class="fa fa-check"></i><b>15</b> Intermediate Regression</a>
<ul>
<li class="chapter" data-level="15.1" data-path="intermediate-regression.html"><a href="intermediate-regression.html#parallel-slopes"><i class="fa fa-check"></i><b>15.1</b> Parallel Slopes</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="intermediate-regression.html"><a href="intermediate-regression.html#parallel-slopes-linear-regression"><i class="fa fa-check"></i><b>15.1.1</b> Parallel slopes linear regression</a></li>
<li class="chapter" data-level="15.1.2" data-path="intermediate-regression.html"><a href="intermediate-regression.html#predicting-parallel-slopes"><i class="fa fa-check"></i><b>15.1.2</b> Predicting parallel slopes</a></li>
<li class="chapter" data-level="15.1.3" data-path="intermediate-regression.html"><a href="intermediate-regression.html#assessing-model-performance"><i class="fa fa-check"></i><b>15.1.3</b> Assessing model performance</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="intermediate-regression.html"><a href="intermediate-regression.html#interactions"><i class="fa fa-check"></i><b>15.2</b> Interactions</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="intermediate-regression.html"><a href="intermediate-regression.html#models-for-each-category"><i class="fa fa-check"></i><b>15.2.1</b> Models for each category</a></li>
<li class="chapter" data-level="15.2.2" data-path="intermediate-regression.html"><a href="intermediate-regression.html#one-model-with-an-interaction"><i class="fa fa-check"></i><b>15.2.2</b> One model with an interaction</a></li>
<li class="chapter" data-level="15.2.3" data-path="intermediate-regression.html"><a href="intermediate-regression.html#predict-with-interactions"><i class="fa fa-check"></i><b>15.2.3</b> Predict with interactions</a></li>
<li class="chapter" data-level="15.2.4" data-path="intermediate-regression.html"><a href="intermediate-regression.html#simpsons-paradox"><i class="fa fa-check"></i><b>15.2.4</b> Simpson’s Paradox</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="intermediate-regression.html"><a href="intermediate-regression.html#multiple-linear-regression"><i class="fa fa-check"></i><b>15.3</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="intermediate-regression.html"><a href="intermediate-regression.html#two-numeric-ivs"><i class="fa fa-check"></i><b>15.3.1</b> Two numeric IVs</a></li>
<li class="chapter" data-level="15.3.2" data-path="intermediate-regression.html"><a href="intermediate-regression.html#more-than-2-ivs"><i class="fa fa-check"></i><b>15.3.2</b> More than 2 IVs</a></li>
<li class="chapter" data-level="15.3.3" data-path="intermediate-regression.html"><a href="intermediate-regression.html#model-performance"><i class="fa fa-check"></i><b>15.3.3</b> Model performance</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="intermediate-regression.html"><a href="intermediate-regression.html#multiple-logistic-regression"><i class="fa fa-check"></i><b>15.4</b> Multiple Logistic Regression</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="intermediate-regression.html"><a href="intermediate-regression.html#multiple-logistic-regression-1"><i class="fa fa-check"></i><b>15.4.1</b> Multiple Logistic Regression</a></li>
<li class="chapter" data-level="15.4.2" data-path="intermediate-regression.html"><a href="intermediate-regression.html#logistic-distribution"><i class="fa fa-check"></i><b>15.4.2</b> Logistic distribution</a></li>
<li class="chapter" data-level="15.4.3" data-path="intermediate-regression.html"><a href="intermediate-regression.html#model-performance-1"><i class="fa fa-check"></i><b>15.4.3</b> Model performance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="sampling-in-r.html"><a href="sampling-in-r.html"><i class="fa fa-check"></i><b>16</b> Sampling in R</a>
<ul>
<li class="chapter" data-level="16.1" data-path="sampling-in-r.html"><a href="sampling-in-r.html#introduction-to-sampling"><i class="fa fa-check"></i><b>16.1</b> Introduction to Sampling</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="sampling-in-r.html"><a href="sampling-in-r.html#sampling-point-estimates"><i class="fa fa-check"></i><b>16.1.1</b> Sampling &amp; point estimates</a></li>
<li class="chapter" data-level="16.1.2" data-path="sampling-in-r.html"><a href="sampling-in-r.html#convenience-sampling"><i class="fa fa-check"></i><b>16.1.2</b> Convenience sampling</a></li>
<li class="chapter" data-level="16.1.3" data-path="sampling-in-r.html"><a href="sampling-in-r.html#pseudo-random-number-generation"><i class="fa fa-check"></i><b>16.1.3</b> Pseudo-random number generation</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="sampling-in-r.html"><a href="sampling-in-r.html#sampling-methods"><i class="fa fa-check"></i><b>16.2</b> Sampling Methods</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="sampling-in-r.html"><a href="sampling-in-r.html#simple-random-systematic-sampling"><i class="fa fa-check"></i><b>16.2.1</b> Simple random &amp; systematic sampling</a></li>
<li class="chapter" data-level="16.2.2" data-path="sampling-in-r.html"><a href="sampling-in-r.html#stratified-weighted-random-sampling"><i class="fa fa-check"></i><b>16.2.2</b> Stratified &amp; weighted random sampling</a></li>
<li class="chapter" data-level="16.2.3" data-path="sampling-in-r.html"><a href="sampling-in-r.html#cluster-sampling"><i class="fa fa-check"></i><b>16.2.3</b> Cluster sampling</a></li>
<li class="chapter" data-level="16.2.4" data-path="sampling-in-r.html"><a href="sampling-in-r.html#comparing-sampling-methods"><i class="fa fa-check"></i><b>16.2.4</b> Comparing sampling methods</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="sampling-in-r.html"><a href="sampling-in-r.html#sampling-distributions"><i class="fa fa-check"></i><b>16.3</b> Sampling Distributions</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="sampling-in-r.html"><a href="sampling-in-r.html#relative-error-of-point-estimates"><i class="fa fa-check"></i><b>16.3.1</b> Relative error of point estimates</a></li>
<li class="chapter" data-level="16.3.2" data-path="sampling-in-r.html"><a href="sampling-in-r.html#creating-a-sampling-distribution"><i class="fa fa-check"></i><b>16.3.2</b> Creating a sampling distribution</a></li>
<li class="chapter" data-level="16.3.3" data-path="sampling-in-r.html"><a href="sampling-in-r.html#approximate-sampling-distributions"><i class="fa fa-check"></i><b>16.3.3</b> Approximate sampling distributions</a></li>
<li class="chapter" data-level="16.3.4" data-path="sampling-in-r.html"><a href="sampling-in-r.html#standard-errors-clt"><i class="fa fa-check"></i><b>16.3.4</b> Standard errors &amp; CLT</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="sampling-in-r.html"><a href="sampling-in-r.html#bootstrap-distributions"><i class="fa fa-check"></i><b>16.4</b> Bootstrap Distributions</a>
<ul>
<li class="chapter" data-level="16.4.1" data-path="sampling-in-r.html"><a href="sampling-in-r.html#introduction-to-bootstrapping"><i class="fa fa-check"></i><b>16.4.1</b> Introduction to bootstrapping</a></li>
<li class="chapter" data-level="16.4.2" data-path="sampling-in-r.html"><a href="sampling-in-r.html#comparing-sampling-bootstrap-distributions"><i class="fa fa-check"></i><b>16.4.2</b> Comparing sampling &amp; bootstrap distributions</a></li>
<li class="chapter" data-level="16.4.3" data-path="sampling-in-r.html"><a href="sampling-in-r.html#confidence-intervals"><i class="fa fa-check"></i><b>16.4.3</b> Confidence intervals</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>17</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="17.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#introduction-to-hypothesis-testing"><i class="fa fa-check"></i><b>17.1</b> Introduction to Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-tests-z-scores"><i class="fa fa-check"></i><b>17.1.1</b> Hypothesis tests &amp; z-scores</a></li>
<li class="chapter" data-level="17.1.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#p-values"><i class="fa fa-check"></i><b>17.1.2</b> p-values</a></li>
<li class="chapter" data-level="17.1.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#statistical-significance"><i class="fa fa-check"></i><b>17.1.3</b> Statistical significance</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#two-sample-anova-tests"><i class="fa fa-check"></i><b>17.2</b> Two-Sample &amp; ANOVA Tests</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#performing-t-tests"><i class="fa fa-check"></i><b>17.2.1</b> Performing t-tests</a></li>
<li class="chapter" data-level="17.2.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#calculating-p-values-from-t-statistics"><i class="fa fa-check"></i><b>17.2.2</b> Calculating p-values from t-statistics</a></li>
<li class="chapter" data-level="17.2.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#paired-t-tests"><i class="fa fa-check"></i><b>17.2.3</b> Paired t-tests</a></li>
<li class="chapter" data-level="17.2.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#anova-tests"><i class="fa fa-check"></i><b>17.2.4</b> ANOVA tests</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#proportion-tests"><i class="fa fa-check"></i><b>17.3</b> Proportion Tests</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#one-sample-proportion-tests"><i class="fa fa-check"></i><b>17.3.1</b> One-sample proportion tests</a></li>
<li class="chapter" data-level="17.3.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#two-sample-proportion-tests"><i class="fa fa-check"></i><b>17.3.2</b> Two-sample proportion tests</a></li>
<li class="chapter" data-level="17.3.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#chi-square-test-of-independence"><i class="fa fa-check"></i><b>17.3.3</b> Chi-square test of independence</a></li>
<li class="chapter" data-level="17.3.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#chi-square-goodness-of-fit-tests"><i class="fa fa-check"></i><b>17.3.4</b> Chi-square goodness of fit tests</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#non-parametric-tests"><i class="fa fa-check"></i><b>17.4</b> Non-Parametric Tests</a>
<ul>
<li class="chapter" data-level="17.4.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#assumptions-in-hypothesis-testing"><i class="fa fa-check"></i><b>17.4.1</b> Assumptions in hypothesis testing</a></li>
<li class="chapter" data-level="17.4.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#simulation-based-infer-pipeline"><i class="fa fa-check"></i><b>17.4.2</b> Simulation-based infer pipeline</a></li>
<li class="chapter" data-level="17.4.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#non-parametric-anova-unpaired-t-tests"><i class="fa fa-check"></i><b>17.4.3</b> Non-parametric ANOVA &amp; unpaired t-tests</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="experimental-design.html"><a href="experimental-design.html"><i class="fa fa-check"></i><b>18</b> Experimental Design</a>
<ul>
<li class="chapter" data-level="18.1" data-path="experimental-design.html"><a href="experimental-design.html#introduction-to-experimental-design"><i class="fa fa-check"></i><b>18.1</b> Introduction to experimental design</a>
<ul>
<li class="chapter" data-level="18.1.1" data-path="experimental-design.html"><a href="experimental-design.html#introduction-1"><i class="fa fa-check"></i><b>18.1.1</b> Introduction</a></li>
<li class="chapter" data-level="18.1.2" data-path="experimental-design.html"><a href="experimental-design.html#replication-blocking"><i class="fa fa-check"></i><b>18.1.2</b> Replication &amp; blocking</a></li>
<li class="chapter" data-level="18.1.3" data-path="experimental-design.html"><a href="experimental-design.html#hypothesis-testing-1"><i class="fa fa-check"></i><b>18.1.3</b> Hypothesis testing</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="experimental-design.html"><a href="experimental-design.html#basic-experiments"><i class="fa fa-check"></i><b>18.2</b> Basic Experiments</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="experimental-design.html"><a href="experimental-design.html#anova-factor-experiments"><i class="fa fa-check"></i><b>18.2.1</b> ANOVA &amp; factor experiments</a></li>
<li class="chapter" data-level="18.2.2" data-path="experimental-design.html"><a href="experimental-design.html#model-validation"><i class="fa fa-check"></i><b>18.2.2</b> Model validation</a></li>
<li class="chapter" data-level="18.2.3" data-path="experimental-design.html"><a href="experimental-design.html#ab-testing"><i class="fa fa-check"></i><b>18.2.3</b> A/B testing</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="experimental-design.html"><a href="experimental-design.html#block-designs"><i class="fa fa-check"></i><b>18.3</b> Block Designs</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="experimental-design.html"><a href="experimental-design.html#intro-to-sampling"><i class="fa fa-check"></i><b>18.3.1</b> Intro to sampling</a></li>
<li class="chapter" data-level="18.3.2" data-path="experimental-design.html"><a href="experimental-design.html#randomized-complete-block-designs-rcbd"><i class="fa fa-check"></i><b>18.3.2</b> Randomized Complete Block Designs (RCBD)</a></li>
<li class="chapter" data-level="18.3.3" data-path="experimental-design.html"><a href="experimental-design.html#balanced-incomplete-block-designs-bibd"><i class="fa fa-check"></i><b>18.3.3</b> Balanced Incomplete Block Designs (BIBD)</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="experimental-design.html"><a href="experimental-design.html#squares-factorial-experiments"><i class="fa fa-check"></i><b>18.4</b> Squares &amp; Factorial Experiments</a>
<ul>
<li class="chapter" data-level="18.4.1" data-path="experimental-design.html"><a href="experimental-design.html#latin-squares"><i class="fa fa-check"></i><b>18.4.1</b> Latin squares</a></li>
<li class="chapter" data-level="18.4.2" data-path="experimental-design.html"><a href="experimental-design.html#graeco-latin-squares"><i class="fa fa-check"></i><b>18.4.2</b> Graeco-Latin squares</a></li>
<li class="chapter" data-level="18.4.3" data-path="experimental-design.html"><a href="experimental-design.html#factorial-experiments"><i class="fa fa-check"></i><b>18.4.3</b> Factorial experiments</a></li>
<li class="chapter" data-level="18.4.4" data-path="experimental-design.html"><a href="experimental-design.html#other-experimental-designs"><i class="fa fa-check"></i><b>18.4.4</b> Other experimental designs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="supervised-learning-classification.html"><a href="supervised-learning-classification.html"><i class="fa fa-check"></i><b>19</b> Supervised Learning: Classification</a>
<ul>
<li class="chapter" data-level="19.1" data-path="supervised-learning-classification.html"><a href="supervised-learning-classification.html#k-nearest-neighbors-knn"><i class="fa fa-check"></i><b>19.1</b> k-Nearest Neighbors (kNN)</a>
<ul>
<li class="chapter" data-level="19.1.1" data-path="supervised-learning-classification.html"><a href="supervised-learning-classification.html#classification-with-nearest-neighbors"><i class="fa fa-check"></i><b>19.1.1</b> Classification with Nearest Neighbors</a></li>
<li class="chapter" data-level="19.1.2" data-path="supervised-learning-classification.html"><a href="supervised-learning-classification.html#k-in-knn"><i class="fa fa-check"></i><b>19.1.2</b> ‘k’ in kNN</a></li>
<li class="chapter" data-level="19.1.3" data-path="supervised-learning-classification.html"><a href="supervised-learning-classification.html#data-preparation-for-knn"><i class="fa fa-check"></i><b>19.1.3</b> 1-3.Data preparation for kNN</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="supervised-learning-classification.html"><a href="supervised-learning-classification.html#naive-bayes"><i class="fa fa-check"></i><b>19.2</b> Naive Bayes</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="supervised-learning-classification.html"><a href="supervised-learning-classification.html#understanding-bayesian-methods"><i class="fa fa-check"></i><b>19.2.1</b> Understanding Bayesian methods</a></li>
<li class="chapter" data-level="19.2.2" data-path="supervised-learning-classification.html"><a href="supervised-learning-classification.html#understanding-nbs-naivety"><i class="fa fa-check"></i><b>19.2.2</b> Understanding NB’s “naivety”</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="supervised-learning-classification.html"><a href="supervised-learning-classification.html#logistic-regression"><i class="fa fa-check"></i><b>19.3</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="supervised-learning-classification.html"><a href="supervised-learning-classification.html#making-binary-predictions-with-regression"><i class="fa fa-check"></i><b>19.3.1</b> Making binary predictions with regression</a></li>
<li class="chapter" data-level="19.3.2" data-path="supervised-learning-classification.html"><a href="supervised-learning-classification.html#model-performance-tradeoffs"><i class="fa fa-check"></i><b>19.3.2</b> Model performance tradeoffs</a></li>
<li class="chapter" data-level="19.3.3" data-path="supervised-learning-classification.html"><a href="supervised-learning-classification.html#dummy-variables-missing-data-and-interactions"><i class="fa fa-check"></i><b>19.3.3</b> Dummy variables, missing data, and interactions</a></li>
<li class="chapter" data-level="19.3.4" data-path="supervised-learning-classification.html"><a href="supervised-learning-classification.html#automatic-feature-selection"><i class="fa fa-check"></i><b>19.3.4</b> Automatic feature selection</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="supervised-learning-classification.html"><a href="supervised-learning-classification.html#classification-trees"><i class="fa fa-check"></i><b>19.4</b> Classification Trees</a>
<ul>
<li class="chapter" data-level="19.4.1" data-path="supervised-learning-classification.html"><a href="supervised-learning-classification.html#making-decisions-with-trees"><i class="fa fa-check"></i><b>19.4.1</b> Making decisions with trees</a></li>
<li class="chapter" data-level="19.4.2" data-path="supervised-learning-classification.html"><a href="supervised-learning-classification.html#growing-larger-classification-trees"><i class="fa fa-check"></i><b>19.4.2</b> Growing larger classification trees</a></li>
<li class="chapter" data-level="19.4.3" data-path="supervised-learning-classification.html"><a href="supervised-learning-classification.html#tending-to-classification-trees"><i class="fa fa-check"></i><b>19.4.3</b> Tending to classification trees</a></li>
<li class="chapter" data-level="19.4.4" data-path="supervised-learning-classification.html"><a href="supervised-learning-classification.html#seeing-the-forest-from-the-trees"><i class="fa fa-check"></i><b>19.4.4</b> Seeing the forest from the trees</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="supervised-learning-regression.html"><a href="supervised-learning-regression.html"><i class="fa fa-check"></i><b>20</b> Supervised Learning: Regression</a>
<ul>
<li class="chapter" data-level="20.1" data-path="supervised-learning-regression.html"><a href="supervised-learning-regression.html#what-is-regression"><i class="fa fa-check"></i><b>20.1</b> What is Regression?</a>
<ul>
<li class="chapter" data-level="20.1.1" data-path="supervised-learning-regression.html"><a href="supervised-learning-regression.html#introduction-2"><i class="fa fa-check"></i><b>20.1.1</b> Introduction</a></li>
<li class="chapter" data-level="20.1.2" data-path="supervised-learning-regression.html"><a href="supervised-learning-regression.html#linear-regression"><i class="fa fa-check"></i><b>20.1.2</b> Linear regression</a></li>
<li class="chapter" data-level="20.1.3" data-path="supervised-learning-regression.html"><a href="supervised-learning-regression.html#predicting-model"><i class="fa fa-check"></i><b>20.1.3</b> Predicting model</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="supervised-learning-regression.html"><a href="supervised-learning-regression.html#training-and-evaluating-models"><i class="fa fa-check"></i><b>20.2</b> Training and Evaluating Models</a>
<ul>
<li class="chapter" data-level="20.2.1" data-path="supervised-learning-regression.html"><a href="supervised-learning-regression.html#graphically"><i class="fa fa-check"></i><b>20.2.1</b> Graphically</a></li>
<li class="chapter" data-level="20.2.2" data-path="supervised-learning-regression.html"><a href="supervised-learning-regression.html#root-mean-squared-error"><i class="fa fa-check"></i><b>20.2.2</b> Root Mean Squared Error</a></li>
<li class="chapter" data-level="20.2.3" data-path="supervised-learning-regression.html"><a href="supervised-learning-regression.html#r-squared"><i class="fa fa-check"></i><b>20.2.3</b> R-squared</a></li>
<li class="chapter" data-level="20.2.4" data-path="supervised-learning-regression.html"><a href="supervised-learning-regression.html#training-a-model"><i class="fa fa-check"></i><b>20.2.4</b> Training a Model</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path="supervised-learning-regression.html"><a href="supervised-learning-regression.html#issues-to-consider"><i class="fa fa-check"></i><b>20.3</b> Issues to Consider</a>
<ul>
<li class="chapter" data-level="20.3.1" data-path="supervised-learning-regression.html"><a href="supervised-learning-regression.html#categorical-iv"><i class="fa fa-check"></i><b>20.3.1</b> Categorical IV</a></li>
<li class="chapter" data-level="20.3.2" data-path="supervised-learning-regression.html"><a href="supervised-learning-regression.html#interactions-1"><i class="fa fa-check"></i><b>20.3.2</b> Interactions</a></li>
<li class="chapter" data-level="20.3.3" data-path="supervised-learning-regression.html"><a href="supervised-learning-regression.html#transforming-dv-before-modeling"><i class="fa fa-check"></i><b>20.3.3</b> Transforming DV before modeling</a></li>
<li class="chapter" data-level="20.3.4" data-path="supervised-learning-regression.html"><a href="supervised-learning-regression.html#transforming-iv-before-modeling"><i class="fa fa-check"></i><b>20.3.4</b> Transforming IV before modeling</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="supervised-learning-regression.html"><a href="supervised-learning-regression.html#dealing-with-non-linear-responses"><i class="fa fa-check"></i><b>20.4</b> Dealing with Non-Linear Responses</a>
<ul>
<li class="chapter" data-level="20.4.1" data-path="supervised-learning-regression.html"><a href="supervised-learning-regression.html#logistic-regression-to-predict-probabilities"><i class="fa fa-check"></i><b>20.4.1</b> Logistic regression to predict probabilities</a></li>
<li class="chapter" data-level="20.4.2" data-path="supervised-learning-regression.html"><a href="supervised-learning-regression.html#poisson-and-quasipoisson-regression-to-predict-counts"><i class="fa fa-check"></i><b>20.4.2</b> Poisson and quasipoisson regression to predict counts</a></li>
<li class="chapter" data-level="20.4.3" data-path="supervised-learning-regression.html"><a href="supervised-learning-regression.html#gam-to-learn-non-linear-transforms"><i class="fa fa-check"></i><b>20.4.3</b> GAM to learn non-linear transforms</a></li>
</ul></li>
<li class="chapter" data-level="20.5" data-path="supervised-learning-regression.html"><a href="supervised-learning-regression.html#tree-based-methods"><i class="fa fa-check"></i><b>20.5</b> Tree-Based Methods</a>
<ul>
<li class="chapter" data-level="20.5.1" data-path="supervised-learning-regression.html"><a href="supervised-learning-regression.html#random-forests"><i class="fa fa-check"></i><b>20.5.1</b> Random forests</a></li>
<li class="chapter" data-level="20.5.2" data-path="supervised-learning-regression.html"><a href="supervised-learning-regression.html#one-hot-encoding"><i class="fa fa-check"></i><b>20.5.2</b> One-Hot-Encoding</a></li>
<li class="chapter" data-level="20.5.3" data-path="supervised-learning-regression.html"><a href="supervised-learning-regression.html#gradient-boosting"><i class="fa fa-check"></i><b>20.5.3</b> Gradient boosting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html"><i class="fa fa-check"></i><b>21</b> Unsupervised Learning</a>
<ul>
<li class="chapter" data-level="21.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#k-means-clustering"><i class="fa fa-check"></i><b>21.1</b> k-means clustering</a>
<ul>
<li class="chapter" data-level="21.1.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#types-of-machine-learning"><i class="fa fa-check"></i><b>21.1.1</b> Types of machine learning</a></li>
<li class="chapter" data-level="21.1.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#introduction-to-k-means"><i class="fa fa-check"></i><b>21.1.2</b> Introduction to k-means</a></li>
<li class="chapter" data-level="21.1.3" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#model-selection"><i class="fa fa-check"></i><b>21.1.3</b> Model selection</a></li>
<li class="chapter" data-level="21.1.4" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#pokemon-data"><i class="fa fa-check"></i><b>21.1.4</b> Pokemon data</a></li>
</ul></li>
<li class="chapter" data-level="21.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#hierarchical-clustering"><i class="fa fa-check"></i><b>21.2</b> Hierarchical clustering</a>
<ul>
<li class="chapter" data-level="21.2.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#introduction-3"><i class="fa fa-check"></i><b>21.2.1</b> Introduction</a></li>
<li class="chapter" data-level="21.2.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#selecting-number-of-clusters-1"><i class="fa fa-check"></i><b>21.2.2</b> Selecting number of clusters</a></li>
<li class="chapter" data-level="21.2.3" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#clustering-linkage"><i class="fa fa-check"></i><b>21.2.3</b> Clustering linkage</a></li>
</ul></li>
<li class="chapter" data-level="21.3" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#dimensionality-reduction---pca"><i class="fa fa-check"></i><b>21.3</b> Dimensionality reduction - PCA</a>
<ul>
<li class="chapter" data-level="21.3.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#introduction-4"><i class="fa fa-check"></i><b>21.3.1</b> Introduction</a></li>
<li class="chapter" data-level="21.3.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#visualizing-and-interpreting-1"><i class="fa fa-check"></i><b>21.3.2</b> Visualizing and interpreting</a></li>
<li class="chapter" data-level="21.3.3" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#practical-issues"><i class="fa fa-check"></i><b>21.3.3</b> Practical issues</a></li>
</ul></li>
<li class="chapter" data-level="21.4" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#case-study-1"><i class="fa fa-check"></i><b>21.4</b> Case study</a>
<ul>
<li class="chapter" data-level="21.4.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#introduction-5"><i class="fa fa-check"></i><b>21.4.1</b> Introduction</a></li>
<li class="chapter" data-level="21.4.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#next-steps"><i class="fa fa-check"></i><b>21.4.2</b> Next steps</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="22" data-path="intermediate-importing-data-in-r.html"><a href="intermediate-importing-data-in-r.html"><i class="fa fa-check"></i><b>22</b> Intermediate Importing Data in R</a>
<ul>
<li class="chapter" data-level="22.1" data-path="intermediate-importing-data-in-r.html"><a href="intermediate-importing-data-in-r.html#import-from-databases-1"><i class="fa fa-check"></i><b>22.1</b> Import from databases-1</a>
<ul>
<li class="chapter" data-level="22.1.1" data-path="intermediate-importing-data-in-r.html"><a href="intermediate-importing-data-in-r.html#connect-to-a-database"><i class="fa fa-check"></i><b>22.1.1</b> Connect to a database</a></li>
<li class="chapter" data-level="22.1.2" data-path="intermediate-importing-data-in-r.html"><a href="intermediate-importing-data-in-r.html#import-table-data"><i class="fa fa-check"></i><b>22.1.2</b> Import table data</a></li>
</ul></li>
<li class="chapter" data-level="22.2" data-path="intermediate-importing-data-in-r.html"><a href="intermediate-importing-data-in-r.html#import-from-databases-2"><i class="fa fa-check"></i><b>22.2</b> Import from databases-2</a>
<ul>
<li class="chapter" data-level="22.2.1" data-path="intermediate-importing-data-in-r.html"><a href="intermediate-importing-data-in-r.html#sql-queries-from-inside-r"><i class="fa fa-check"></i><b>22.2.1</b> SQL Queries from inside R</a></li>
<li class="chapter" data-level="22.2.2" data-path="intermediate-importing-data-in-r.html"><a href="intermediate-importing-data-in-r.html#dbi-internals"><i class="fa fa-check"></i><b>22.2.2</b> DBI internals</a></li>
</ul></li>
<li class="chapter" data-level="22.3" data-path="intermediate-importing-data-in-r.html"><a href="intermediate-importing-data-in-r.html#import-from-the-web-1"><i class="fa fa-check"></i><b>22.3</b> Import from the web-1</a>
<ul>
<li class="chapter" data-level="22.3.1" data-path="intermediate-importing-data-in-r.html"><a href="intermediate-importing-data-in-r.html#http"><i class="fa fa-check"></i><b>22.3.1</b> HTTP</a></li>
<li class="chapter" data-level="22.3.2" data-path="intermediate-importing-data-in-r.html"><a href="intermediate-importing-data-in-r.html#downloading-files"><i class="fa fa-check"></i><b>22.3.2</b> Downloading files</a></li>
</ul></li>
<li class="chapter" data-level="22.4" data-path="intermediate-importing-data-in-r.html"><a href="intermediate-importing-data-in-r.html#import-from-the-web-2"><i class="fa fa-check"></i><b>22.4</b> Import from the web-2</a>
<ul>
<li class="chapter" data-level="22.4.1" data-path="intermediate-importing-data-in-r.html"><a href="intermediate-importing-data-in-r.html#apis-json"><i class="fa fa-check"></i><b>22.4.1</b> APIs &amp; JSON</a></li>
<li class="chapter" data-level="22.4.2" data-path="intermediate-importing-data-in-r.html"><a href="intermediate-importing-data-in-r.html#json-jsonlite"><i class="fa fa-check"></i><b>22.4.2</b> JSON &amp; jsonlite</a></li>
</ul></li>
<li class="chapter" data-level="22.5" data-path="intermediate-importing-data-in-r.html"><a href="intermediate-importing-data-in-r.html#import-from-statistical-software"><i class="fa fa-check"></i><b>22.5</b> Import from statistical software</a>
<ul>
<li class="chapter" data-level="22.5.1" data-path="intermediate-importing-data-in-r.html"><a href="intermediate-importing-data-in-r.html#haven-package"><i class="fa fa-check"></i><b>22.5.1</b> haven package</a></li>
<li class="chapter" data-level="22.5.2" data-path="intermediate-importing-data-in-r.html"><a href="intermediate-importing-data-in-r.html#foreign-package"><i class="fa fa-check"></i><b>22.5.2</b> foreign package</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="23" data-path="introduction-to-sql.html"><a href="introduction-to-sql.html"><i class="fa fa-check"></i><b>23</b> Introduction to SQL</a>
<ul>
<li class="chapter" data-level="23.1" data-path="introduction-to-sql.html"><a href="introduction-to-sql.html#relational-databases"><i class="fa fa-check"></i><b>23.1</b> Relational Databases</a>
<ul>
<li class="chapter" data-level="23.1.1" data-path="introduction-to-sql.html"><a href="introduction-to-sql.html#databases"><i class="fa fa-check"></i><b>23.1.1</b> Databases</a></li>
<li class="chapter" data-level="23.1.2" data-path="introduction-to-sql.html"><a href="introduction-to-sql.html#tables"><i class="fa fa-check"></i><b>23.1.2</b> Tables</a></li>
<li class="chapter" data-level="23.1.3" data-path="introduction-to-sql.html"><a href="introduction-to-sql.html#data"><i class="fa fa-check"></i><b>23.1.3</b> Data</a></li>
</ul></li>
<li class="chapter" data-level="23.2" data-path="introduction-to-sql.html"><a href="introduction-to-sql.html#querying"><i class="fa fa-check"></i><b>23.2</b> Querying</a>
<ul>
<li class="chapter" data-level="23.2.1" data-path="introduction-to-sql.html"><a href="introduction-to-sql.html#introducing"><i class="fa fa-check"></i><b>23.2.1</b> Introducing</a></li>
<li class="chapter" data-level="23.2.2" data-path="introduction-to-sql.html"><a href="introduction-to-sql.html#writing-queries"><i class="fa fa-check"></i><b>23.2.2</b> Writing queries</a></li>
<li class="chapter" data-level="23.2.3" data-path="introduction-to-sql.html"><a href="introduction-to-sql.html#sql-flavors"><i class="fa fa-check"></i><b>23.2.3</b> SQL flavors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="24" data-path="intermediate-sql.html"><a href="intermediate-sql.html"><i class="fa fa-check"></i><b>24</b> Intermediate SQL</a>
<ul>
<li class="chapter" data-level="24.1" data-path="intermediate-sql.html"><a href="intermediate-sql.html#selecting-data"><i class="fa fa-check"></i><b>24.1</b> Selecting Data</a>
<ul>
<li class="chapter" data-level="24.1.1" data-path="intermediate-sql.html"><a href="intermediate-sql.html#querying-a-database"><i class="fa fa-check"></i><b>24.1.1</b> Querying a database</a></li>
<li class="chapter" data-level="24.1.2" data-path="intermediate-sql.html"><a href="intermediate-sql.html#query-execution"><i class="fa fa-check"></i><b>24.1.2</b> Query execution</a></li>
<li class="chapter" data-level="24.1.3" data-path="intermediate-sql.html"><a href="intermediate-sql.html#sql-style"><i class="fa fa-check"></i><b>24.1.3</b> SQL style</a></li>
</ul></li>
<li class="chapter" data-level="24.2" data-path="intermediate-sql.html"><a href="intermediate-sql.html#filtering-records"><i class="fa fa-check"></i><b>24.2</b> Filtering Records</a>
<ul>
<li class="chapter" data-level="24.2.1" data-path="intermediate-sql.html"><a href="intermediate-sql.html#filtering-numbers"><i class="fa fa-check"></i><b>24.2.1</b> Filtering numbers</a></li>
<li class="chapter" data-level="24.2.2" data-path="intermediate-sql.html"><a href="intermediate-sql.html#multiple-criteria"><i class="fa fa-check"></i><b>24.2.2</b> Multiple criteria</a></li>
<li class="chapter" data-level="24.2.3" data-path="intermediate-sql.html"><a href="intermediate-sql.html#filtering-text"><i class="fa fa-check"></i><b>24.2.3</b> Filtering text</a></li>
<li class="chapter" data-level="24.2.4" data-path="intermediate-sql.html"><a href="intermediate-sql.html#null-values"><i class="fa fa-check"></i><b>24.2.4</b> NULL values</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="intermediate-sql.html"><a href="intermediate-sql.html#aggregate-functions"><i class="fa fa-check"></i><b>24.3</b> Aggregate Functions</a>
<ul>
<li class="chapter" data-level="24.3.1" data-path="intermediate-sql.html"><a href="intermediate-sql.html#summarizing-data"><i class="fa fa-check"></i><b>24.3.1</b> Summarizing data</a></li>
<li class="chapter" data-level="24.3.2" data-path="intermediate-sql.html"><a href="intermediate-sql.html#summarizing-subsets"><i class="fa fa-check"></i><b>24.3.2</b> Summarizing subsets</a></li>
<li class="chapter" data-level="24.3.3" data-path="intermediate-sql.html"><a href="intermediate-sql.html#aliasing-and-arithmetic"><i class="fa fa-check"></i><b>24.3.3</b> Aliasing and arithmetic</a></li>
</ul></li>
<li class="chapter" data-level="24.4" data-path="intermediate-sql.html"><a href="intermediate-sql.html#sorting-and-grouping"><i class="fa fa-check"></i><b>24.4</b> Sorting and Grouping</a>
<ul>
<li class="chapter" data-level="24.4.1" data-path="intermediate-sql.html"><a href="intermediate-sql.html#sorting-results"><i class="fa fa-check"></i><b>24.4.1</b> Sorting results</a></li>
<li class="chapter" data-level="24.4.2" data-path="intermediate-sql.html"><a href="intermediate-sql.html#grouping-data"><i class="fa fa-check"></i><b>24.4.2</b> Grouping data</a></li>
<li class="chapter" data-level="24.4.3" data-path="intermediate-sql.html"><a href="intermediate-sql.html#filtering-grouped-data"><i class="fa fa-check"></i><b>24.4.3</b> Filtering grouped data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="25" data-path="joining-data-in-sql.html"><a href="joining-data-in-sql.html"><i class="fa fa-check"></i><b>25</b> Joining Data in SQL</a>
<ul>
<li class="chapter" data-level="25.1" data-path="joining-data-in-sql.html"><a href="joining-data-in-sql.html#inner-joins"><i class="fa fa-check"></i><b>25.1</b> Inner Joins</a>
<ul>
<li class="chapter" data-level="25.1.1" data-path="joining-data-in-sql.html"><a href="joining-data-in-sql.html#ins-outs-of-inner-join"><i class="fa fa-check"></i><b>25.1.1</b> ins &amp; outs of INNER JOIN</a></li>
<li class="chapter" data-level="25.1.2" data-path="joining-data-in-sql.html"><a href="joining-data-in-sql.html#defining-relationships"><i class="fa fa-check"></i><b>25.1.2</b> Defining relationships</a></li>
<li class="chapter" data-level="25.1.3" data-path="joining-data-in-sql.html"><a href="joining-data-in-sql.html#multiple-joins"><i class="fa fa-check"></i><b>25.1.3</b> Multiple joins</a></li>
</ul></li>
<li class="chapter" data-level="25.2" data-path="joining-data-in-sql.html"><a href="joining-data-in-sql.html#outer-cross-self-joins"><i class="fa fa-check"></i><b>25.2</b> Outer, Cross &amp; Self Joins</a>
<ul>
<li class="chapter" data-level="25.2.1" data-path="joining-data-in-sql.html"><a href="joining-data-in-sql.html#left-right-joins-1"><i class="fa fa-check"></i><b>25.2.1</b> LEFT &amp; RIGHT JOINs</a></li>
<li class="chapter" data-level="25.2.2" data-path="joining-data-in-sql.html"><a href="joining-data-in-sql.html#full-join-1"><i class="fa fa-check"></i><b>25.2.2</b> FULL JOIN</a></li>
<li class="chapter" data-level="25.2.3" data-path="joining-data-in-sql.html"><a href="joining-data-in-sql.html#cross-join"><i class="fa fa-check"></i><b>25.2.3</b> CROSS JOIN</a></li>
<li class="chapter" data-level="25.2.4" data-path="joining-data-in-sql.html"><a href="joining-data-in-sql.html#self-joins"><i class="fa fa-check"></i><b>25.2.4</b> Self joins</a></li>
</ul></li>
<li class="chapter" data-level="25.3" data-path="joining-data-in-sql.html"><a href="joining-data-in-sql.html#set-theory-for-sql-joins"><i class="fa fa-check"></i><b>25.3</b> Set Theory for SQL Joins</a>
<ul>
<li class="chapter" data-level="25.3.1" data-path="joining-data-in-sql.html"><a href="joining-data-in-sql.html#union-vs.-union-all"><i class="fa fa-check"></i><b>25.3.1</b> UNION vs. UNION ALL</a></li>
<li class="chapter" data-level="25.3.2" data-path="joining-data-in-sql.html"><a href="joining-data-in-sql.html#intersect"><i class="fa fa-check"></i><b>25.3.2</b> INTERSECT</a></li>
<li class="chapter" data-level="25.3.3" data-path="joining-data-in-sql.html"><a href="joining-data-in-sql.html#except"><i class="fa fa-check"></i><b>25.3.3</b> EXCEPT</a></li>
</ul></li>
<li class="chapter" data-level="25.4" data-path="joining-data-in-sql.html"><a href="joining-data-in-sql.html#subqueries"><i class="fa fa-check"></i><b>25.4</b> Subqueries</a>
<ul>
<li class="chapter" data-level="25.4.1" data-path="joining-data-in-sql.html"><a href="joining-data-in-sql.html#with-semi-joins-anti-joins"><i class="fa fa-check"></i><b>25.4.1</b> With semi joins &amp; anti joins</a></li>
<li class="chapter" data-level="25.4.2" data-path="joining-data-in-sql.html"><a href="joining-data-in-sql.html#inside-where-select"><i class="fa fa-check"></i><b>25.4.2</b> Inside WHERE &amp; SELECT</a></li>
<li class="chapter" data-level="25.4.3" data-path="joining-data-in-sql.html"><a href="joining-data-in-sql.html#inside-from"><i class="fa fa-check"></i><b>25.4.3</b> Inside FROM</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="26" data-path="introduction-to-git.html"><a href="introduction-to-git.html"><i class="fa fa-check"></i><b>26</b> Introduction to Git</a>
<ul>
<li class="chapter" data-level="26.1" data-path="introduction-to-git.html"><a href="introduction-to-git.html#introduction-6"><i class="fa fa-check"></i><b>26.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="26.1.1" data-path="introduction-to-git.html"><a href="introduction-to-git.html#useful-shell-commands"><i class="fa fa-check"></i><b>26.1.1</b> Useful shell commands</a></li>
<li class="chapter" data-level="26.1.2" data-path="introduction-to-git.html"><a href="introduction-to-git.html#saving-files"><i class="fa fa-check"></i><b>26.1.2</b> Saving files</a></li>
<li class="chapter" data-level="26.1.3" data-path="introduction-to-git.html"><a href="introduction-to-git.html#comparing-files"><i class="fa fa-check"></i><b>26.1.3</b> Comparing files</a></li>
</ul></li>
<li class="chapter" data-level="26.2" data-path="introduction-to-git.html"><a href="introduction-to-git.html#making-changes"><i class="fa fa-check"></i><b>26.2</b> Making changes</a>
<ul>
<li class="chapter" data-level="26.2.1" data-path="introduction-to-git.html"><a href="introduction-to-git.html#storing-data-with-git"><i class="fa fa-check"></i><b>26.2.1</b> Storing data with Git</a></li>
<li class="chapter" data-level="26.2.2" data-path="introduction-to-git.html"><a href="introduction-to-git.html#viewing-changes"><i class="fa fa-check"></i><b>26.2.2</b> Viewing changes</a></li>
<li class="chapter" data-level="26.2.3" data-path="introduction-to-git.html"><a href="introduction-to-git.html#undoing-changes-before-committing"><i class="fa fa-check"></i><b>26.2.3</b> Undoing changes before committing</a></li>
<li class="chapter" data-level="26.2.4" data-path="introduction-to-git.html"><a href="introduction-to-git.html#restoring-and-reverting"><i class="fa fa-check"></i><b>26.2.4</b> Restoring and reverting</a></li>
</ul></li>
<li class="chapter" data-level="26.3" data-path="introduction-to-git.html"><a href="introduction-to-git.html#git-workflows"><i class="fa fa-check"></i><b>26.3</b> Git workflows</a>
<ul>
<li class="chapter" data-level="26.3.1" data-path="introduction-to-git.html"><a href="introduction-to-git.html#configuring-git"><i class="fa fa-check"></i><b>26.3.1</b> Configuring Git</a></li>
<li class="chapter" data-level="26.3.2" data-path="introduction-to-git.html"><a href="introduction-to-git.html#branches"><i class="fa fa-check"></i><b>26.3.2</b> Branches</a></li>
<li class="chapter" data-level="26.3.3" data-path="introduction-to-git.html"><a href="introduction-to-git.html#working-with-branches"><i class="fa fa-check"></i><b>26.3.3</b> Working with branches</a></li>
<li class="chapter" data-level="26.3.4" data-path="introduction-to-git.html"><a href="introduction-to-git.html#handling-conflict"><i class="fa fa-check"></i><b>26.3.4</b> Handling conflict</a></li>
</ul></li>
<li class="chapter" data-level="26.4" data-path="introduction-to-git.html"><a href="introduction-to-git.html#collaborating-with-git"><i class="fa fa-check"></i><b>26.4</b> Collaborating with Git</a>
<ul>
<li class="chapter" data-level="26.4.1" data-path="introduction-to-git.html"><a href="introduction-to-git.html#creating-repos"><i class="fa fa-check"></i><b>26.4.1</b> Creating repos</a></li>
<li class="chapter" data-level="26.4.2" data-path="introduction-to-git.html"><a href="introduction-to-git.html#working-with-remotes"><i class="fa fa-check"></i><b>26.4.2</b> Working with remotes</a></li>
<li class="chapter" data-level="26.4.3" data-path="introduction-to-git.html"><a href="introduction-to-git.html#pulling-from-a-remote"><i class="fa fa-check"></i><b>26.4.3</b> Pulling from a remote</a></li>
<li class="chapter" data-level="26.4.4" data-path="introduction-to-git.html"><a href="introduction-to-git.html#pushing-to-a-remote"><i class="fa fa-check"></i><b>26.4.4</b> Pushing to a remote</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Scientist with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="supervised-learning-regression" class="section level1 hasAnchor" number="20">
<h1><span class="header-section-number">Chapter 20</span> Supervised Learning: Regression<a href="supervised-learning-regression.html#supervised-learning-regression" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="what-is-regression" class="section level2 hasAnchor" number="20.1">
<h2><span class="header-section-number">20.1</span> What is Regression?<a href="supervised-learning-regression.html#what-is-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="introduction-2" class="section level3 hasAnchor" number="20.1.1">
<h3><span class="header-section-number">20.1.1</span> Introduction<a href="supervised-learning-regression.html#introduction-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<dl>
<dt>Regression</dt>
<dd>
<p>Predict a numerical outcome (“dependent variable”) from a set of inputs (“independent variables”).</p>
</dd>
</dl>
<ul>
<li><p>Statistical Sense: Predicting the expected value of the outcome.</p></li>
<li><p>Casual Sense: Predicting a numerical outcome.</p></li>
</ul>
<p><strong>Regression from a Machine Learning Perspective</strong></p>
<ul>
<li>Scientific mindset: Modeling to understand the data generation process</li>
</ul>
<p><strong>Collinearity</strong></p>
<ul>
<li><p>Collinearity: when independent variables are partially correlated.</p></li>
<li><p>High collinearity:</p>
<ul>
<li><p>Coefficients (or standard errors) look too large</p></li>
<li><p>Model may be unstable</p></li>
</ul></li>
</ul>
</div>
<div id="linear-regression" class="section level3 hasAnchor" number="20.1.2">
<h3><span class="header-section-number">20.1.2</span> Linear regression<a href="supervised-learning-regression.html#linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><span class="math inline">\(y = β_0 + β_1 x_1 + β_2 x_2 + ...\)</span></p>
<ul>
<li><p><span class="math inline">\(y\)</span> is linearly related to each <span class="math inline">\(x_i\)</span></p></li>
<li><p>Each <span class="math inline">\(x_i\)</span> contributes additively to <span class="math inline">\(y\)</span></p></li>
</ul>
<p><strong>Linear Regression in R</strong></p>
<div class="sourceCode" id="cb2721"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2721-1"><a href="supervised-learning-regression.html#cb2721-1" aria-hidden="true" tabindex="-1"></a><span class="co"># lm() function</span></span>
<span id="cb2721-2"><a href="supervised-learning-regression.html#cb2721-2" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2..., data)</span>
<span id="cb2721-3"><a href="supervised-learning-regression.html#cb2721-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2721-4"><a href="supervised-learning-regression.html#cb2721-4" aria-hidden="true" tabindex="-1"></a><span class="co"># look at the model</span></span>
<span id="cb2721-5"><a href="supervised-learning-regression.html#cb2721-5" aria-hidden="true" tabindex="-1"></a>model</span>
<span id="cb2721-6"><a href="supervised-learning-regression.html#cb2721-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2721-7"><a href="supervised-learning-regression.html#cb2721-7" aria-hidden="true" tabindex="-1"></a><span class="co"># more information od the model</span></span>
<span id="cb2721-8"><a href="supervised-learning-regression.html#cb2721-8" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span>
<span id="cb2721-9"><a href="supervised-learning-regression.html#cb2721-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2721-10"><a href="supervised-learning-regression.html#cb2721-10" aria-hidden="true" tabindex="-1"></a>broom<span class="sc">::</span><span class="fu">glance</span>(cmodel)</span>
<span id="cb2721-11"><a href="supervised-learning-regression.html#cb2721-11" aria-hidden="true" tabindex="-1"></a>sigr<span class="sc">::</span><span class="fu">wrapFTest</span>(cmodel)</span></code></pre></div>
<div id="simple-regression" class="section level4 hasAnchor" number="20.1.2.1">
<h4><span class="header-section-number">20.1.2.1</span> Simple regression<a href="supervised-learning-regression.html#simple-regression" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><code>unemployment</code> given the rates of male and female unemployment in the United States over several years.</p>
<p>The task is to predict the rate of female unemployment from the observed rate of male unemployment. The outcome is <code>female_unemployment</code>, and the input is <code>male_unemployment</code>.</p>
<p>The sign of the variable coefficient tells you whether the outcome increases (+) or decreases (-) as the variable increases.</p>
<div class="sourceCode" id="cb2722"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2722-1"><a href="supervised-learning-regression.html#cb2722-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb2722-2"><a href="supervised-learning-regression.html#cb2722-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2722-3"><a href="supervised-learning-regression.html#cb2722-3" aria-hidden="true" tabindex="-1"></a>unemployment <span class="ot">&lt;-</span> <span class="fu">read_rds</span>(<span class="st">&quot;data/unemployment.rds&quot;</span>)</span>
<span id="cb2722-4"><a href="supervised-learning-regression.html#cb2722-4" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(unemployment)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    13 obs. of  2 variables:
##  $ male_unemployment  : num  2.9 6.7 4.9 7.9 9.8 ...
##  $ female_unemployment: num  4 7.4 5 7.2 7.9 ...</code></pre>
<div class="sourceCode" id="cb2724"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2724-1"><a href="supervised-learning-regression.html#cb2724-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the formula to fit a model: unemployment_model</span></span>
<span id="cb2724-2"><a href="supervised-learning-regression.html#cb2724-2" aria-hidden="true" tabindex="-1"></a>unemployment_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(female_unemployment <span class="sc">~</span> male_unemployment, unemployment)</span>
<span id="cb2724-3"><a href="supervised-learning-regression.html#cb2724-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2724-4"><a href="supervised-learning-regression.html#cb2724-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print it</span></span>
<span id="cb2724-5"><a href="supervised-learning-regression.html#cb2724-5" aria-hidden="true" tabindex="-1"></a>unemployment_model</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = female_unemployment ~ male_unemployment, data = unemployment)
## 
## Coefficients:
##       (Intercept)  male_unemployment  
##             1.434              0.695</code></pre>
<p>The coefficient for male unemployment is positive, so female unemployment increases as male unemployment does.</p>
</div>
<div id="examining-a-model" class="section level4 hasAnchor" number="20.1.2.2">
<h4><span class="header-section-number">20.1.2.2</span> Examining a model<a href="supervised-learning-regression.html#examining-a-model" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>There are a variety of different ways to examine a model; each way provides different information.</p>
<div class="sourceCode" id="cb2726"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2726-1"><a href="supervised-learning-regression.html#cb2726-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Call summary() on unemployment_model to get more details</span></span>
<span id="cb2726-2"><a href="supervised-learning-regression.html#cb2726-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(unemployment_model)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = female_unemployment ~ male_unemployment, data = unemployment)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -0.776 -0.341 -0.090  0.279  1.312 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)         1.4341     0.6034    2.38    0.037 *  
## male_unemployment   0.6945     0.0977    7.11  0.00002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.58 on 11 degrees of freedom
## Multiple R-squared:  0.821,  Adjusted R-squared:  0.805 
## F-statistic: 50.6 on 1 and 11 DF,  p-value: 0.0000197</code></pre>
<div class="sourceCode" id="cb2728"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2728-1"><a href="supervised-learning-regression.html#cb2728-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Call glance() on unemployment_model to see the details in a tidier form</span></span>
<span id="cb2728-2"><a href="supervised-learning-regression.html#cb2728-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb2728-3"><a href="supervised-learning-regression.html#cb2728-3" aria-hidden="true" tabindex="-1"></a><span class="fu">glance</span>(unemployment_model)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 12
##   r.squared adj.r.squared sigma statistic   p.value    df logLik   AIC   BIC
##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1     0.821         0.805 0.580      50.6 0.0000197     1  -10.3  26.6  28.3
## # ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;</code></pre>
<div class="sourceCode" id="cb2730"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2730-1"><a href="supervised-learning-regression.html#cb2730-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Call wrapFTest() on unemployment_model to see the most relevant details</span></span>
<span id="cb2730-2"><a href="supervised-learning-regression.html#cb2730-2" aria-hidden="true" tabindex="-1"></a>sigr<span class="sc">::</span><span class="fu">wrapFTest</span>(unemployment_model)</span></code></pre></div>
<pre><code>## [1] &quot;F Test summary: (R2=0.8213, F(1,11)=50.56, p=1.966e-05).&quot;</code></pre>
</div>
</div>
<div id="predicting-model" class="section level3 hasAnchor" number="20.1.3">
<h3><span class="header-section-number">20.1.3</span> Predicting model<a href="supervised-learning-regression.html#predicting-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>You will also use your model to predict on the new data in <code>newrates</code>, which consists of only one observation, where male unemployment is 5%.</p>
<p><code>predict(model, newdata)</code></p>
<div class="sourceCode" id="cb2732"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2732-1"><a href="supervised-learning-regression.html#cb2732-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(unemployment)</span></code></pre></div>
<pre><code>##  male_unemployment female_unemployment
##  Min.   :2.90      Min.   :4.00       
##  1st Qu.:4.90      1st Qu.:4.40       
##  Median :6.00      Median :5.20       
##  Mean   :5.95      Mean   :5.57       
##  3rd Qu.:6.70      3rd Qu.:6.10       
##  Max.   :9.80      Max.   :7.90</code></pre>
<p>Plot a scatterplot of <code>dframe$outcome</code> versus <code>dframe$pred</code> (pred on the x axis, outcome on the y axis), along with a <code>abine</code> where <code>outcome == pred</code>.</p>
<div class="sourceCode" id="cb2734"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2734-1"><a href="supervised-learning-regression.html#cb2734-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict female unemployment in the unemployment dataset</span></span>
<span id="cb2734-2"><a href="supervised-learning-regression.html#cb2734-2" aria-hidden="true" tabindex="-1"></a>unemployment<span class="sc">$</span>prediction <span class="ot">&lt;-</span>  <span class="fu">predict</span>(unemployment_model, unemployment)</span>
<span id="cb2734-3"><a href="supervised-learning-regression.html#cb2734-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2734-4"><a href="supervised-learning-regression.html#cb2734-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a plot to compare predictions to actual (prediction on x axis). </span></span>
<span id="cb2734-5"><a href="supervised-learning-regression.html#cb2734-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(unemployment, <span class="fu">aes</span>(<span class="at">x =</span> prediction, <span class="at">y =</span> female_unemployment)) <span class="sc">+</span> </span>
<span id="cb2734-6"><a href="supervised-learning-regression.html#cb2734-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb2734-7"><a href="supervised-learning-regression.html#cb2734-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">color =</span> <span class="st">&quot;blue&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-1035-1.png" width="672" /></p>
<div class="sourceCode" id="cb2735"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2735-1"><a href="supervised-learning-regression.html#cb2735-1" aria-hidden="true" tabindex="-1"></a>newrates <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">male_unemployment =</span> <span class="dv">5</span>)</span>
<span id="cb2735-2"><a href="supervised-learning-regression.html#cb2735-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2735-3"><a href="supervised-learning-regression.html#cb2735-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict female unemployment rate when male unemployment is 5%</span></span>
<span id="cb2735-4"><a href="supervised-learning-regression.html#cb2735-4" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(unemployment_model, newrates)</span></code></pre></div>
<pre><code>##    1 
## 4.91</code></pre>
<div id="multivariate-linear-regression" class="section level4 hasAnchor" number="20.1.3.1">
<h4><span class="header-section-number">20.1.3.1</span> Multivariate linear regression<a href="supervised-learning-regression.html#multivariate-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>you will work with the blood pressure dataset, and model <code>blood_pressure</code> as a function of <code>weight</code> and <code>age</code>.</p>
<div class="sourceCode" id="cb2737"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2737-1"><a href="supervised-learning-regression.html#cb2737-1" aria-hidden="true" tabindex="-1"></a>bloodpressure <span class="ot">&lt;-</span> <span class="fu">read_rds</span>(<span class="st">&quot;data/bloodpressure.rds&quot;</span>)</span>
<span id="cb2737-2"><a href="supervised-learning-regression.html#cb2737-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(bloodpressure)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    11 obs. of  3 variables:
##  $ blood_pressure: int  132 143 153 162 154 168 137 149 159 128 ...
##  $ age           : int  52 59 67 73 64 74 54 61 65 46 ...
##  $ weight        : int  173 184 194 211 196 220 188 188 207 167 ...</code></pre>
<div class="sourceCode" id="cb2739"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2739-1"><a href="supervised-learning-regression.html#cb2739-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(bloodpressure)</span></code></pre></div>
<pre><code>##  blood_pressure      age           weight   
##  Min.   :128    Min.   :46.0   Min.   :167  
##  1st Qu.:140    1st Qu.:56.5   1st Qu.:186  
##  Median :153    Median :64.0   Median :194  
##  Mean   :150    Mean   :62.5   Mean   :195  
##  3rd Qu.:160    3rd Qu.:69.5   3rd Qu.:209  
##  Max.   :168    Max.   :74.0   Max.   :220</code></pre>
<div class="sourceCode" id="cb2741"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2741-1"><a href="supervised-learning-regression.html#cb2741-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model: bloodpressure_model</span></span>
<span id="cb2741-2"><a href="supervised-learning-regression.html#cb2741-2" aria-hidden="true" tabindex="-1"></a>bloodpressure_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(blood_pressure <span class="sc">~</span> age <span class="sc">+</span> weight, bloodpressure)</span>
<span id="cb2741-3"><a href="supervised-learning-regression.html#cb2741-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2741-4"><a href="supervised-learning-regression.html#cb2741-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print bloodpressure_model and call summary() </span></span>
<span id="cb2741-5"><a href="supervised-learning-regression.html#cb2741-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(bloodpressure_model)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = blood_pressure ~ age + weight, data = bloodpressure)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -3.464 -1.195 -0.408  1.851  2.698 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)   30.994     11.944    2.59   0.0319 * 
## age            0.861      0.248    3.47   0.0084 **
## weight         0.335      0.131    2.56   0.0335 * 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.32 on 8 degrees of freedom
## Multiple R-squared:  0.977,  Adjusted R-squared:  0.971 
## F-statistic:  169 on 2 and 8 DF,  p-value: 0.000000287</code></pre>
<p>In this case the coefficients for both age and weight are positive, which indicates that bloodpressure tends to increase as both age and weight increase.</p>
<p>You will also compare the predictions to outcomes graphically.</p>
<div class="sourceCode" id="cb2743"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2743-1"><a href="supervised-learning-regression.html#cb2743-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict blood pressure using bloodpressure_model: prediction</span></span>
<span id="cb2743-2"><a href="supervised-learning-regression.html#cb2743-2" aria-hidden="true" tabindex="-1"></a>bloodpressure<span class="sc">$</span>prediction <span class="ot">&lt;-</span> <span class="fu">predict</span>(bloodpressure_model, bloodpressure)</span>
<span id="cb2743-3"><a href="supervised-learning-regression.html#cb2743-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2743-4"><a href="supervised-learning-regression.html#cb2743-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the results</span></span>
<span id="cb2743-5"><a href="supervised-learning-regression.html#cb2743-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(bloodpressure, <span class="fu">aes</span>(prediction, blood_pressure)) <span class="sc">+</span> </span>
<span id="cb2743-6"><a href="supervised-learning-regression.html#cb2743-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb2743-7"><a href="supervised-learning-regression.html#cb2743-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_abline</span>(<span class="at">color =</span> <span class="st">&quot;blue&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-1040-1.png" width="672" /></p>
<p>The results stay fairly close to the line of perfect prediction, indicating that the model fits the training data well. From a prediction perspective, multivariate linear regression behaves much as simple (one-variable) linear regression does.</p>
</div>
</div>
</div>
<div id="training-and-evaluating-models" class="section level2 hasAnchor" number="20.2">
<h2><span class="header-section-number">20.2</span> Training and Evaluating Models<a href="supervised-learning-regression.html#training-and-evaluating-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="graphically" class="section level3 hasAnchor" number="20.2.1">
<h3><span class="header-section-number">20.2.1</span> Graphically<a href="supervised-learning-regression.html#graphically" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="the-residual-plot" class="section level4 hasAnchor" number="20.2.1.1">
<h4><span class="header-section-number">20.2.1.1</span> The Residual Plot<a href="supervised-learning-regression.html#the-residual-plot" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Plot the model’s predictions against the actual value. Are the predictions near the <span class="math inline">\(x = y\)</span> line?</p>
<div class="sourceCode" id="cb2744"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2744-1"><a href="supervised-learning-regression.html#cb2744-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions from the model</span></span>
<span id="cb2744-2"><a href="supervised-learning-regression.html#cb2744-2" aria-hidden="true" tabindex="-1"></a>unemployment<span class="sc">$</span>predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(unemployment_model, unemployment)</span>
<span id="cb2744-3"><a href="supervised-learning-regression.html#cb2744-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2744-4"><a href="supervised-learning-regression.html#cb2744-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Fill in the blanks to plot predictions (on x-axis) versus the female_unemployment rates</span></span>
<span id="cb2744-5"><a href="supervised-learning-regression.html#cb2744-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(unemployment, <span class="fu">aes</span>(<span class="at">x =</span> predictions, <span class="at">y =</span> female_unemployment)) <span class="sc">+</span> </span>
<span id="cb2744-6"><a href="supervised-learning-regression.html#cb2744-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb2744-7"><a href="supervised-learning-regression.html#cb2744-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-1041-1.png" width="672" /></p>
<p>Plot predictions (on the x-axis) versus residuals (on the y-axis).</p>
<p>This gives you a different view of the model’s predictions as compared to ground truth.</p>
<div class="sourceCode" id="cb2745"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2745-1"><a href="supervised-learning-regression.html#cb2745-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate residuals</span></span>
<span id="cb2745-2"><a href="supervised-learning-regression.html#cb2745-2" aria-hidden="true" tabindex="-1"></a>unemployment<span class="sc">$</span>residuals <span class="ot">&lt;-</span> unemployment<span class="sc">$</span>female_unemployment <span class="sc">-</span> unemployment<span class="sc">$</span>predictions</span>
<span id="cb2745-3"><a href="supervised-learning-regression.html#cb2745-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2745-4"><a href="supervised-learning-regression.html#cb2745-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Fill in the blanks to plot predictions (on x-axis) versus the residuals</span></span>
<span id="cb2745-5"><a href="supervised-learning-regression.html#cb2745-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(unemployment, <span class="fu">aes</span>(<span class="at">x =</span> predictions, <span class="at">y =</span> residuals)) <span class="sc">+</span> </span>
<span id="cb2745-6"><a href="supervised-learning-regression.html#cb2745-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_pointrange</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> <span class="dv">0</span>, <span class="at">ymax =</span> residuals)) <span class="sc">+</span> </span>
<span id="cb2745-7"><a href="supervised-learning-regression.html#cb2745-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="dv">3</span>) <span class="sc">+</span> </span>
<span id="cb2745-8"><a href="supervised-learning-regression.html#cb2745-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;residuals vs. linear model prediction&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-1042-1.png" width="672" /></p>
</div>
<div id="the-gain-curve" class="section level4 hasAnchor" number="20.2.1.2">
<h4><span class="header-section-number">20.2.1.2</span> The Gain Curve<a href="supervised-learning-regression.html#the-gain-curve" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Now, you will also plot the gain curve of the <code>unemployment_model</code>’s predictions against actual <code>female_unemployment</code> using the <code>WVPlots::GainCurvePlot()</code> function.</p>
<p><code>GainCurvePlot(frame, xvar, truthvar, title)</code></p>
<ul>
<li><p><code>xvar</code> = “prediction”</p></li>
<li><p><code>truthvar</code> = “actual outcome”</p></li>
<li><p><code>title</code> = title of the plot</p></li>
</ul>
<p><strong>Relative gini coefficient</strong></p>
<ul>
<li><p>When the predictions sort in exactly the same order, the relative Gini coefficient is 1.</p></li>
<li><p>When the model sorts poorly, the relative Gini coefficient is close to zero, or even negative.</p></li>
<li><p>Wizard curve: perfect model, 藍線越接近綠線越好</p></li>
</ul>
<div class="sourceCode" id="cb2746"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2746-1"><a href="supervised-learning-regression.html#cb2746-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the package WVPlots</span></span>
<span id="cb2746-2"><a href="supervised-learning-regression.html#cb2746-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(WVPlots)</span>
<span id="cb2746-3"><a href="supervised-learning-regression.html#cb2746-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2746-4"><a href="supervised-learning-regression.html#cb2746-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the Gain Curve</span></span>
<span id="cb2746-5"><a href="supervised-learning-regression.html#cb2746-5" aria-hidden="true" tabindex="-1"></a><span class="fu">GainCurvePlot</span>(unemployment, <span class="st">&quot;predictions&quot;</span>, <span class="st">&quot;female_unemployment&quot;</span>, <span class="st">&quot;Unemployment model&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-1043-1.png" width="672" /></p>
<p>A relative gini coefficient close to one shows that the model correctly sorts high unemployment situations from lower ones.</p>
</div>
</div>
<div id="root-mean-squared-error" class="section level3 hasAnchor" number="20.2.2">
<h3><span class="header-section-number">20.2.2</span> Root Mean Squared Error<a href="supervised-learning-regression.html#root-mean-squared-error" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>RMSE</strong></p>
<p><span class="math inline">\(RMSE = \sqrt{\overline{(pred − y)^2}}\)</span></p>
<ul>
<li><p><span class="math inline">\(pred − y\)</span> : the error, or residuals vector = <span class="math inline">\(res\)</span></p></li>
<li><p><span class="math inline">\(\overline{(pred − y)^2}\)</span> : mean value of <span class="math inline">\((pred − y)^2\)</span></p></li>
</ul>
<p>One way to evaluate the RMSE is to compare it to the standard deviation of the outcome. With a good model, the RMSE should be smaller.</p>
<div class="sourceCode" id="cb2747"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2747-1"><a href="supervised-learning-regression.html#cb2747-1" aria-hidden="true" tabindex="-1"></a><span class="co"># For convenience put the residuals in the variable res</span></span>
<span id="cb2747-2"><a href="supervised-learning-regression.html#cb2747-2" aria-hidden="true" tabindex="-1"></a>res <span class="ot">&lt;-</span> unemployment<span class="sc">$</span>residuals</span>
<span id="cb2747-3"><a href="supervised-learning-regression.html#cb2747-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2747-4"><a href="supervised-learning-regression.html#cb2747-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate RMSE, assign it to the variable rmse and print it</span></span>
<span id="cb2747-5"><a href="supervised-learning-regression.html#cb2747-5" aria-hidden="true" tabindex="-1"></a>rmse <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(res<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb2747-6"><a href="supervised-learning-regression.html#cb2747-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2747-7"><a href="supervised-learning-regression.html#cb2747-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the standard deviation of female_unemployment and print it</span></span>
<span id="cb2747-8"><a href="supervised-learning-regression.html#cb2747-8" aria-hidden="true" tabindex="-1"></a>sd_unemployment <span class="ot">&lt;-</span> <span class="fu">sd</span>(unemployment<span class="sc">$</span>female_unemployment)</span>
<span id="cb2747-9"><a href="supervised-learning-regression.html#cb2747-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2747-10"><a href="supervised-learning-regression.html#cb2747-10" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">rmse =</span> rmse, <span class="at">sd =</span> sd_unemployment)</span></code></pre></div>
<pre><code>##  rmse    sd 
## 0.534 1.314</code></pre>
<p>An RMSE much smaller than the outcome’s standard deviation suggests a model that predicts well.</p>
</div>
<div id="r-squared" class="section level3 hasAnchor" number="20.2.3">
<h3><span class="header-section-number">20.2.3</span> R-squared<a href="supervised-learning-regression.html#r-squared" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<dl>
<dt>R-squared (<span class="math inline">\(R^2\)</span>)</dt>
<dd>
<p>A measure of how well the model fits or explains the data.</p>
</dd>
</dl>
<ul>
<li><p>A value between 0-1</p>
<ul>
<li><p>near 1: model fits well</p></li>
<li><p>near 0: no better than guessing the average value</p></li>
</ul></li>
</ul>
<p>Calculating: the variance explained by the model</p>
<p><span class="math inline">\(R^2 = 1 - \frac{RSS}{SS_{Tot}}\)</span></p>
<ul>
<li><p><span class="math inline">\(RSS = \sum{(y - prediction)^2}\)</span></p>
<ul>
<li>Residual sum of squares (variance from model)</li>
</ul></li>
<li><p><span class="math inline">\(SS_{Tot} = \sum{(y - \overline{y})^2}\)</span></p>
<ul>
<li>Total sum of squares (variance of data)</li>
</ul></li>
</ul>
<p><strong>Correlation and</strong> <span class="math inline">\(R^2\)</span></p>
<ul>
<li><p><span class="math inline">\(ρ\)</span> = <code>cor(predict, actual)</code></p></li>
<li><p><span class="math inline">\(ρ^2\)</span>= <span class="math inline">\(R^2\)</span></p></li>
</ul>
<div id="calculate-r-squared" class="section level4 hasAnchor" number="20.2.3.1">
<h4><span class="header-section-number">20.2.3.1</span> Calculate R-squared<a href="supervised-learning-regression.html#calculate-r-squared" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>You will examine how well the model fits the data: that is, how much variance does it explain.</p>
<div class="sourceCode" id="cb2749"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2749-1"><a href="supervised-learning-regression.html#cb2749-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate and print the mean female_unemployment: fe_mean</span></span>
<span id="cb2749-2"><a href="supervised-learning-regression.html#cb2749-2" aria-hidden="true" tabindex="-1"></a>fe_mean <span class="ot">&lt;-</span> <span class="fu">mean</span>(unemployment<span class="sc">$</span>female_unemployment)</span>
<span id="cb2749-3"><a href="supervised-learning-regression.html#cb2749-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2749-4"><a href="supervised-learning-regression.html#cb2749-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate and print the total sum of squares: tss</span></span>
<span id="cb2749-5"><a href="supervised-learning-regression.html#cb2749-5" aria-hidden="true" tabindex="-1"></a>tss <span class="ot">&lt;-</span> <span class="fu">sum</span>((unemployment<span class="sc">$</span>female_unemployment <span class="sc">-</span> fe_mean)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb2749-6"><a href="supervised-learning-regression.html#cb2749-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2749-7"><a href="supervised-learning-regression.html#cb2749-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate and print residual sum of squares: rss</span></span>
<span id="cb2749-8"><a href="supervised-learning-regression.html#cb2749-8" aria-hidden="true" tabindex="-1"></a>rss <span class="ot">&lt;-</span> <span class="fu">sum</span>(unemployment<span class="sc">$</span>residuals<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb2749-9"><a href="supervised-learning-regression.html#cb2749-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2749-10"><a href="supervised-learning-regression.html#cb2749-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate and print the R-squared: rsq</span></span>
<span id="cb2749-11"><a href="supervised-learning-regression.html#cb2749-11" aria-hidden="true" tabindex="-1"></a>rsq <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> rss <span class="sc">/</span> tss</span>
<span id="cb2749-12"><a href="supervised-learning-regression.html#cb2749-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2749-13"><a href="supervised-learning-regression.html#cb2749-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Get R-squared from glance and print it</span></span>
<span id="cb2749-14"><a href="supervised-learning-regression.html#cb2749-14" aria-hidden="true" tabindex="-1"></a>rsq_glance <span class="ot">&lt;-</span> <span class="fu">glance</span>(unemployment_model)<span class="sc">$</span>r.squared</span>
<span id="cb2749-15"><a href="supervised-learning-regression.html#cb2749-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2749-16"><a href="supervised-learning-regression.html#cb2749-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Is it the same as what you calculated?</span></span>
<span id="cb2749-17"><a href="supervised-learning-regression.html#cb2749-17" aria-hidden="true" tabindex="-1"></a><span class="fu">list</span>(<span class="at">rsq_calculate =</span> rsq, <span class="at">rsq_glance =</span> rsq_glance)</span></code></pre></div>
<pre><code>## $rsq_calculate
## [1] 0.821
## 
## $rsq_glance
## [1] 0.821</code></pre>
<p>An R-squared close to one suggests a model that predicts well.</p>
</div>
<div id="correlation-and-r-squared" class="section level4 hasAnchor" number="20.2.3.2">
<h4><span class="header-section-number">20.2.3.2</span> Correlation and R-squared<a href="supervised-learning-regression.html#correlation-and-r-squared" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The linear correlation of two variables, x and y, measures the strength of the linear relationship between them. When x and y are respectively:</p>
<ul>
<li><p>the outcomes of a regression model that minimizes squared-error (like linear regression) and</p></li>
<li><p>the true outcomes of the training data,</p></li>
</ul>
<p>then the square of the correlation is the same as <span class="math inline">\(R^2\)</span>.</p>
<div class="sourceCode" id="cb2751"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2751-1"><a href="supervised-learning-regression.html#cb2751-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the correlation between the prediction and true outcome: rho and print it</span></span>
<span id="cb2751-2"><a href="supervised-learning-regression.html#cb2751-2" aria-hidden="true" tabindex="-1"></a>(rho <span class="ot">&lt;-</span> <span class="fu">cor</span>(unemployment<span class="sc">$</span>predictions, unemployment<span class="sc">$</span>female_unemployment))</span></code></pre></div>
<pre><code>## [1] 0.906</code></pre>
<div class="sourceCode" id="cb2753"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2753-1"><a href="supervised-learning-regression.html#cb2753-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Square rho: rho2 and print it</span></span>
<span id="cb2753-2"><a href="supervised-learning-regression.html#cb2753-2" aria-hidden="true" tabindex="-1"></a>(rho2 <span class="ot">&lt;-</span> rho<span class="sc">^</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 0.821</code></pre>
<div class="sourceCode" id="cb2755"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2755-1"><a href="supervised-learning-regression.html#cb2755-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get R-squared from glance and print it</span></span>
<span id="cb2755-2"><a href="supervised-learning-regression.html#cb2755-2" aria-hidden="true" tabindex="-1"></a>(rsq_glance <span class="ot">&lt;-</span> <span class="fu">glance</span>(unemployment_model)<span class="sc">$</span>r.squared)</span></code></pre></div>
<pre><code>## [1] 0.821</code></pre>
<p>Remember this equivalence is only true for the training data, and only for models that minimize squared error.</p>
</div>
</div>
<div id="training-a-model" class="section level3 hasAnchor" number="20.2.4">
<h3><span class="header-section-number">20.2.4</span> Training a Model<a href="supervised-learning-regression.html#training-a-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Test/Train Split</strong></p>
<ul>
<li>Recommended method when data is plentiful</li>
</ul>
<p><strong>Cross-Validation</strong></p>
<ul>
<li>Preferred when data is not large enough to split off a test set</li>
</ul>
<div class="sourceCode" id="cb2757"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2757-1"><a href="supervised-learning-regression.html#cb2757-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(vtreat)</span>
<span id="cb2757-2"><a href="supervised-learning-regression.html#cb2757-2" aria-hidden="true" tabindex="-1"></a>splitPlan <span class="ot">&lt;-</span> <span class="fu">kWayCrossValidation</span>(nRows, nSplits, <span class="cn">NULL</span>, <span class="cn">NULL</span>)</span></code></pre></div>
<ul>
<li><p><code>nRows</code> : number of rows in the training data</p></li>
<li><p><code>nSplits</code> : number folds (partitions) in the cross-validation</p>
<ul>
<li>e.g, nfolds = 3 for 3-way cross-validation</li>
</ul></li>
</ul>
<div id="generate-a-random-testtrain-split" class="section level4 hasAnchor" number="20.2.4.1">
<h4><span class="header-section-number">20.2.4.1</span> Generate a random test/train split<a href="supervised-learning-regression.html#generate-a-random-testtrain-split" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><code>mpg</code> describes the characteristics of several makes and models of cars from different years. The goal is to predict city fuel efficiency from highway fuel efficiency.</p>
<p>n this exercise, you will split mpg into a training set mpg_train (75% of the data) and a test set mpg_test (25% of the data).</p>
<p>One way to do this is to generate a column of uniform random numbers between <code>0</code> and <code>1</code>, using the function <code>runif()</code>.</p>
<ol style="list-style-type: decimal">
<li><p>Generate a vector of uniform random numbers: <code>gp = runif(N)</code>. (N = data sample size)</p></li>
<li><p><code>dframe[gp &lt; X,]</code> will be about the right size.</p></li>
<li><p><code>dframe[gp &gt;= X,]</code> will be the complement.</p></li>
</ol>
<div class="sourceCode" id="cb2758"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2758-1"><a href="supervised-learning-regression.html#cb2758-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(mpg)</span></code></pre></div>
<pre><code>## Rows: 234
## Columns: 13
## $ manufacturer &lt;chr&gt; &quot;audi&quot;, &quot;audi&quot;, &quot;audi&quot;, &quot;audi&quot;, &quot;audi&quot;, &quot;audi&quot;, &quot;audi&quot;, &quot;…
## $ model        &lt;chr&gt; &quot;a4&quot;, &quot;a4&quot;, &quot;a4&quot;, &quot;a4&quot;, &quot;a4&quot;, &quot;a4&quot;, &quot;a4&quot;, &quot;a4 quattro&quot;, &quot;…
## $ displ        &lt;dbl&gt; 1.8, 1.8, 2.0, 2.0, 2.8, 2.8, 3.1, 1.8, 1.8, 2.0, 2.0, 2.…
## $ year         &lt;int&gt; 1999, 1999, 2008, 2008, 1999, 1999, 2008, 1999, 1999, 200…
## $ cyl          &lt;int&gt; 4, 4, 4, 4, 6, 6, 6, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, …
## $ trans        &lt;chr&gt; &quot;auto(l5)&quot;, &quot;manual(m5)&quot;, &quot;manual(m6)&quot;, &quot;auto(av)&quot;, &quot;auto…
## $ drv          &lt;chr&gt; &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;4&quot;, &quot;4&quot;, &quot;4&quot;, &quot;4&quot;, &quot;4…
## $ cty          &lt;int&gt; 18, 21, 20, 21, 16, 18, 18, 18, 16, 20, 19, 15, 17, 17, 1…
## $ hwy          &lt;int&gt; 29, 29, 31, 30, 26, 26, 27, 26, 25, 28, 27, 25, 25, 25, 2…
## $ fl           &lt;chr&gt; &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p…
## $ class        &lt;chr&gt; &quot;compact&quot;, &quot;compact&quot;, &quot;compact&quot;, &quot;compact&quot;, &quot;compact&quot;, &quot;c…
## $ pred.cv      &lt;dbl&gt; 20.8, 20.8, 22.2, 21.3, 18.5, 18.6, 19.2, 18.6, 17.8, 19.…
## $ pred         &lt;dbl&gt; 20.7, 20.7, 22.0, 21.3, 18.6, 18.6, 19.3, 18.6, 17.9, 20.…</code></pre>
<div class="sourceCode" id="cb2760"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2760-1"><a href="supervised-learning-regression.html#cb2760-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use nrow to get the number of rows in mpg (N) and print it</span></span>
<span id="cb2760-2"><a href="supervised-learning-regression.html#cb2760-2" aria-hidden="true" tabindex="-1"></a>(N <span class="ot">&lt;-</span> <span class="fu">nrow</span>(mpg))</span></code></pre></div>
<pre><code>## [1] 234</code></pre>
<div class="sourceCode" id="cb2762"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2762-1"><a href="supervised-learning-regression.html#cb2762-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate how many rows 75% of N should be and print it</span></span>
<span id="cb2762-2"><a href="supervised-learning-regression.html#cb2762-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Hint: use round() to get an integer</span></span>
<span id="cb2762-3"><a href="supervised-learning-regression.html#cb2762-3" aria-hidden="true" tabindex="-1"></a>(target <span class="ot">&lt;-</span> <span class="fu">round</span>(N <span class="sc">*</span> <span class="fl">0.75</span>))</span></code></pre></div>
<pre><code>## [1] 176</code></pre>
<div class="sourceCode" id="cb2764"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2764-1"><a href="supervised-learning-regression.html#cb2764-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the vector of N uniform random variables: gp</span></span>
<span id="cb2764-2"><a href="supervised-learning-regression.html#cb2764-2" aria-hidden="true" tabindex="-1"></a>gp <span class="ot">&lt;-</span> <span class="fu">runif</span>(N)</span>
<span id="cb2764-3"><a href="supervised-learning-regression.html#cb2764-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2764-4"><a href="supervised-learning-regression.html#cb2764-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Use gp to create the training set: mpg_train (75% of data) and mpg_test (25% of data)</span></span>
<span id="cb2764-5"><a href="supervised-learning-regression.html#cb2764-5" aria-hidden="true" tabindex="-1"></a>mpg_train <span class="ot">&lt;-</span> mpg[gp <span class="sc">&lt;</span> <span class="fl">0.75</span>, ]</span>
<span id="cb2764-6"><a href="supervised-learning-regression.html#cb2764-6" aria-hidden="true" tabindex="-1"></a>mpg_test <span class="ot">&lt;-</span> mpg[gp <span class="sc">&gt;=</span> <span class="fl">0.75</span>, ]</span>
<span id="cb2764-7"><a href="supervised-learning-regression.html#cb2764-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2764-8"><a href="supervised-learning-regression.html#cb2764-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Use nrow() to examine mpg_train and mpg_test</span></span>
<span id="cb2764-9"><a href="supervised-learning-regression.html#cb2764-9" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">train_n =</span> <span class="fu">nrow</span>(mpg_train), <span class="at">test_n =</span> <span class="fu">nrow</span>(mpg_test))</span></code></pre></div>
<pre><code>## train_n  test_n 
##     180      54</code></pre>
<p>A random split won’t always produce sets of exactly X% and (100-X)% of the data, but it should be close.</p>
</div>
<div id="train-a-model-using-testtrain-split" class="section level4 hasAnchor" number="20.2.4.2">
<h4><span class="header-section-number">20.2.4.2</span> Train a model using test/train split<a href="supervised-learning-regression.html#train-a-model-using-testtrain-split" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>You will use <code>mpg_train</code> to train a model to predict city fuel efficiency (<code>cty</code>) from highway fuel efficiency (<code>hwy</code>).</p>
<div class="sourceCode" id="cb2766"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2766-1"><a href="supervised-learning-regression.html#cb2766-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Now use lm() to build a model mpg_model from mpg_train that predicts cty from hwy </span></span>
<span id="cb2766-2"><a href="supervised-learning-regression.html#cb2766-2" aria-hidden="true" tabindex="-1"></a>mpg_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(cty <span class="sc">~</span> hwy, mpg_train)</span>
<span id="cb2766-3"><a href="supervised-learning-regression.html#cb2766-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2766-4"><a href="supervised-learning-regression.html#cb2766-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Use summary() to examine the model</span></span>
<span id="cb2766-5"><a href="supervised-learning-regression.html#cb2766-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mpg_model)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = cty ~ hwy, data = mpg_train)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.8862 -0.7400  0.0108  0.7051  2.5889 
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)   0.7766     0.3551    2.19                0.03 *  
## hwy           0.6844     0.0147   46.62 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.15 on 178 degrees of freedom
## Multiple R-squared:  0.924,  Adjusted R-squared:  0.924 
## F-statistic: 2.17e+03 on 1 and 178 DF,  p-value: &lt;0.0000000000000002</code></pre>
</div>
<div id="evaluate-model-using-testtrain-split" class="section level4 hasAnchor" number="20.2.4.3">
<h4><span class="header-section-number">20.2.4.3</span> Evaluate model using test/train split<a href="supervised-learning-regression.html#evaluate-model-using-testtrain-split" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Now you will test the model <code>mpg_model</code> on the test data, <code>mpg_test</code>.</p>
<p>Functions <code>rmse()</code> and <code>r_squared()</code> to calculate RMSE and R-squared</p>
<div class="sourceCode" id="cb2768"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2768-1"><a href="supervised-learning-regression.html#cb2768-1" aria-hidden="true" tabindex="-1"></a><span class="co"># function rmse, </span></span>
<span id="cb2768-2"><a href="supervised-learning-regression.html#cb2768-2" aria-hidden="true" tabindex="-1"></a><span class="co"># predcol: The predicted values, ycol: The actual outcome</span></span>
<span id="cb2768-3"><a href="supervised-learning-regression.html#cb2768-3" aria-hidden="true" tabindex="-1"></a>rmse <span class="ot">&lt;-</span> <span class="cf">function</span>(predcol, ycol) {</span>
<span id="cb2768-4"><a href="supervised-learning-regression.html#cb2768-4" aria-hidden="true" tabindex="-1"></a>  res <span class="ot">=</span> predcol<span class="sc">-</span>ycol</span>
<span id="cb2768-5"><a href="supervised-learning-regression.html#cb2768-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sqrt</span>(<span class="fu">mean</span>(res<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb2768-6"><a href="supervised-learning-regression.html#cb2768-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2768-7"><a href="supervised-learning-regression.html#cb2768-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2768-8"><a href="supervised-learning-regression.html#cb2768-8" aria-hidden="true" tabindex="-1"></a><span class="co"># function r_squared</span></span>
<span id="cb2768-9"><a href="supervised-learning-regression.html#cb2768-9" aria-hidden="true" tabindex="-1"></a>r_squared <span class="ot">&lt;-</span> <span class="cf">function</span>(predcol, ycol) {</span>
<span id="cb2768-10"><a href="supervised-learning-regression.html#cb2768-10" aria-hidden="true" tabindex="-1"></a>  tss <span class="ot">=</span> <span class="fu">sum</span>( (ycol <span class="sc">-</span> <span class="fu">mean</span>(ycol))<span class="sc">^</span><span class="dv">2</span> )</span>
<span id="cb2768-11"><a href="supervised-learning-regression.html#cb2768-11" aria-hidden="true" tabindex="-1"></a>  rss <span class="ot">=</span> <span class="fu">sum</span>( (predcol <span class="sc">-</span> ycol)<span class="sc">^</span><span class="dv">2</span> )</span>
<span id="cb2768-12"><a href="supervised-learning-regression.html#cb2768-12" aria-hidden="true" tabindex="-1"></a>  <span class="dv">1</span> <span class="sc">-</span> rss<span class="sc">/</span>tss</span>
<span id="cb2768-13"><a href="supervised-learning-regression.html#cb2768-13" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Evaluate RMSE for both the test and training sets.</p>
<div class="sourceCode" id="cb2769"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2769-1"><a href="supervised-learning-regression.html#cb2769-1" aria-hidden="true" tabindex="-1"></a><span class="co"># predict cty from hwy for the training set</span></span>
<span id="cb2769-2"><a href="supervised-learning-regression.html#cb2769-2" aria-hidden="true" tabindex="-1"></a>mpg_train<span class="sc">$</span>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(mpg_model, mpg_train)</span>
<span id="cb2769-3"><a href="supervised-learning-regression.html#cb2769-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2769-4"><a href="supervised-learning-regression.html#cb2769-4" aria-hidden="true" tabindex="-1"></a><span class="co"># predict cty from hwy for the test set</span></span>
<span id="cb2769-5"><a href="supervised-learning-regression.html#cb2769-5" aria-hidden="true" tabindex="-1"></a>mpg_test<span class="sc">$</span>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(mpg_model, mpg_test)</span>
<span id="cb2769-6"><a href="supervised-learning-regression.html#cb2769-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2769-7"><a href="supervised-learning-regression.html#cb2769-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the rmse on both training and test data and print them</span></span>
<span id="cb2769-8"><a href="supervised-learning-regression.html#cb2769-8" aria-hidden="true" tabindex="-1"></a>rmse_train <span class="ot">&lt;-</span> <span class="fu">rmse</span>(mpg_train<span class="sc">$</span>pred, mpg_train<span class="sc">$</span>cty)</span>
<span id="cb2769-9"><a href="supervised-learning-regression.html#cb2769-9" aria-hidden="true" tabindex="-1"></a>rmse_test <span class="ot">&lt;-</span> <span class="fu">rmse</span>(mpg_test<span class="sc">$</span>pred, mpg_test<span class="sc">$</span>cty)</span>
<span id="cb2769-10"><a href="supervised-learning-regression.html#cb2769-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2769-11"><a href="supervised-learning-regression.html#cb2769-11" aria-hidden="true" tabindex="-1"></a><span class="fu">list</span>(<span class="at">rmse_train =</span> rmse_train, <span class="at">rmse_test =</span> rmse_test)</span></code></pre></div>
<pre><code>## $rmse_train
## [1] 1.14
## 
## $rmse_test
## [1] 1.55</code></pre>
<p>Evaluate r-squared for both the test and training sets.</p>
<div class="sourceCode" id="cb2771"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2771-1"><a href="supervised-learning-regression.html#cb2771-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the r-squared on both training and test data.and print them</span></span>
<span id="cb2771-2"><a href="supervised-learning-regression.html#cb2771-2" aria-hidden="true" tabindex="-1"></a>rsq_train <span class="ot">&lt;-</span> <span class="fu">r_squared</span>(mpg_train<span class="sc">$</span>pred, mpg_train<span class="sc">$</span>cty)</span>
<span id="cb2771-3"><a href="supervised-learning-regression.html#cb2771-3" aria-hidden="true" tabindex="-1"></a>rsq_test <span class="ot">&lt;-</span> <span class="fu">r_squared</span>(mpg_test<span class="sc">$</span>pred, mpg_test<span class="sc">$</span>cty)</span>
<span id="cb2771-4"><a href="supervised-learning-regression.html#cb2771-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2771-5"><a href="supervised-learning-regression.html#cb2771-5" aria-hidden="true" tabindex="-1"></a><span class="fu">list</span>(<span class="at">rsq_train =</span> rsq_train, <span class="at">rsq_test =</span> rsq_test)</span></code></pre></div>
<pre><code>## $rsq_train
## [1] 0.924
## 
## $rsq_test
## [1] 0.885</code></pre>
<p>Plot test data.</p>
<div class="sourceCode" id="cb2773"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2773-1"><a href="supervised-learning-regression.html#cb2773-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the predictions (on the x-axis) against the outcome (cty) on the test data</span></span>
<span id="cb2773-2"><a href="supervised-learning-regression.html#cb2773-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(mpg_test, <span class="fu">aes</span>(<span class="at">x =</span> pred, <span class="at">y =</span> cty)) <span class="sc">+</span> </span>
<span id="cb2773-3"><a href="supervised-learning-regression.html#cb2773-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb2773-4"><a href="supervised-learning-regression.html#cb2773-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-1053-1.png" width="672" /></p>
<p>Good performance on the test data is more confirmation that the model works as expected.</p>
</div>
<div id="create-a-cross-validation-plan" class="section level4 hasAnchor" number="20.2.4.4">
<h4><span class="header-section-number">20.2.4.4</span> Create a cross validation plan<a href="supervised-learning-regression.html#create-a-cross-validation-plan" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>n-fold cross validation plan from <code>vtreat</code> package:</p>
<p><code>splitPlan &lt;- kWayCrossValidation(nRows, nSplits, dframe, y)</code></p>
<ul>
<li><p><code>nRows</code> is the number of rows of data to be split.</p></li>
<li><p><code>nSplits</code> is the desired number of cross-validation folds.</p></li>
<li><p><code>dframe</code> and <code>y</code> : set them both to <code>NULL</code>. they are for compatibility with other <code>vtreat</code> data partitioning functions.</p></li>
</ul>
<p>The resulting <code>splitPlan</code> is a list of <code>nSplits</code> elements; each element contains two vectors:</p>
<ul>
<li><p><code>train</code>: the indices of <code>dframe</code> that will form the training set</p></li>
<li><p><code>app</code>: the indices of <code>dframe</code> that will form the test (or application) set</p></li>
</ul>
<div class="sourceCode" id="cb2774"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2774-1"><a href="supervised-learning-regression.html#cb2774-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the package vtreat</span></span>
<span id="cb2774-2"><a href="supervised-learning-regression.html#cb2774-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(vtreat)</span></code></pre></div>
<pre><code>## 
## Attaching package: &#39;vtreat&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:infer&#39;:
## 
##     fit</code></pre>
<div class="sourceCode" id="cb2777"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2777-1"><a href="supervised-learning-regression.html#cb2777-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the number of rows in mpg</span></span>
<span id="cb2777-2"><a href="supervised-learning-regression.html#cb2777-2" aria-hidden="true" tabindex="-1"></a>nRows <span class="ot">&lt;-</span> <span class="fu">nrow</span>(mpg)</span>
<span id="cb2777-3"><a href="supervised-learning-regression.html#cb2777-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2777-4"><a href="supervised-learning-regression.html#cb2777-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Implement the 3-fold cross-fold plan with vtreat</span></span>
<span id="cb2777-5"><a href="supervised-learning-regression.html#cb2777-5" aria-hidden="true" tabindex="-1"></a>splitPlan <span class="ot">&lt;-</span> <span class="fu">kWayCrossValidation</span>(nRows, <span class="dv">3</span>, <span class="cn">NULL</span>, <span class="cn">NULL</span>)</span>
<span id="cb2777-6"><a href="supervised-learning-regression.html#cb2777-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2777-7"><a href="supervised-learning-regression.html#cb2777-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Examine the split plan</span></span>
<span id="cb2777-8"><a href="supervised-learning-regression.html#cb2777-8" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(splitPlan)</span></code></pre></div>
<pre><code>## List of 3
##  $ :List of 2
##   ..$ train: int [1:156] 4 5 6 7 8 9 10 11 13 14 ...
##   ..$ app  : int [1:78] 81 134 206 77 12 69 195 127 26 23 ...
##  $ :List of 2
##   ..$ train: int [1:156] 1 2 3 5 7 9 10 11 12 14 ...
##   ..$ app  : int [1:78] 79 98 198 138 80 56 186 156 101 39 ...
##  $ :List of 2
##   ..$ train: int [1:156] 1 2 3 4 6 8 12 13 17 19 ...
##   ..$ app  : int [1:78] 209 16 100 54 175 147 196 162 124 122 ...
##  - attr(*, &quot;splitmethod&quot;)= chr &quot;kwaycross&quot;</code></pre>
</div>
<div id="evaluate-a-modeling-procedure-using-n-fold-cross-validation" class="section level4 hasAnchor" number="20.2.4.5">
<h4><span class="header-section-number">20.2.4.5</span> Evaluate a modeling procedure using n-fold cross-validation<a href="supervised-learning-regression.html#evaluate-a-modeling-procedure-using-n-fold-cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>If <code>dframe</code> is the training data, then one way to add a column of cross-validation predictions to the frame:</p>
<div class="sourceCode" id="cb2779"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2779-1"><a href="supervised-learning-regression.html#cb2779-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize a column of the appropriate length</span></span>
<span id="cb2779-2"><a href="supervised-learning-regression.html#cb2779-2" aria-hidden="true" tabindex="-1"></a>dframe<span class="sc">$</span>pred.cv <span class="ot">&lt;-</span> <span class="dv">0</span> </span>
<span id="cb2779-3"><a href="supervised-learning-regression.html#cb2779-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2779-4"><a href="supervised-learning-regression.html#cb2779-4" aria-hidden="true" tabindex="-1"></a><span class="co"># k is the number of folds</span></span>
<span id="cb2779-5"><a href="supervised-learning-regression.html#cb2779-5" aria-hidden="true" tabindex="-1"></a><span class="co"># splitPlan is the cross validation plan</span></span>
<span id="cb2779-6"><a href="supervised-learning-regression.html#cb2779-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2779-7"><a href="supervised-learning-regression.html#cb2779-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>k) {</span>
<span id="cb2779-8"><a href="supervised-learning-regression.html#cb2779-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Get the ith split</span></span>
<span id="cb2779-9"><a href="supervised-learning-regression.html#cb2779-9" aria-hidden="true" tabindex="-1"></a>  split <span class="ot">&lt;-</span> splitPlan[[i]]</span>
<span id="cb2779-10"><a href="supervised-learning-regression.html#cb2779-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2779-11"><a href="supervised-learning-regression.html#cb2779-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Build a model on the training data </span></span>
<span id="cb2779-12"><a href="supervised-learning-regression.html#cb2779-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># from this split </span></span>
<span id="cb2779-13"><a href="supervised-learning-regression.html#cb2779-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># (lm, in this case)</span></span>
<span id="cb2779-14"><a href="supervised-learning-regression.html#cb2779-14" aria-hidden="true" tabindex="-1"></a>  model <span class="ot">&lt;-</span> <span class="fu">lm</span>(fmla, <span class="at">data =</span> dframe[split<span class="sc">$</span>train,])</span>
<span id="cb2779-15"><a href="supervised-learning-regression.html#cb2779-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2779-16"><a href="supervised-learning-regression.html#cb2779-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># make predictions on the </span></span>
<span id="cb2779-17"><a href="supervised-learning-regression.html#cb2779-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># application data from this split</span></span>
<span id="cb2779-18"><a href="supervised-learning-regression.html#cb2779-18" aria-hidden="true" tabindex="-1"></a>  dframe<span class="sc">$</span>pred.cv[split<span class="sc">$</span>app] <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, <span class="at">newdata =</span> dframe[split<span class="sc">$</span>app,])</span>
<span id="cb2779-19"><a href="supervised-learning-regression.html#cb2779-19" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Run the 3-fold cross validation plan from <code>splitPlan</code> and put the predictions in the column <code>mpg$pred.cv</code>.</p>
<div class="sourceCode" id="cb2780"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2780-1"><a href="supervised-learning-regression.html#cb2780-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the 3-fold cross validation plan from splitPlan</span></span>
<span id="cb2780-2"><a href="supervised-learning-regression.html#cb2780-2" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">3</span> <span class="co"># Number of folds</span></span>
<span id="cb2780-3"><a href="supervised-learning-regression.html#cb2780-3" aria-hidden="true" tabindex="-1"></a>mpg<span class="sc">$</span>pred.cv <span class="ot">&lt;-</span> <span class="dv">0</span> </span>
<span id="cb2780-4"><a href="supervised-learning-regression.html#cb2780-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>k) {</span>
<span id="cb2780-5"><a href="supervised-learning-regression.html#cb2780-5" aria-hidden="true" tabindex="-1"></a>  split <span class="ot">&lt;-</span> splitPlan[[i]]</span>
<span id="cb2780-6"><a href="supervised-learning-regression.html#cb2780-6" aria-hidden="true" tabindex="-1"></a>  model <span class="ot">&lt;-</span> <span class="fu">lm</span>(cty <span class="sc">~</span> hwy, <span class="at">data =</span> mpg[split<span class="sc">$</span>train,])</span>
<span id="cb2780-7"><a href="supervised-learning-regression.html#cb2780-7" aria-hidden="true" tabindex="-1"></a>  mpg<span class="sc">$</span>pred.cv[split<span class="sc">$</span>app] <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, <span class="at">newdata =</span> mpg[split<span class="sc">$</span>app,])</span>
<span id="cb2780-8"><a href="supervised-learning-regression.html#cb2780-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2780-9"><a href="supervised-learning-regression.html#cb2780-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2780-10"><a href="supervised-learning-regression.html#cb2780-10" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(mpg)</span></code></pre></div>
<pre><code>## # A tibble: 6 × 13
##   manufacturer model displ  year   cyl trans      drv     cty   hwy fl    class 
##   &lt;chr&gt;        &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;      &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; 
## 1 audi         a4      1.8  1999     4 auto(l5)   f        18    29 p     compa…
## 2 audi         a4      1.8  1999     4 manual(m5) f        21    29 p     compa…
## 3 audi         a4      2    2008     4 manual(m6) f        20    31 p     compa…
## 4 audi         a4      2    2008     4 auto(av)   f        21    30 p     compa…
## 5 audi         a4      2.8  1999     6 auto(l5)   f        16    26 p     compa…
## 6 audi         a4      2.8  1999     6 manual(m5) f        18    26 p     compa…
## # ℹ 2 more variables: pred.cv &lt;dbl&gt;, pred &lt;dbl&gt;</code></pre>
<p>Are the two values about the same?</p>
<div class="sourceCode" id="cb2782"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2782-1"><a href="supervised-learning-regression.html#cb2782-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict from a full model</span></span>
<span id="cb2782-2"><a href="supervised-learning-regression.html#cb2782-2" aria-hidden="true" tabindex="-1"></a>mpg<span class="sc">$</span>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(<span class="fu">lm</span>(cty <span class="sc">~</span> hwy, <span class="at">data =</span> mpg))</span>
<span id="cb2782-3"><a href="supervised-learning-regression.html#cb2782-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2782-4"><a href="supervised-learning-regression.html#cb2782-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the rmse of the full model&#39;s predictions</span></span>
<span id="cb2782-5"><a href="supervised-learning-regression.html#cb2782-5" aria-hidden="true" tabindex="-1"></a><span class="fu">rmse</span>(mpg<span class="sc">$</span>pred, mpg<span class="sc">$</span>cty)</span></code></pre></div>
<pre><code>## [1] 1.25</code></pre>
<div class="sourceCode" id="cb2784"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2784-1"><a href="supervised-learning-regression.html#cb2784-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the rmse of the cross-validation predictions</span></span>
<span id="cb2784-2"><a href="supervised-learning-regression.html#cb2784-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rmse</span>(mpg<span class="sc">$</span>pred.cv, mpg<span class="sc">$</span>cty)</span></code></pre></div>
<pre><code>## [1] 1.28</code></pre>
<p>Remember, cross-validation validates the modeling process, not an actual model.</p>
</div>
</div>
</div>
<div id="issues-to-consider" class="section level2 hasAnchor" number="20.3">
<h2><span class="header-section-number">20.3</span> Issues to Consider<a href="supervised-learning-regression.html#issues-to-consider" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="categorical-iv" class="section level3 hasAnchor" number="20.3.1">
<h3><span class="header-section-number">20.3.1</span> Categorical IV<a href="supervised-learning-regression.html#categorical-iv" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>one-hot-encoding</strong></p>
<ul>
<li><code>model.matrix()</code>: Converts categorical variable with N levels into N - 1 indicator variables.</li>
</ul>
<div id="structure-of-categorical-inputs" class="section level4 hasAnchor" number="20.3.1.1">
<h4><span class="header-section-number">20.3.1.1</span> Structure of categorical inputs<a href="supervised-learning-regression.html#structure-of-categorical-inputs" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>You will call <code>model.matrix()</code> to examine how R represents data with both categorical and numerical inputs for modeling.</p>
<p>The dataset <code>flowers</code> following columns:</p>
<ul>
<li><p><code>Flowers</code>: the average number of flowers on a <em>meadowfoam</em> plant</p></li>
<li><p><code>Intensity</code>: the intensity of a light treatment applied to the plant</p></li>
<li><p><code>Time</code>: A categorical variable - when (<code>Late</code> or <code>Early</code>) in the lifecycle the light treatment occurred</p></li>
</ul>
<p>The ultimate goal is to predict <code>Flowers</code> as a function of <code>Time</code> and <code>Intensity</code>.</p>
<div class="sourceCode" id="cb2786"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2786-1"><a href="supervised-learning-regression.html#cb2786-1" aria-hidden="true" tabindex="-1"></a>flowers <span class="ot">&lt;-</span> <span class="fu">read_delim</span>(<span class="st">&quot;data/flowers.txt&quot;</span>)</span>
<span id="cb2786-2"><a href="supervised-learning-regression.html#cb2786-2" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(flowers)</span></code></pre></div>
<pre><code>## Rows: 24
## Columns: 3
## $ Flowers   &lt;dbl&gt; 62.3, 77.4, 55.3, 54.2, 49.6, 61.9, 39.4, 45.7, 31.3, 44.9, …
## $ Time      &lt;chr&gt; &quot;Late&quot;, &quot;Late&quot;, &quot;Late&quot;, &quot;Late&quot;, &quot;Late&quot;, &quot;Late&quot;, &quot;Late&quot;, &quot;Lat…
## $ Intensity &lt;dbl&gt; 150, 150, 300, 300, 450, 450, 600, 600, 750, 750, 900, 900, …</code></pre>
<div class="sourceCode" id="cb2788"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2788-1"><a href="supervised-learning-regression.html#cb2788-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use unique() to see how many possible values Time takes</span></span>
<span id="cb2788-2"><a href="supervised-learning-regression.html#cb2788-2" aria-hidden="true" tabindex="-1"></a><span class="fu">unique</span>(flowers<span class="sc">$</span>Time)</span></code></pre></div>
<pre><code>## [1] &quot;Late&quot;  &quot;Early&quot;</code></pre>
<p><code>TimeLate</code> = Late = 1; <code>TimeLate</code> = Early = 0</p>
<div class="sourceCode" id="cb2790"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2790-1"><a href="supervised-learning-regression.html#cb2790-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use fmla and model.matrix to see how the data is represented for modeling</span></span>
<span id="cb2790-2"><a href="supervised-learning-regression.html#cb2790-2" aria-hidden="true" tabindex="-1"></a>mmat <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(Flowers <span class="sc">~</span> Intensity <span class="sc">+</span> Time, flowers)</span>
<span id="cb2790-3"><a href="supervised-learning-regression.html#cb2790-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2790-4"><a href="supervised-learning-regression.html#cb2790-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Examine the first 20 lines of mmat</span></span>
<span id="cb2790-5"><a href="supervised-learning-regression.html#cb2790-5" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(mmat, <span class="dv">20</span>)</span></code></pre></div>
<pre><code>##    (Intercept) Intensity TimeLate
## 1            1       150        1
## 2            1       150        1
## 3            1       300        1
## 4            1       300        1
## 5            1       450        1
## 6            1       450        1
## 7            1       600        1
## 8            1       600        1
## 9            1       750        1
## 10           1       750        1
## 11           1       900        1
## 12           1       900        1
## 13           1       150        0
## 14           1       150        0
## 15           1       300        0
## 16           1       300        0
## 17           1       450        0
## 18           1       450        0
## 19           1       600        0
## 20           1       600        0</code></pre>
<div class="sourceCode" id="cb2792"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2792-1"><a href="supervised-learning-regression.html#cb2792-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Examine the first 20 lines of flowers</span></span>
<span id="cb2792-2"><a href="supervised-learning-regression.html#cb2792-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(flowers, <span class="dv">20</span>)</span></code></pre></div>
<pre><code>## # A tibble: 20 × 3
##    Flowers Time  Intensity
##      &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;
##  1    62.3 Late        150
##  2    77.4 Late        150
##  3    55.3 Late        300
##  4    54.2 Late        300
##  5    49.6 Late        450
##  6    61.9 Late        450
##  7    39.4 Late        600
##  8    45.7 Late        600
##  9    31.3 Late        750
## 10    44.9 Late        750
## 11    36.8 Late        900
## 12    41.9 Late        900
## 13    77.8 Early       150
## 14    75.6 Early       150
## 15    69.1 Early       300
## 16    78   Early       300
## 17    57   Early       450
## 18    71.1 Early       450
## 19    62.9 Early       600
## 20    52.2 Early       600</code></pre>
</div>
<div id="modeling-with-categorical-inputs" class="section level4 hasAnchor" number="20.3.1.2">
<h4><span class="header-section-number">20.3.1.2</span> Modeling with categorical inputs<a href="supervised-learning-regression.html#modeling-with-categorical-inputs" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>You will fit a linear model to the <code>flowers</code> data, to predict <code>Flowers</code> as a function of <code>Time</code> and <code>Intensity</code>.</p>
<div class="sourceCode" id="cb2794"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2794-1"><a href="supervised-learning-regression.html#cb2794-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a model to predict Flowers from Intensity and Time : flower_model</span></span>
<span id="cb2794-2"><a href="supervised-learning-regression.html#cb2794-2" aria-hidden="true" tabindex="-1"></a>flower_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(Flowers <span class="sc">~</span> Intensity <span class="sc">+</span> Time, flowers)</span>
<span id="cb2794-3"><a href="supervised-learning-regression.html#cb2794-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2794-4"><a href="supervised-learning-regression.html#cb2794-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Use summary to examine flower_model </span></span>
<span id="cb2794-5"><a href="supervised-learning-regression.html#cb2794-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(flower_model)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Flowers ~ Intensity + Time, data = flowers)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
##  -9.65  -4.14  -1.56   5.63  12.16 
## 
## Coefficients:
##              Estimate Std. Error t value             Pr(&gt;|t|)    
## (Intercept)  83.46417    3.27377   25.49 &lt; 0.0000000000000002 ***
## Intensity    -0.04047    0.00513   -7.89            0.0000001 ***
## TimeLate    -12.15833    2.62956   -4.62              0.00015 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.44 on 21 degrees of freedom
## Multiple R-squared:  0.799,  Adjusted R-squared:  0.78 
## F-statistic: 41.8 on 2 and 21 DF,  p-value: 0.0000000479</code></pre>
<p>Intercept = Early (reference group), TimeLate = Late.</p>
<div class="sourceCode" id="cb2796"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2796-1"><a href="supervised-learning-regression.html#cb2796-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict the number of flowers on each plant</span></span>
<span id="cb2796-2"><a href="supervised-learning-regression.html#cb2796-2" aria-hidden="true" tabindex="-1"></a>flowers<span class="sc">$</span>predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(flower_model, flowers)</span>
<span id="cb2796-3"><a href="supervised-learning-regression.html#cb2796-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2796-4"><a href="supervised-learning-regression.html#cb2796-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot predictions vs actual flowers (predictions on x-axis)</span></span>
<span id="cb2796-5"><a href="supervised-learning-regression.html#cb2796-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(flowers, <span class="fu">aes</span>(<span class="at">x =</span> predictions, <span class="at">y =</span> Flowers)) <span class="sc">+</span> </span>
<span id="cb2796-6"><a href="supervised-learning-regression.html#cb2796-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb2796-7"><a href="supervised-learning-regression.html#cb2796-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">color =</span> <span class="st">&quot;blue&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-1062-1.png" width="672" /></p>
</div>
</div>
<div id="interactions-1" class="section level3 hasAnchor" number="20.3.2">
<h3><span class="header-section-number">20.3.2</span> Interactions<a href="supervised-learning-regression.html#interactions-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="modeling-an-interaction" class="section level4 hasAnchor" number="20.3.2.1">
<h4><span class="header-section-number">20.3.2.1</span> Modeling an interaction<a href="supervised-learning-regression.html#modeling-an-interaction" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>You will use interactions to model the effect of gender and gastric activity on alcohol metabolism.</p>
<p>The <code>alcohol</code> data frame has the columns:</p>
<ul>
<li><p><code>Metabol</code>: the alcohol metabolism rate</p></li>
<li><p><code>Gastric</code>: the rate of gastric alcohol dehydrogenase activity</p></li>
<li><p><code>Sex</code>: the sex of the drinker (<code>Male</code> or <code>Female</code>)</p></li>
</ul>
<div class="sourceCode" id="cb2797"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2797-1"><a href="supervised-learning-regression.html#cb2797-1" aria-hidden="true" tabindex="-1"></a>alcohol <span class="ot">&lt;-</span> <span class="fu">read_tsv</span>(<span class="st">&quot;data/alcohol.txt&quot;</span>)</span>
<span id="cb2797-2"><a href="supervised-learning-regression.html#cb2797-2" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(alcohol)</span></code></pre></div>
<pre><code>## Rows: 32
## Columns: 5
## $ Subject &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,…
## $ Metabol &lt;dbl&gt; 0.6, 0.6, 1.5, 0.4, 0.1, 0.2, 0.3, 0.3, 0.4, 1.0, 1.1, 1.2, 1.…
## $ Gastric &lt;dbl&gt; 1.0, 1.6, 1.5, 2.2, 1.1, 1.2, 0.9, 0.8, 1.5, 0.9, 1.6, 1.7, 1.…
## $ Sex     &lt;chr&gt; &quot;Female&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;Female&quot;, &quot;F…
## $ Alcohol &lt;chr&gt; &quot;Alcoholic&quot;, &quot;Alcoholic&quot;, &quot;Alcoholic&quot;, &quot;Non-alcoholic&quot;, &quot;Non-a…</code></pre>
<p>No interaction.</p>
<div class="sourceCode" id="cb2799"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2799-1"><a href="supervised-learning-regression.html#cb2799-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the main effects only model</span></span>
<span id="cb2799-2"><a href="supervised-learning-regression.html#cb2799-2" aria-hidden="true" tabindex="-1"></a>model_add <span class="ot">&lt;-</span> <span class="fu">lm</span>(Metabol <span class="sc">~</span> Gastric <span class="sc">+</span> Sex, alcohol)</span>
<span id="cb2799-3"><a href="supervised-learning-regression.html#cb2799-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2799-4"><a href="supervised-learning-regression.html#cb2799-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_add)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Metabol ~ Gastric + Sex, data = alcohol)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -2.278 -0.633 -0.097  0.578  4.570 
## 
## Coefficients:
##             Estimate Std. Error t value    Pr(&gt;|t|)    
## (Intercept)   -1.947      0.520   -3.75      0.0008 ***
## Gastric        1.966      0.267    7.35 0.000000042 ***
## SexMale        1.617      0.511    3.16      0.0036 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.33 on 29 degrees of freedom
## Multiple R-squared:  0.765,  Adjusted R-squared:  0.749 
## F-statistic: 47.3 on 2 and 29 DF,  p-value: 0.000000000741</code></pre>
<p>Add <code>Gastric</code> as a main effect, plus interaction.</p>
<div class="sourceCode" id="cb2801"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2801-1"><a href="supervised-learning-regression.html#cb2801-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the interaction model</span></span>
<span id="cb2801-2"><a href="supervised-learning-regression.html#cb2801-2" aria-hidden="true" tabindex="-1"></a>model_interaction <span class="ot">&lt;-</span> <span class="fu">lm</span>(Metabol <span class="sc">~</span> Gastric <span class="sc">+</span> Gastric<span class="sc">:</span>Sex, alcohol)</span>
<span id="cb2801-3"><a href="supervised-learning-regression.html#cb2801-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2801-4"><a href="supervised-learning-regression.html#cb2801-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_interaction)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Metabol ~ Gastric + Gastric:Sex, data = alcohol)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -2.466 -0.509  0.014  0.566  4.067 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)       -0.750      0.531   -1.41  0.16824    
## Gastric            1.149      0.345    3.33  0.00237 ** 
## Gastric:SexMale    1.042      0.241    4.32  0.00017 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.2 on 29 degrees of freedom
## Multiple R-squared:  0.808,  Adjusted R-squared:  0.795 
## F-statistic:   61 on 2 and 29 DF,  p-value: 0.0000000000403</code></pre>
<p>An interaction appears to give a better fit to the data.</p>
<p><strong>cross-validation</strong></p>
<p>Because this dataset is small, we will use cross-validation to simulate making predictions on out-of-sample data.</p>
<div class="sourceCode" id="cb2803"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2803-1"><a href="supervised-learning-regression.html#cb2803-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the formula with main effects only</span></span>
<span id="cb2803-2"><a href="supervised-learning-regression.html#cb2803-2" aria-hidden="true" tabindex="-1"></a>fmla_add <span class="ot">&lt;-</span> <span class="fu">as.formula</span>(Metabol <span class="sc">~</span> Gastric <span class="sc">+</span> Sex)</span>
<span id="cb2803-3"><a href="supervised-learning-regression.html#cb2803-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2803-4"><a href="supervised-learning-regression.html#cb2803-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the formula with interactions</span></span>
<span id="cb2803-5"><a href="supervised-learning-regression.html#cb2803-5" aria-hidden="true" tabindex="-1"></a>fmla_interaction <span class="ot">&lt;-</span> <span class="fu">as.formula</span>(Metabol <span class="sc">~</span> Gastric <span class="sc">+</span> Gastric<span class="sc">:</span>Sex)</span>
<span id="cb2803-6"><a href="supervised-learning-regression.html#cb2803-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2803-7"><a href="supervised-learning-regression.html#cb2803-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the splitting plan for 3-fold cross validation</span></span>
<span id="cb2803-8"><a href="supervised-learning-regression.html#cb2803-8" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">34245</span>)  <span class="co"># set the seed for reproducibility</span></span>
<span id="cb2803-9"><a href="supervised-learning-regression.html#cb2803-9" aria-hidden="true" tabindex="-1"></a>splitPlan <span class="ot">&lt;-</span> <span class="fu">kWayCrossValidation</span>(<span class="fu">nrow</span>(alcohol), <span class="dv">3</span>, <span class="cn">NULL</span>, <span class="cn">NULL</span>)</span>
<span id="cb2803-10"><a href="supervised-learning-regression.html#cb2803-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2803-11"><a href="supervised-learning-regression.html#cb2803-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample code: Get cross-val predictions for main-effects only model</span></span>
<span id="cb2803-12"><a href="supervised-learning-regression.html#cb2803-12" aria-hidden="true" tabindex="-1"></a>alcohol<span class="sc">$</span>pred_add <span class="ot">&lt;-</span> <span class="dv">0</span>  <span class="co"># initialize the prediction vector</span></span>
<span id="cb2803-13"><a href="supervised-learning-regression.html#cb2803-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>) {</span>
<span id="cb2803-14"><a href="supervised-learning-regression.html#cb2803-14" aria-hidden="true" tabindex="-1"></a>  split <span class="ot">&lt;-</span> splitPlan[[i]]</span>
<span id="cb2803-15"><a href="supervised-learning-regression.html#cb2803-15" aria-hidden="true" tabindex="-1"></a>  model_add <span class="ot">&lt;-</span> <span class="fu">lm</span>(fmla_add, <span class="at">data =</span> alcohol[split<span class="sc">$</span>train, ])</span>
<span id="cb2803-16"><a href="supervised-learning-regression.html#cb2803-16" aria-hidden="true" tabindex="-1"></a>  alcohol<span class="sc">$</span>pred_add[split<span class="sc">$</span>app] <span class="ot">&lt;-</span> <span class="fu">predict</span>(model_add, <span class="at">newdata =</span> alcohol[split<span class="sc">$</span>app, ])</span>
<span id="cb2803-17"><a href="supervised-learning-regression.html#cb2803-17" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2803-18"><a href="supervised-learning-regression.html#cb2803-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2803-19"><a href="supervised-learning-regression.html#cb2803-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the cross-val predictions for the model with interactions</span></span>
<span id="cb2803-20"><a href="supervised-learning-regression.html#cb2803-20" aria-hidden="true" tabindex="-1"></a>alcohol<span class="sc">$</span>pred_interaction <span class="ot">&lt;-</span> <span class="dv">0</span> <span class="co"># initialize the prediction vector</span></span>
<span id="cb2803-21"><a href="supervised-learning-regression.html#cb2803-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>) {</span>
<span id="cb2803-22"><a href="supervised-learning-regression.html#cb2803-22" aria-hidden="true" tabindex="-1"></a>  split <span class="ot">&lt;-</span> splitPlan[[i]]</span>
<span id="cb2803-23"><a href="supervised-learning-regression.html#cb2803-23" aria-hidden="true" tabindex="-1"></a>  model_interaction <span class="ot">&lt;-</span> <span class="fu">lm</span>(fmla_interaction, <span class="at">data =</span> alcohol[split<span class="sc">$</span>train, ])</span>
<span id="cb2803-24"><a href="supervised-learning-regression.html#cb2803-24" aria-hidden="true" tabindex="-1"></a>  alcohol<span class="sc">$</span>pred_interaction[split<span class="sc">$</span>app] <span class="ot">&lt;-</span> <span class="fu">predict</span>(model_interaction, <span class="at">newdata =</span> alcohol[split<span class="sc">$</span>app, ])</span>
<span id="cb2803-25"><a href="supervised-learning-regression.html#cb2803-25" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2803-26"><a href="supervised-learning-regression.html#cb2803-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2803-27"><a href="supervised-learning-regression.html#cb2803-27" aria-hidden="true" tabindex="-1"></a><span class="co"># see dataset</span></span>
<span id="cb2803-28"><a href="supervised-learning-regression.html#cb2803-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2803-29"><a href="supervised-learning-regression.html#cb2803-29" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(alcohol)</span></code></pre></div>
<pre><code>## # A tibble: 6 × 7
##   Subject Metabol Gastric Sex    Alcohol       pred_add pred_interaction
##     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;            &lt;dbl&gt;            &lt;dbl&gt;
## 1       1     0.6     1   Female Alcoholic       -0.209            0.416
## 2       2     0.6     1.6 Female Alcoholic        1.46             1.30 
## 3       3     1.5     1.5 Female Alcoholic        1.26             1.18 
## 4       4     0.4     2.2 Female Non-alcoholic    2.62             2.00 
## 5       5     0.1     1.1 Female Non-alcoholic    0.224            0.338
## 6       6     0.2     1.2 Female Non-alcoholic    0.682            0.832</code></pre>
<p>Use <code>tidyr</code>’s <code>gather()</code> which takes multiple columns and collapses them into key-value pairs.</p>
<div class="sourceCode" id="cb2805"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2805-1"><a href="supervised-learning-regression.html#cb2805-1" aria-hidden="true" tabindex="-1"></a>alcohol <span class="sc">%&gt;%</span> </span>
<span id="cb2805-2"><a href="supervised-learning-regression.html#cb2805-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather</span>(<span class="at">key =</span> modeltype, <span class="at">value =</span> pred, pred_add, pred_interaction)</span></code></pre></div>
<pre><code>## # A tibble: 64 × 7
##    Subject Metabol Gastric Sex    Alcohol       modeltype   pred
##      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;         &lt;chr&gt;      &lt;dbl&gt;
##  1       1     0.6     1   Female Alcoholic     pred_add  -0.209
##  2       2     0.6     1.6 Female Alcoholic     pred_add   1.46 
##  3       3     1.5     1.5 Female Alcoholic     pred_add   1.26 
##  4       4     0.4     2.2 Female Non-alcoholic pred_add   2.62 
##  5       5     0.1     1.1 Female Non-alcoholic pred_add   0.224
##  6       6     0.2     1.2 Female Non-alcoholic pred_add   0.682
##  7       7     0.3     0.9 Female Non-alcoholic pred_add  -0.396
##  8       8     0.3     0.8 Female Non-alcoholic pred_add  -0.582
##  9       9     0.4     1.5 Female Non-alcoholic pred_add   1.04 
## 10      10     1       0.9 Female Non-alcoholic pred_add  -0.396
## # ℹ 54 more rows</code></pre>
<div class="sourceCode" id="cb2807"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2807-1"><a href="supervised-learning-regression.html#cb2807-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get RMSE</span></span>
<span id="cb2807-2"><a href="supervised-learning-regression.html#cb2807-2" aria-hidden="true" tabindex="-1"></a>alcohol <span class="sc">%&gt;%</span> </span>
<span id="cb2807-3"><a href="supervised-learning-regression.html#cb2807-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather</span>(<span class="at">key =</span> modeltype, <span class="at">value =</span> pred, pred_add, pred_interaction) <span class="sc">%&gt;%</span></span>
<span id="cb2807-4"><a href="supervised-learning-regression.html#cb2807-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">residuals =</span> Metabol <span class="sc">-</span> pred) <span class="sc">%&gt;%</span>      </span>
<span id="cb2807-5"><a href="supervised-learning-regression.html#cb2807-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(modeltype) <span class="sc">%&gt;%</span></span>
<span id="cb2807-6"><a href="supervised-learning-regression.html#cb2807-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">rmse =</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(residuals<span class="sc">^</span><span class="dv">2</span>)))</span></code></pre></div>
<pre><code>## # A tibble: 2 × 2
##   modeltype         rmse
##   &lt;chr&gt;            &lt;dbl&gt;
## 1 pred_add          1.38
## 2 pred_interaction  1.26</code></pre>
<p>Cross-validation confirms that a model with interaction will likely give better predictions.</p>
</div>
</div>
<div id="transforming-dv-before-modeling" class="section level3 hasAnchor" number="20.3.3">
<h3><span class="header-section-number">20.3.3</span> Transforming DV before modeling<a href="supervised-learning-regression.html#transforming-dv-before-modeling" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Root Mean Squared Relative Error</strong></p>
<p>RMS-relative error = <span class="math inline">\(\sqrt{\overline{(\frac{pred - y}{y})^2}}\)</span></p>
<ul>
<li><p>Predicting log-outcome reduces RMS-relative error</p></li>
<li><p>But the model will o/en have larger RMSE</p></li>
</ul>
<div id="relative-error" class="section level4 hasAnchor" number="20.3.3.1">
<h4><span class="header-section-number">20.3.3.1</span> Relative error<a href="supervised-learning-regression.html#relative-error" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>You will compare relative error to absolute error.</p>
<p>The example (toy) dataset <code>fdata</code> includes the columns:</p>
<ul>
<li><p><code>y</code>: the true output to be predicted by some model; imagine it is the amount of money a customer will spend on a visit to your store.</p></li>
<li><p><code>pred</code>: the predictions of a model that predicts <code>y</code>.</p></li>
<li><p><code>label</code>: categorical: whether <code>y</code> comes from a population that makes <code>small</code> purchases, or <code>large</code> ones.</p></li>
</ul>
<p>You want to know which model does “better”: the one predicting the <code>small</code> purchases, or the one predicting <code>large</code> ones.</p>
<div class="sourceCode" id="cb2809"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2809-1"><a href="supervised-learning-regression.html#cb2809-1" aria-hidden="true" tabindex="-1"></a>fdata <span class="ot">&lt;-</span> <span class="fu">read_tsv</span>(<span class="st">&quot;data/fdata.txt&quot;</span>)</span>
<span id="cb2809-2"><a href="supervised-learning-regression.html#cb2809-2" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(fdata)</span></code></pre></div>
<pre><code>## Rows: 100
## Columns: 3
## $ y     &lt;dbl&gt; 9.15, 1.90, -3.86, 2.39, 1.54, 13.56, 10.20, 1.10, 3.94, 9.04, 1…
## $ pred  &lt;dbl&gt; 6.43, 3.47, 1.59, 3.76, 9.51, 6.93, 8.19, 1.51, 8.99, 6.15, 8.50…
## $ label &lt;chr&gt; &quot;small purchases&quot;, &quot;small purchases&quot;, &quot;small purchases&quot;, &quot;small …</code></pre>
<div class="sourceCode" id="cb2811"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2811-1"><a href="supervised-learning-regression.html#cb2811-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Examine the data: generate the summaries for the groups large and small:</span></span>
<span id="cb2811-2"><a href="supervised-learning-regression.html#cb2811-2" aria-hidden="true" tabindex="-1"></a>fdata <span class="sc">%&gt;%</span> </span>
<span id="cb2811-3"><a href="supervised-learning-regression.html#cb2811-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># group by small/large purchases</span></span>
<span id="cb2811-4"><a href="supervised-learning-regression.html#cb2811-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(label) <span class="sc">%&gt;%</span>     </span>
<span id="cb2811-5"><a href="supervised-learning-regression.html#cb2811-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarize</span>(<span class="at">min  =</span> <span class="fu">min</span>(y),   <span class="co"># min of y</span></span>
<span id="cb2811-6"><a href="supervised-learning-regression.html#cb2811-6" aria-hidden="true" tabindex="-1"></a>              <span class="at">mean =</span> <span class="fu">mean</span>(y),  <span class="co"># mean of y</span></span>
<span id="cb2811-7"><a href="supervised-learning-regression.html#cb2811-7" aria-hidden="true" tabindex="-1"></a>              <span class="at">max  =</span> <span class="fu">max</span>(y))   <span class="co"># max of y</span></span></code></pre></div>
<pre><code>## # A tibble: 2 × 4
##   label             min   mean    max
##   &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1 large purchases 96.1  606.   1102. 
## 2 small purchases -5.89   6.48   18.6</code></pre>
<div class="sourceCode" id="cb2813"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2813-1"><a href="supervised-learning-regression.html#cb2813-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fill in the blanks to add error columns</span></span>
<span id="cb2813-2"><a href="supervised-learning-regression.html#cb2813-2" aria-hidden="true" tabindex="-1"></a>fdata2 <span class="ot">&lt;-</span> fdata <span class="sc">%&gt;%</span> </span>
<span id="cb2813-3"><a href="supervised-learning-regression.html#cb2813-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># group by label</span></span>
<span id="cb2813-4"><a href="supervised-learning-regression.html#cb2813-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(label) <span class="sc">%&gt;%</span>       </span>
<span id="cb2813-5"><a href="supervised-learning-regression.html#cb2813-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">residual =</span> y <span class="sc">-</span> pred,      <span class="co"># Residual</span></span>
<span id="cb2813-6"><a href="supervised-learning-regression.html#cb2813-6" aria-hidden="true" tabindex="-1"></a>           <span class="at">relerr   =</span> residual <span class="sc">/</span> y)  <span class="co"># Relative error</span></span>
<span id="cb2813-7"><a href="supervised-learning-regression.html#cb2813-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2813-8"><a href="supervised-learning-regression.html#cb2813-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare the rmse and rmse.rel of the large and small groups:</span></span>
<span id="cb2813-9"><a href="supervised-learning-regression.html#cb2813-9" aria-hidden="true" tabindex="-1"></a>fdata2 <span class="sc">%&gt;%</span> </span>
<span id="cb2813-10"><a href="supervised-learning-regression.html#cb2813-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(label) <span class="sc">%&gt;%</span> </span>
<span id="cb2813-11"><a href="supervised-learning-regression.html#cb2813-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">rmse =</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(residual<span class="sc">^</span><span class="dv">2</span>)),   <span class="co"># RMSE</span></span>
<span id="cb2813-12"><a href="supervised-learning-regression.html#cb2813-12" aria-hidden="true" tabindex="-1"></a>            <span class="at">rmse.rel =</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(relerr<span class="sc">^</span><span class="dv">2</span>))) <span class="co"># Root mean squared relative error</span></span></code></pre></div>
<pre><code>## # A tibble: 2 × 3
##   label            rmse rmse.rel
##   &lt;chr&gt;           &lt;dbl&gt;    &lt;dbl&gt;
## 1 large purchases  5.54   0.0147
## 2 small purchases  4.01   1.25</code></pre>
<p>Notice from this example how a model with larger RMSE might still be better, if relative errors are more important than absolute errors.</p>
<div class="sourceCode" id="cb2815"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2815-1"><a href="supervised-learning-regression.html#cb2815-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the predictions for both groups of purchases</span></span>
<span id="cb2815-2"><a href="supervised-learning-regression.html#cb2815-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(fdata2, <span class="fu">aes</span>(<span class="at">x =</span> pred, <span class="at">y =</span> y, <span class="at">color =</span> label)) <span class="sc">+</span> </span>
<span id="cb2815-3"><a href="supervised-learning-regression.html#cb2815-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb2815-4"><a href="supervised-learning-regression.html#cb2815-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>() <span class="sc">+</span> </span>
<span id="cb2815-5"><a href="supervised-learning-regression.html#cb2815-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> label, <span class="at">ncol =</span> <span class="dv">1</span>, <span class="at">scales =</span> <span class="st">&quot;free&quot;</span>) <span class="sc">+</span> </span>
<span id="cb2815-6"><a href="supervised-learning-regression.html#cb2815-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Outcome vs prediction&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-1072-1.png" width="672" /></p>
</div>
<div id="modeling-log-transformed-output" class="section level4 hasAnchor" number="20.3.3.2">
<h4><span class="header-section-number">20.3.3.2</span> Modeling log-transformed output<a href="supervised-learning-regression.html#modeling-log-transformed-output" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>You will practice modeling on log-transformed monetary output, and then transforming the “log-money” predictions back into monetary units.</p>
<p><code>Income2005</code> records subjects’ incomes in 2005, as well as the results of several aptitude tests taken by the subjects in 1981.</p>
<p>You will build a model of log(income) from the inputs, and then convert log(income) back into income.</p>
<div class="sourceCode" id="cb2816"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2816-1"><a href="supervised-learning-regression.html#cb2816-1" aria-hidden="true" tabindex="-1"></a><span class="co"># A vector contain &quot;incometrain&quot; and &quot;incometest&quot;</span></span>
<span id="cb2816-2"><a href="supervised-learning-regression.html#cb2816-2" aria-hidden="true" tabindex="-1"></a>Income2005 <span class="ot">&lt;-</span> <span class="fu">load</span>(<span class="st">&quot;data/Income.RData&quot;</span>)</span>
<span id="cb2816-3"><a href="supervised-learning-regression.html#cb2816-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2816-4"><a href="supervised-learning-regression.html#cb2816-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up dataset</span></span>
<span id="cb2816-5"><a href="supervised-learning-regression.html#cb2816-5" aria-hidden="true" tabindex="-1"></a>income_train <span class="ot">&lt;-</span> incometrain</span>
<span id="cb2816-6"><a href="supervised-learning-regression.html#cb2816-6" aria-hidden="true" tabindex="-1"></a>income_test <span class="ot">&lt;-</span> incometest</span>
<span id="cb2816-7"><a href="supervised-learning-regression.html#cb2816-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2816-8"><a href="supervised-learning-regression.html#cb2816-8" aria-hidden="true" tabindex="-1"></a><span class="co"># See data structure</span></span>
<span id="cb2816-9"><a href="supervised-learning-regression.html#cb2816-9" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(income_train)</span></code></pre></div>
<pre><code>## Rows: 2,069
## Columns: 7
## $ Subject    &lt;int&gt; 2, 6, 8, 9, 16, 17, 18, 20, 21, 22, 29, 34, 37, 38, 39, 41,…
## $ Arith      &lt;int&gt; 8, 30, 13, 21, 17, 29, 30, 17, 29, 27, 12, 8, 21, 9, 16, 15…
## $ Word       &lt;int&gt; 15, 35, 35, 28, 30, 33, 35, 28, 33, 31, 9, 20, 31, 17, 23, …
## $ Parag      &lt;int&gt; 6, 15, 12, 10, 12, 13, 14, 14, 13, 14, 11, 8, 13, 9, 10, 11…
## $ Math       &lt;int&gt; 6, 23, 4, 13, 17, 21, 23, 20, 25, 22, 9, 3, 12, 5, 8, 18, 8…
## $ AFQT       &lt;dbl&gt; 6.84, 99.39, 44.02, 59.68, 50.28, 89.67, 95.98, 67.02, 88.4…
## $ Income2005 &lt;int&gt; 5500, 65000, 36000, 65000, 71000, 43000, 120000, 64000, 253…</code></pre>
<div class="sourceCode" id="cb2818"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2818-1"><a href="supervised-learning-regression.html#cb2818-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(income_test)</span></code></pre></div>
<pre><code>## Rows: 515
## Columns: 7
## $ Subject    &lt;int&gt; 7, 13, 47, 62, 73, 78, 89, 105, 106, 107, 129, 152, 160, 16…
## $ Arith      &lt;int&gt; 14, 30, 26, 12, 18, 25, 24, 28, 30, 19, 28, 30, 28, 16, 21,…
## $ Word       &lt;int&gt; 27, 29, 33, 25, 34, 35, 34, 32, 35, 31, 33, 33, 31, 25, 28,…
## $ Parag      &lt;int&gt; 8, 13, 13, 10, 13, 14, 15, 14, 12, 11, 14, 14, 13, 13, 13, …
## $ Math       &lt;int&gt; 11, 24, 16, 10, 18, 21, 17, 20, 23, 16, 23, 22, 19, 12, 16,…
## $ AFQT       &lt;dbl&gt; 47.41, 72.31, 75.47, 36.38, 81.53, 85.35, 84.98, 81.79, 87.…
## $ Income2005 &lt;int&gt; 19000, 8000, 66309, 30000, 186135, 14657, 62000, 40000, 105…</code></pre>
<div class="sourceCode" id="cb2820"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2820-1"><a href="supervised-learning-regression.html#cb2820-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Examine Income2005 in the training set</span></span>
<span id="cb2820-2"><a href="supervised-learning-regression.html#cb2820-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(income_train<span class="sc">$</span>Income2005)</span></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##      63   23000   39000   49894   61500  703637</code></pre>
<p>Plot outcome variable.</p>
<div class="sourceCode" id="cb2822"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2822-1"><a href="supervised-learning-regression.html#cb2822-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(income_train, <span class="fu">aes</span>(Income2005)) <span class="sc">+</span></span>
<span id="cb2822-2"><a href="supervised-learning-regression.html#cb2822-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_histogram</span>()</span></code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better
## value with `binwidth`.</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-1076-1.png" width="672" /></p>
<p>Fit log transform model and predict on testing data.</p>
<div class="sourceCode" id="cb2824"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2824-1"><a href="supervised-learning-regression.html#cb2824-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the linear model</span></span>
<span id="cb2824-2"><a href="supervised-learning-regression.html#cb2824-2" aria-hidden="true" tabindex="-1"></a>model.log <span class="ot">&lt;-</span>  <span class="fu">lm</span>(<span class="fu">log</span>(Income2005) <span class="sc">~</span> Arith <span class="sc">+</span> Word <span class="sc">+</span> Parag <span class="sc">+</span> Math <span class="sc">+</span> AFQT, income_train)</span>
<span id="cb2824-3"><a href="supervised-learning-regression.html#cb2824-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2824-4"><a href="supervised-learning-regression.html#cb2824-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on income_test</span></span>
<span id="cb2824-5"><a href="supervised-learning-regression.html#cb2824-5" aria-hidden="true" tabindex="-1"></a>income_test<span class="sc">$</span>logpred <span class="ot">&lt;-</span> <span class="fu">predict</span>(model.log, income_test)</span>
<span id="cb2824-6"><a href="supervised-learning-regression.html#cb2824-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(income_test<span class="sc">$</span>logpred)</span></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    9.77   10.13   10.42   10.42   10.70   11.01</code></pre>
<p>Reverse the log transformation to put the predictions into “monetary units”.</p>
<div class="sourceCode" id="cb2826"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2826-1"><a href="supervised-learning-regression.html#cb2826-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the predictions to monetary units</span></span>
<span id="cb2826-2"><a href="supervised-learning-regression.html#cb2826-2" aria-hidden="true" tabindex="-1"></a>income_test<span class="sc">$</span>pred.income <span class="ot">&lt;-</span> <span class="fu">exp</span>(income_test<span class="sc">$</span>logpred)</span>
<span id="cb2826-3"><a href="supervised-learning-regression.html#cb2826-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(income_test<span class="sc">$</span>pred.income)</span></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   17432   25167   33615   35363   44566   60217</code></pre>
<p>Plot a scatter plot of predicted income vs income on the test set.</p>
<div class="sourceCode" id="cb2828"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2828-1"><a href="supervised-learning-regression.html#cb2828-1" aria-hidden="true" tabindex="-1"></a><span class="co">#  Plot predicted income (x axis) vs income</span></span>
<span id="cb2828-2"><a href="supervised-learning-regression.html#cb2828-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(income_test, <span class="fu">aes</span>(<span class="at">x =</span> pred.income, <span class="at">y =</span> Income2005)) <span class="sc">+</span> </span>
<span id="cb2828-3"><a href="supervised-learning-regression.html#cb2828-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb2828-4"><a href="supervised-learning-regression.html#cb2828-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">color =</span> <span class="st">&quot;blue&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-1079-1.png" width="672" /></p>
<p>Remember that when you transform the output before modeling, you have to <em>‘reverse transform’</em> the resulting predictions after applying the model.</p>
</div>
<div id="comparing-rmse-and-rms-relative-error" class="section level4 hasAnchor" number="20.3.3.3">
<h4><span class="header-section-number">20.3.3.3</span> Comparing RMSE and RMS Relative Error<a href="supervised-learning-regression.html#comparing-rmse-and-rms-relative-error" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In this exercise, you will show that log-transforming a monetary output before modeling improves mean relative error (but increases RMSE) compared to modeling the monetary output directly.</p>
<p>Compare the results of <code>model.log</code> from the previous exercise to a model (<code>model.abs</code>) that directly fits income.</p>
<div class="sourceCode" id="cb2829"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2829-1"><a href="supervised-learning-regression.html#cb2829-1" aria-hidden="true" tabindex="-1"></a><span class="co"># a model that directly fits income to the inputs</span></span>
<span id="cb2829-2"><a href="supervised-learning-regression.html#cb2829-2" aria-hidden="true" tabindex="-1"></a>model.abs <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">formula =</span> Income2005 <span class="sc">~</span> Arith <span class="sc">+</span> Word <span class="sc">+</span> Parag <span class="sc">+</span> Math <span class="sc">+</span> AFQT, <span class="at">data =</span> income_train)</span>
<span id="cb2829-3"><a href="supervised-learning-regression.html#cb2829-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2829-4"><a href="supervised-learning-regression.html#cb2829-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model.abs)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Income2005 ~ Arith + Word + Parag + Math + AFQT, 
##     data = income_train)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -78728 -24137  -6979  11964 648573 
## 
## Coefficients:
##             Estimate Std. Error t value   Pr(&gt;|t|)    
## (Intercept)    17517       6420    2.73     0.0064 ** 
## Arith           1552        303    5.12 0.00000034 ***
## Word            -132        265   -0.50     0.6175    
## Parag          -1155        618   -1.87     0.0619 .  
## Math             726        372    1.95     0.0513 .  
## AFQT             178        144    1.23     0.2173    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 45500 on 2063 degrees of freedom
## Multiple R-squared:  0.116,  Adjusted R-squared:  0.114 
## F-statistic: 54.4 on 5 and 2063 DF,  p-value: &lt;0.0000000000000002</code></pre>
<div class="sourceCode" id="cb2831"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2831-1"><a href="supervised-learning-regression.html#cb2831-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Add predictions to the test set</span></span>
<span id="cb2831-2"><a href="supervised-learning-regression.html#cb2831-2" aria-hidden="true" tabindex="-1"></a>income_test <span class="ot">&lt;-</span> income_test <span class="sc">%&gt;%</span></span>
<span id="cb2831-3"><a href="supervised-learning-regression.html#cb2831-3" aria-hidden="true" tabindex="-1"></a>           <span class="co"># predictions from model.abs</span></span>
<span id="cb2831-4"><a href="supervised-learning-regression.html#cb2831-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">pred.absmodel =</span> <span class="fu">predict</span>(model.abs, income_test),        </span>
<span id="cb2831-5"><a href="supervised-learning-regression.html#cb2831-5" aria-hidden="true" tabindex="-1"></a>           <span class="co"># predictions from model.log</span></span>
<span id="cb2831-6"><a href="supervised-learning-regression.html#cb2831-6" aria-hidden="true" tabindex="-1"></a>           <span class="at">pred.logmodel =</span> <span class="fu">exp</span>(<span class="fu">predict</span>(model.log, income_test)))</span>
<span id="cb2831-7"><a href="supervised-learning-regression.html#cb2831-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2831-8"><a href="supervised-learning-regression.html#cb2831-8" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(income_test)</span></code></pre></div>
<pre><code>##    Subject Arith Word Parag Math AFQT Income2005 logpred pred.income
## 3        7    14   27     8   11 47.4      19000    10.3       28644
## 6       13    30   29    13   24 72.3       8000    10.9       56646
## 22      47    26   33    13   16 75.5      66309    10.7       44468
## 27      62    12   25    10   10 36.4      30000    10.1       25462
## 30      73    18   34    13   18 81.5     186135    10.5       36356
## 31      78    25   35    14   21 85.3      14657    10.8       46948
##    pred.absmodel pred.logmodel
## 3          42844         28644
## 6          75499         56646
## 22         63519         44468
## 27         35008         25462
## 30         53495         36356
## 31         65929         46948</code></pre>
<div class="sourceCode" id="cb2833"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2833-1"><a href="supervised-learning-regression.html#cb2833-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Gather the predictions and calculate residuals and relative error</span></span>
<span id="cb2833-2"><a href="supervised-learning-regression.html#cb2833-2" aria-hidden="true" tabindex="-1"></a>income_long <span class="ot">&lt;-</span> income_test <span class="sc">%&gt;%</span> </span>
<span id="cb2833-3"><a href="supervised-learning-regression.html#cb2833-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather</span>(<span class="at">key =</span> modeltype, <span class="at">value =</span> pred, pred.absmodel, pred.logmodel) <span class="sc">%&gt;%</span></span>
<span id="cb2833-4"><a href="supervised-learning-regression.html#cb2833-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">residual =</span> Income2005 <span class="sc">-</span> pred,   <span class="co"># residuals</span></span>
<span id="cb2833-5"><a href="supervised-learning-regression.html#cb2833-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">relerr =</span> residual <span class="sc">/</span> Income2005) <span class="co"># relative error</span></span>
<span id="cb2833-6"><a href="supervised-learning-regression.html#cb2833-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2833-7"><a href="supervised-learning-regression.html#cb2833-7" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(income_long)</span></code></pre></div>
<pre><code>##   Subject Arith Word Parag Math AFQT Income2005 logpred pred.income
## 1       7    14   27     8   11 47.4      19000    10.3       28644
## 2      13    30   29    13   24 72.3       8000    10.9       56646
## 3      47    26   33    13   16 75.5      66309    10.7       44468
## 4      62    12   25    10   10 36.4      30000    10.1       25462
## 5      73    18   34    13   18 81.5     186135    10.5       36356
## 6      78    25   35    14   21 85.3      14657    10.8       46948
##       modeltype  pred residual  relerr
## 1 pred.absmodel 42844   -23844 -1.2550
## 2 pred.absmodel 75499   -67499 -8.4374
## 3 pred.absmodel 63519     2790  0.0421
## 4 pred.absmodel 35008    -5008 -0.1669
## 5 pred.absmodel 53495   132640  0.7126
## 6 pred.absmodel 65929   -51272 -3.4981</code></pre>
<div class="sourceCode" id="cb2835"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2835-1"><a href="supervised-learning-regression.html#cb2835-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate RMSE and relative RMSE and compare</span></span>
<span id="cb2835-2"><a href="supervised-learning-regression.html#cb2835-2" aria-hidden="true" tabindex="-1"></a>income_long <span class="sc">%&gt;%</span> </span>
<span id="cb2835-3"><a href="supervised-learning-regression.html#cb2835-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># group by modeltype</span></span>
<span id="cb2835-4"><a href="supervised-learning-regression.html#cb2835-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(modeltype) <span class="sc">%&gt;%</span>      </span>
<span id="cb2835-5"><a href="supervised-learning-regression.html#cb2835-5" aria-hidden="true" tabindex="-1"></a>              <span class="co"># RMSE</span></span>
<span id="cb2835-6"><a href="supervised-learning-regression.html#cb2835-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarize</span>(<span class="at">rmse =</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(residual<span class="sc">^</span><span class="dv">2</span>)),  </span>
<span id="cb2835-7"><a href="supervised-learning-regression.html#cb2835-7" aria-hidden="true" tabindex="-1"></a>              <span class="co"># Root mean squared relative error</span></span>
<span id="cb2835-8"><a href="supervised-learning-regression.html#cb2835-8" aria-hidden="true" tabindex="-1"></a>              <span class="at">rmse.rel =</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(relerr<span class="sc">^</span><span class="dv">2</span>)))  </span></code></pre></div>
<pre><code>## # A tibble: 2 × 3
##   modeltype       rmse rmse.rel
##   &lt;chr&gt;          &lt;dbl&gt;    &lt;dbl&gt;
## 1 pred.absmodel 37448.     3.18
## 2 pred.logmodel 39235.     2.22</code></pre>
<p>You’ve seen how modeling log(income) can reduce the relative error of the fit, at the cost of increased RMSE. Which tradeoff to make depends on the goals of your project.</p>
</div>
</div>
<div id="transforming-iv-before-modeling" class="section level3 hasAnchor" number="20.3.4">
<h3><span class="header-section-number">20.3.4</span> Transforming IV before modeling<a href="supervised-learning-regression.html#transforming-iv-before-modeling" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="input-transforms-the-hockey-stick" class="section level4 hasAnchor" number="20.3.4.1">
<h4><span class="header-section-number">20.3.4.1</span> Input transforms: the “hockey stick”<a href="supervised-learning-regression.html#input-transforms-the-hockey-stick" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In this exercise, we will build a model to predict price from a measure of the house’s size. The <code>houseprice</code> dataset, has the columns:</p>
<ul>
<li><p><code>price</code>: house price in units of $1000</p></li>
<li><p><code>size</code>: surface area</p></li>
</ul>
<div class="sourceCode" id="cb2837"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2837-1"><a href="supervised-learning-regression.html#cb2837-1" aria-hidden="true" tabindex="-1"></a>houseprice <span class="ot">&lt;-</span> <span class="fu">read_rds</span>(<span class="st">&quot;data/houseprice.rds&quot;</span>)</span>
<span id="cb2837-2"><a href="supervised-learning-regression.html#cb2837-2" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(houseprice)</span></code></pre></div>
<pre><code>## Rows: 40
## Columns: 2
## $ size  &lt;int&gt; 72, 98, 92, 90, 44, 46, 90, 150, 94, 90, 90, 66, 142, 74, 86, 46…
## $ price &lt;int&gt; 156, 153, 230, 152, 42, 157, 113, 573, 202, 261, 175, 212, 486, …</code></pre>
<p>A scatterplot of the data shows that the data is quite non-linear: a sort of “hockey-stick” where price is fairly flat for smaller houses, but rises steeply as the house gets larger.</p>
<p>Quadratics and tritics are often good functional forms to express hockey-stick like relationships.</p>
<div class="sourceCode" id="cb2839"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2839-1"><a href="supervised-learning-regression.html#cb2839-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(houseprice, <span class="fu">aes</span>(size, price)) <span class="sc">+</span></span>
<span id="cb2839-2"><a href="supervised-learning-regression.html#cb2839-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb2839-3"><a href="supervised-learning-regression.html#cb2839-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_smooth</span>(<span class="at">se =</span> F)</span></code></pre></div>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and
## formula = &#39;y ~ x&#39;</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-1085-1.png" width="672" /></p>
<p>You will fit a model to predict price as a function of the squared size, and look at its fit on the training data.</p>
<div class="sourceCode" id="cb2841"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2841-1"><a href="supervised-learning-regression.html#cb2841-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a model of price as a function of squared size</span></span>
<span id="cb2841-2"><a href="supervised-learning-regression.html#cb2841-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Because ^ is also a symbol to express interactions, use the function I() to treat the expression x^2 “as is”: that is, as the square of x rather than the interaction of x with itself.</span></span>
<span id="cb2841-3"><a href="supervised-learning-regression.html#cb2841-3" aria-hidden="true" tabindex="-1"></a>model_sqr <span class="ot">&lt;-</span> <span class="fu">lm</span>(price <span class="sc">~</span> <span class="fu">I</span>(size<span class="sc">^</span><span class="dv">2</span>), houseprice)</span>
<span id="cb2841-4"><a href="supervised-learning-regression.html#cb2841-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2841-5"><a href="supervised-learning-regression.html#cb2841-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a model of price as a linear function of size</span></span>
<span id="cb2841-6"><a href="supervised-learning-regression.html#cb2841-6" aria-hidden="true" tabindex="-1"></a>model_lin <span class="ot">&lt;-</span> <span class="fu">lm</span>(price <span class="sc">~</span> size, houseprice)</span></code></pre></div>
<div class="sourceCode" id="cb2842"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2842-1"><a href="supervised-learning-regression.html#cb2842-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions and compare</span></span>
<span id="cb2842-2"><a href="supervised-learning-regression.html#cb2842-2" aria-hidden="true" tabindex="-1"></a>houseprice <span class="sc">%&gt;%</span> </span>
<span id="cb2842-3"><a href="supervised-learning-regression.html#cb2842-3" aria-hidden="true" tabindex="-1"></a>           <span class="co"># predictions from linear model</span></span>
<span id="cb2842-4"><a href="supervised-learning-regression.html#cb2842-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">pred_lin =</span> <span class="fu">predict</span>(model_lin, houseprice),</span>
<span id="cb2842-5"><a href="supervised-learning-regression.html#cb2842-5" aria-hidden="true" tabindex="-1"></a>           <span class="co"># predictions from quadratic model</span></span>
<span id="cb2842-6"><a href="supervised-learning-regression.html#cb2842-6" aria-hidden="true" tabindex="-1"></a>           <span class="at">pred_sqr =</span> <span class="fu">predict</span>(model_sqr, houseprice)) <span class="sc">%&gt;%</span>    </span>
<span id="cb2842-7"><a href="supervised-learning-regression.html#cb2842-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">gather</span>(<span class="at">key =</span> modeltype, <span class="at">value =</span> pred, pred_lin, pred_sqr)</span></code></pre></div>
<pre><code>##    size price modeltype  pred
## 1    72   156  pred_lin 160.8
## 2    98   153  pred_lin 263.9
## 3    92   230  pred_lin 240.1
## 4    90   152  pred_lin 232.2
## 5    44    42  pred_lin  49.8
## 6    46   157  pred_lin  57.7
## 7    90   113  pred_lin 232.2
## 8   150   573  pred_lin 470.1
## 9    94   202  pred_lin 248.0
## 10   90   261  pred_lin 232.2
## 11   90   175  pred_lin 232.2
## 12   66   212  pred_lin 137.0
## 13  142   486  pred_lin 438.4
## 14   74   109  pred_lin 168.7
## 15   86   220  pred_lin 216.3
## 16   46   186  pred_lin  57.7
## 17   54   133  pred_lin  89.4
## 18  130   360  pred_lin 390.8
## 19  122   283  pred_lin 359.1
## 20  118   380  pred_lin 343.2
## 21  100   185  pred_lin 271.8
## 22   74   186  pred_lin 168.7
## 23  146   459  pred_lin 454.2
## 24   92   167  pred_lin 240.1
## 25  100   171  pred_lin 271.8
## 26  140   547  pred_lin 430.4
## 27   94   170  pred_lin 248.0
## 28   90   286  pred_lin 232.2
## 29  120   293  pred_lin 351.1
## 30   70   109  pred_lin 152.9
## 31  100   205  pred_lin 271.8
## 32  132   514  pred_lin 398.7
## 33   58   175  pred_lin 105.3
## 34   92   249  pred_lin 240.1
## 35   76   234  pred_lin 176.7
## 36   90   242  pred_lin 232.2
## 37   66   177  pred_lin 137.0
## 38  134   399  pred_lin 406.7
## 39  140   511  pred_lin 430.4
## 40   64   107  pred_lin 129.1
## 41   72   156  pred_sqr 153.8
## 42   98   153  pred_sqr 246.5
## 43   92   230  pred_sqr 222.6
## 44   90   152  pred_sqr 214.9
## 45   44    42  pred_sqr  85.6
## 46   46   157  pred_sqr  89.4
## 47   90   113  pred_sqr 214.9
## 48  150   573  pred_sqr 517.0
## 49   94   202  pred_sqr 230.4
## 50   90   261  pred_sqr 214.9
## 51   90   175  pred_sqr 214.9
## 52   66   212  pred_sqr 136.4
## 53  142   486  pred_sqr 468.0
## 54   74   109  pred_sqr 159.9
## 55   86   220  pred_sqr 200.2
## 56   46   186  pred_sqr  89.4
## 57   54   133  pred_sqr 106.2
## 58  130   360  pred_sqr 399.5
## 59  122   283  pred_sqr 357.2
## 60  118   380  pred_sqr 337.1
## 61  100   185  pred_sqr 254.8
## 62   74   186  pred_sqr 159.9
## 63  146   459  pred_sqr 492.1
## 64   92   167  pred_sqr 222.6
## 65  100   171  pred_sqr 254.8
## 66  140   547  pred_sqr 456.1
## 67   94   170  pred_sqr 230.4
## 68   90   286  pred_sqr 214.9
## 69  120   293  pred_sqr 347.1
## 70   70   109  pred_sqr 147.8
## 71  100   205  pred_sqr 254.8
## 72  132   514  pred_sqr 410.5
## 73   58   175  pred_sqr 115.6
## 74   92   249  pred_sqr 222.6
## 75   76   234  pred_sqr 166.2
## 76   90   242  pred_sqr 214.9
## 77   66   177  pred_sqr 136.4
## 78  134   399  pred_sqr 421.7
## 79  140   511  pred_sqr 456.1
## 80   64   107  pred_sqr 130.9</code></pre>
<p>Graphically compare the predictions of the two models to the data.</p>
<div class="sourceCode" id="cb2844"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2844-1"><a href="supervised-learning-regression.html#cb2844-1" aria-hidden="true" tabindex="-1"></a>houseprice <span class="sc">%&gt;%</span> </span>
<span id="cb2844-2"><a href="supervised-learning-regression.html#cb2844-2" aria-hidden="true" tabindex="-1"></a>           <span class="co"># predictions from linear model</span></span>
<span id="cb2844-3"><a href="supervised-learning-regression.html#cb2844-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">pred_lin =</span> <span class="fu">predict</span>(model_lin, houseprice),</span>
<span id="cb2844-4"><a href="supervised-learning-regression.html#cb2844-4" aria-hidden="true" tabindex="-1"></a>           <span class="co"># predictions from quadratic model</span></span>
<span id="cb2844-5"><a href="supervised-learning-regression.html#cb2844-5" aria-hidden="true" tabindex="-1"></a>           <span class="at">pred_sqr =</span> <span class="fu">predict</span>(model_sqr, houseprice)) <span class="sc">%&gt;%</span>    </span>
<span id="cb2844-6"><a href="supervised-learning-regression.html#cb2844-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">gather</span>(<span class="at">key =</span> modeltype, <span class="at">value =</span> pred, pred_lin, pred_sqr) <span class="sc">%&gt;%</span></span>
<span id="cb2844-7"><a href="supervised-learning-regression.html#cb2844-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> size)) <span class="sc">+</span> </span>
<span id="cb2844-8"><a href="supervised-learning-regression.html#cb2844-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># actual prices</span></span>
<span id="cb2844-9"><a href="supervised-learning-regression.html#cb2844-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> price)) <span class="sc">+</span>               </span>
<span id="cb2844-10"><a href="supervised-learning-regression.html#cb2844-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># the predictions</span></span>
<span id="cb2844-11"><a href="supervised-learning-regression.html#cb2844-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> pred, <span class="at">color =</span> modeltype)) <span class="sc">+</span> </span>
<span id="cb2844-12"><a href="supervised-learning-regression.html#cb2844-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_color_brewer</span>(<span class="at">palette =</span> <span class="st">&quot;Dark2&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-1088-1.png" width="672" /></p>
<p>In this exercise, you will confirm whether the quadratic model would perform better on out-of-sample data. Since this dataset is small, you will use cross-validation.</p>
<div class="sourceCode" id="cb2845"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2845-1"><a href="supervised-learning-regression.html#cb2845-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a splitting plan for 3-fold cross validation</span></span>
<span id="cb2845-2"><a href="supervised-learning-regression.html#cb2845-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">34245</span>)  <span class="co"># set the seed for reproducibility</span></span>
<span id="cb2845-3"><a href="supervised-learning-regression.html#cb2845-3" aria-hidden="true" tabindex="-1"></a>splitPlan <span class="ot">&lt;-</span> <span class="fu">kWayCrossValidation</span>(<span class="fu">nrow</span>(houseprice), <span class="dv">3</span>, <span class="cn">NULL</span>, <span class="cn">NULL</span>)</span>
<span id="cb2845-4"><a href="supervised-learning-regression.html#cb2845-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2845-5"><a href="supervised-learning-regression.html#cb2845-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample code: get cross-val predictions for price ~ size</span></span>
<span id="cb2845-6"><a href="supervised-learning-regression.html#cb2845-6" aria-hidden="true" tabindex="-1"></a>houseprice<span class="sc">$</span>pred_lin <span class="ot">&lt;-</span> <span class="dv">0</span>  <span class="co"># initialize the prediction vector</span></span>
<span id="cb2845-7"><a href="supervised-learning-regression.html#cb2845-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>) {</span>
<span id="cb2845-8"><a href="supervised-learning-regression.html#cb2845-8" aria-hidden="true" tabindex="-1"></a>  split <span class="ot">&lt;-</span> splitPlan[[i]]</span>
<span id="cb2845-9"><a href="supervised-learning-regression.html#cb2845-9" aria-hidden="true" tabindex="-1"></a>  model_lin <span class="ot">&lt;-</span> <span class="fu">lm</span>(price <span class="sc">~</span> size, <span class="at">data =</span> houseprice[split<span class="sc">$</span>train,])</span>
<span id="cb2845-10"><a href="supervised-learning-regression.html#cb2845-10" aria-hidden="true" tabindex="-1"></a>  houseprice<span class="sc">$</span>pred_lin[split<span class="sc">$</span>app] <span class="ot">&lt;-</span> <span class="fu">predict</span>(model_lin, <span class="at">newdata =</span> houseprice[split<span class="sc">$</span>app,])</span>
<span id="cb2845-11"><a href="supervised-learning-regression.html#cb2845-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2845-12"><a href="supervised-learning-regression.html#cb2845-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2845-13"><a href="supervised-learning-regression.html#cb2845-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Get cross-val predictions for price as a function of size^2 (use fmla_sqr)</span></span>
<span id="cb2845-14"><a href="supervised-learning-regression.html#cb2845-14" aria-hidden="true" tabindex="-1"></a>houseprice<span class="sc">$</span>pred_sqr <span class="ot">&lt;-</span> <span class="dv">0</span> <span class="co"># initialize the prediction vector</span></span>
<span id="cb2845-15"><a href="supervised-learning-regression.html#cb2845-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>) {</span>
<span id="cb2845-16"><a href="supervised-learning-regression.html#cb2845-16" aria-hidden="true" tabindex="-1"></a>  split <span class="ot">&lt;-</span> splitPlan[[i]]</span>
<span id="cb2845-17"><a href="supervised-learning-regression.html#cb2845-17" aria-hidden="true" tabindex="-1"></a>  model_sqr <span class="ot">&lt;-</span> <span class="fu">lm</span>(price <span class="sc">~</span> <span class="fu">I</span>(size<span class="sc">^</span><span class="dv">2</span>), <span class="at">data =</span> houseprice[split<span class="sc">$</span>train, ])</span>
<span id="cb2845-18"><a href="supervised-learning-regression.html#cb2845-18" aria-hidden="true" tabindex="-1"></a>  houseprice<span class="sc">$</span>pred_sqr[split<span class="sc">$</span>app] <span class="ot">&lt;-</span> <span class="fu">predict</span>(model_sqr, <span class="at">newdata =</span> houseprice[split<span class="sc">$</span>app, ])</span>
<span id="cb2845-19"><a href="supervised-learning-regression.html#cb2845-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2845-20"><a href="supervised-learning-regression.html#cb2845-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2845-21"><a href="supervised-learning-regression.html#cb2845-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Gather the predictions and calculate the residuals</span></span>
<span id="cb2845-22"><a href="supervised-learning-regression.html#cb2845-22" aria-hidden="true" tabindex="-1"></a>houseprice_long <span class="ot">&lt;-</span> houseprice <span class="sc">%&gt;%</span></span>
<span id="cb2845-23"><a href="supervised-learning-regression.html#cb2845-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather</span>(<span class="at">key =</span> modeltype, <span class="at">value =</span> pred, pred_lin, pred_sqr) <span class="sc">%&gt;%</span></span>
<span id="cb2845-24"><a href="supervised-learning-regression.html#cb2845-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">residuals =</span> price <span class="sc">-</span> pred)</span>
<span id="cb2845-25"><a href="supervised-learning-regression.html#cb2845-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2845-26"><a href="supervised-learning-regression.html#cb2845-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare the cross-validated RMSE for the two models</span></span>
<span id="cb2845-27"><a href="supervised-learning-regression.html#cb2845-27" aria-hidden="true" tabindex="-1"></a>houseprice_long <span class="sc">%&gt;%</span> </span>
<span id="cb2845-28"><a href="supervised-learning-regression.html#cb2845-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(modeltype) <span class="sc">%&gt;%</span> <span class="co"># group by modeltype</span></span>
<span id="cb2845-29"><a href="supervised-learning-regression.html#cb2845-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">rmse =</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(residuals<span class="sc">^</span><span class="dv">2</span>)))</span></code></pre></div>
<pre><code>## # A tibble: 2 × 2
##   modeltype  rmse
##   &lt;chr&gt;     &lt;dbl&gt;
## 1 pred_lin   71.8
## 2 pred_sqr   60.5</code></pre>
<p>You’ve confirmed that the quadratic input tranformation improved the model.</p>
</div>
</div>
</div>
<div id="dealing-with-non-linear-responses" class="section level2 hasAnchor" number="20.4">
<h2><span class="header-section-number">20.4</span> Dealing with Non-Linear Responses<a href="supervised-learning-regression.html#dealing-with-non-linear-responses" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="logistic-regression-to-predict-probabilities" class="section level3 hasAnchor" number="20.4.1">
<h3><span class="header-section-number">20.4.1</span> Logistic regression to predict probabilities<a href="supervised-learning-regression.html#logistic-regression-to-predict-probabilities" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Evaluating a logistic regression model</p>
<p><span class="math inline">\(pseudoR^2 = 1 - \frac{deviance}{null.deviance}\)</span></p>
<ul>
<li><p>Deviance: analogous to variance (RSS)</p></li>
<li><p>Null deviance: Similar to <span class="math inline">\(SS_{Tot}\)</span></p></li>
<li><p><span class="math inline">\(pseudoR^2\)</span> : Deviance explained, close to 1 is the better</p></li>
</ul>
<div id="fit-a-logistic-regression-model" class="section level4 hasAnchor" number="20.4.1.1">
<h4><span class="header-section-number">20.4.1.1</span> Fit a logistic regression model<a href="supervised-learning-regression.html#fit-a-logistic-regression-model" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>You will estimate the probability that a sparrow survives a severe winter storm, based on physical characteristics of the sparrow.</p>
<p><code>sparrow</code> dataset has columns:</p>
<ul>
<li><p><code>status</code>: outcome variable, “Survived” or “Perished”</p></li>
<li><p><code>total_length</code>: length of the bird from tip of beak to tip of tail (mm)</p></li>
<li><p><code>weight</code>: in grams</p></li>
<li><p><code>humerus</code> : length of humerus (“upper arm bone” that connects the wing to the body) (inches)</p></li>
</ul>
<div class="sourceCode" id="cb2847"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2847-1"><a href="supervised-learning-regression.html#cb2847-1" aria-hidden="true" tabindex="-1"></a>sparrow <span class="ot">&lt;-</span> <span class="fu">read_rds</span>(<span class="st">&quot;data/sparrow.rds&quot;</span>)</span>
<span id="cb2847-2"><a href="supervised-learning-regression.html#cb2847-2" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(sparrow)</span></code></pre></div>
<pre><code>## Rows: 87
## Columns: 11
## $ status       &lt;fct&gt; Survived, Survived, Survived, Survived, Survived, Survive…
## $ age          &lt;chr&gt; &quot;adult&quot;, &quot;adult&quot;, &quot;adult&quot;, &quot;adult&quot;, &quot;adult&quot;, &quot;adult&quot;, &quot;ad…
## $ total_length &lt;int&gt; 154, 160, 155, 154, 156, 161, 157, 159, 158, 158, 160, 16…
## $ wingspan     &lt;int&gt; 241, 252, 243, 245, 247, 253, 251, 247, 247, 252, 252, 25…
## $ weight       &lt;dbl&gt; 24.5, 26.9, 26.9, 24.3, 24.1, 26.5, 24.6, 24.2, 23.6, 26.…
## $ beak_head    &lt;dbl&gt; 31.2, 30.8, 30.6, 31.7, 31.5, 31.8, 31.1, 31.4, 29.8, 32.…
## $ humerus      &lt;dbl&gt; 0.69, 0.74, 0.73, 0.74, 0.71, 0.78, 0.74, 0.73, 0.70, 0.7…
## $ femur        &lt;dbl&gt; 0.67, 0.71, 0.70, 0.69, 0.71, 0.74, 0.74, 0.72, 0.67, 0.7…
## $ legbone      &lt;dbl&gt; 1.02, 1.18, 1.15, 1.15, 1.13, 1.14, 1.15, 1.13, 1.08, 1.1…
## $ skull        &lt;dbl&gt; 0.59, 0.60, 0.60, 0.58, 0.57, 0.61, 0.61, 0.61, 0.60, 0.6…
## $ sternum      &lt;dbl&gt; 0.83, 0.84, 0.85, 0.84, 0.82, 0.89, 0.86, 0.79, 0.82, 0.8…</code></pre>
<div class="sourceCode" id="cb2849"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2849-1"><a href="supervised-learning-regression.html#cb2849-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the survived column</span></span>
<span id="cb2849-2"><a href="supervised-learning-regression.html#cb2849-2" aria-hidden="true" tabindex="-1"></a>sparrow<span class="sc">$</span>survived <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(sparrow<span class="sc">$</span>status <span class="sc">==</span> <span class="st">&quot;Survived&quot;</span>, <span class="cn">TRUE</span>, <span class="cn">FALSE</span>)</span>
<span id="cb2849-3"><a href="supervised-learning-regression.html#cb2849-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(sparrow)</span></code></pre></div>
<pre><code>##     status   age total_length wingspan weight beak_head humerus femur legbone
## 1 Survived adult          154      241   24.5      31.2    0.69  0.67    1.02
## 2 Survived adult          160      252   26.9      30.8    0.74  0.71    1.18
## 3 Survived adult          155      243   26.9      30.6    0.73  0.70    1.15
## 4 Survived adult          154      245   24.3      31.7    0.74  0.69    1.15
## 5 Survived adult          156      247   24.1      31.5    0.71  0.71    1.13
## 6 Survived adult          161      253   26.5      31.8    0.78  0.74    1.14
##   skull sternum survived
## 1  0.59    0.83     TRUE
## 2  0.60    0.84     TRUE
## 3  0.60    0.85     TRUE
## 4  0.58    0.84     TRUE
## 5  0.57    0.82     TRUE
## 6  0.61    0.89     TRUE</code></pre>
<div class="sourceCode" id="cb2851"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2851-1"><a href="supervised-learning-regression.html#cb2851-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the logistic regression model</span></span>
<span id="cb2851-2"><a href="supervised-learning-regression.html#cb2851-2" aria-hidden="true" tabindex="-1"></a>sparrow_model <span class="ot">&lt;-</span> <span class="fu">glm</span>(survived <span class="sc">~</span> total_length <span class="sc">+</span> weight <span class="sc">+</span> humerus, </span>
<span id="cb2851-3"><a href="supervised-learning-regression.html#cb2851-3" aria-hidden="true" tabindex="-1"></a>                     <span class="at">data =</span> sparrow, </span>
<span id="cb2851-4"><a href="supervised-learning-regression.html#cb2851-4" aria-hidden="true" tabindex="-1"></a>                     <span class="at">family =</span> <span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb2851-5"><a href="supervised-learning-regression.html#cb2851-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2851-6"><a href="supervised-learning-regression.html#cb2851-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Call summary</span></span>
<span id="cb2851-7"><a href="supervised-learning-regression.html#cb2851-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(sparrow_model)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = survived ~ total_length + weight + humerus, family = &quot;binomial&quot;, 
##     data = sparrow)
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)    46.881     16.963    2.76  0.00571 ** 
## total_length   -0.543      0.141   -3.86  0.00011 ***
## weight         -0.569      0.277   -2.05  0.04006 *  
## humerus        75.461     19.159    3.94 0.000082 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 118.008  on 86  degrees of freedom
## Residual deviance:  75.094  on 83  degrees of freedom
## AIC: 83.09
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<div class="sourceCode" id="cb2853"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2853-1"><a href="supervised-learning-regression.html#cb2853-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Call glance</span></span>
<span id="cb2853-2"><a href="supervised-learning-regression.html#cb2853-2" aria-hidden="true" tabindex="-1"></a>perf <span class="ot">&lt;-</span> <span class="fu">glance</span>(sparrow_model)</span>
<span id="cb2853-3"><a href="supervised-learning-regression.html#cb2853-3" aria-hidden="true" tabindex="-1"></a>perf</span></code></pre></div>
<pre><code>## # A tibble: 1 × 8
##   null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs
##           &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;
## 1          118.      86  -37.5  83.1  93.0     75.1          83    87</code></pre>
<div class="sourceCode" id="cb2855"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2855-1"><a href="supervised-learning-regression.html#cb2855-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate pseudo-R-squared</span></span>
<span id="cb2855-2"><a href="supervised-learning-regression.html#cb2855-2" aria-hidden="true" tabindex="-1"></a>(pseudoR2 <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> (perf<span class="sc">$</span>deviance <span class="sc">/</span> perf<span class="sc">$</span>null.deviance))</span></code></pre></div>
<pre><code>## [1] 0.364</code></pre>
</div>
<div id="predict" class="section level4 hasAnchor" number="20.4.1.2">
<h4><span class="header-section-number">20.4.1.2</span> Predict<a href="supervised-learning-regression.html#predict" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Recall that when calling <code>predict()</code> to get the predicted probabilities from a <code>glm()</code> model, you must specify that you want the response.</p>
<p><code>predict(model, type = "response")</code></p>
<p>You will also use the <code>GainCurvePlot()</code> function to plot the gain curve from the model predictions. If the model’s gain curve is close to the ideal (“wizard”) gain curve, then the model sorted the sparrows well.</p>
<div class="sourceCode" id="cb2857"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2857-1"><a href="supervised-learning-regression.html#cb2857-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb2857-2"><a href="supervised-learning-regression.html#cb2857-2" aria-hidden="true" tabindex="-1"></a>sparrow<span class="sc">$</span>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(sparrow_model, <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb2857-3"><a href="supervised-learning-regression.html#cb2857-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2857-4"><a href="supervised-learning-regression.html#cb2857-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Look at gain curve</span></span>
<span id="cb2857-5"><a href="supervised-learning-regression.html#cb2857-5" aria-hidden="true" tabindex="-1"></a><span class="fu">GainCurvePlot</span>(sparrow, <span class="st">&quot;pred&quot;</span>, <span class="st">&quot;survived&quot;</span>, <span class="st">&quot;sparrow survival model&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-1095-1.png" width="672" /></p>
<p>You see from the gain curve that the model follows the wizard curve for about the first 30% of the data, identifying about 45% of the surviving sparrows with only a few false positives.</p>
</div>
</div>
<div id="poisson-and-quasipoisson-regression-to-predict-counts" class="section level3 hasAnchor" number="20.4.2">
<h3><span class="header-section-number">20.4.2</span> Poisson and quasipoisson regression to predict counts<a href="supervised-learning-regression.html#poisson-and-quasipoisson-regression-to-predict-counts" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Predicting Counts: counts, integers in range [0, ∞]</p>
<p><strong>Poisson/Quasipoisson Regression</strong></p>
<p><code>glm(formula, data, family = "poisson" / "quasipoisson")</code></p>
<ul>
<li><p>outcome: integer</p>
<ul>
<li><p>counts: e.g. number of traffic tickets a driver gets</p></li>
<li><p>rates: e.g. number of website hits/day</p></li>
</ul></li>
<li><p>prediction: expected rate or intensity (not integral)</p>
<ul>
<li>expected : traffic tickets; expected hits/day</li>
</ul></li>
<li><p>Poisson vs. Quasipoisson</p>
<ul>
<li><p>Poisson assumes that <code>mean(y) = var(y)</code></p></li>
<li><p>If <code>var(y)</code> much different from <code>mean(y)</code> ⟶ use quasipoisson</p></li>
<li><p>If <code>var(y)</code> much close to <code>mean(y)</code> ⟶ use poisson</p></li>
</ul></li>
<li><p>Evaluate the model</p>
<ul>
<li><p><span class="math inline">\(pseudoR^2\)</span></p></li>
<li><p>RMSE</p></li>
</ul></li>
</ul>
<div id="fit-a-model-to-predict-counts" class="section level4 hasAnchor" number="20.4.2.1">
<h4><span class="header-section-number">20.4.2.1</span> Fit a model to predict counts<a href="supervised-learning-regression.html#fit-a-model-to-predict-counts" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>You will build a model to predict the number of bikes rented in an hour as a function of the weather, the type of day (holiday, working day, or weekend), and the time of day.</p>
<p>You will train the model on data from the month of July. The data frame has the columns:</p>
<ul>
<li><p><code>cnt</code>: the number of bikes rented in that hour (the outcome)</p></li>
<li><p><code>hr</code>: the hour of the day (0-23, as a factor)</p></li>
<li><p><code>holiday</code>: TRUE/FALSE</p></li>
<li><p><code>workingday</code>: TRUE if neither a holiday nor a weekend, else FALSE</p></li>
<li><p><code>weathersit</code>: categorical, “Clear to partly cloudy”/“Light Precipitation”/“Misty”</p></li>
<li><p><code>temp</code>: normalized temperature in Celsius</p></li>
<li><p><code>atemp</code>: normalized “feeling” temperature in Celsius</p></li>
<li><p><code>hum</code>: normalized humidity</p></li>
<li><p><code>windspeed</code>: normalized windspeed</p></li>
<li><p><code>instant</code>: the time index -- number of hours since beginning of dataset (not a variable)</p></li>
<li><p><code>mnth</code> and <code>yr</code>: month and year indices (not variables)</p></li>
</ul>
<div class="sourceCode" id="cb2858"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2858-1"><a href="supervised-learning-regression.html#cb2858-1" aria-hidden="true" tabindex="-1"></a>bikes <span class="ot">&lt;-</span> <span class="fu">load</span>(<span class="st">&quot;data/Bikes.RData&quot;</span>)</span>
<span id="cb2858-2"><a href="supervised-learning-regression.html#cb2858-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(bikesJuly)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    744 obs. of  12 variables:
##  $ hr        : Factor w/ 24 levels &quot;0&quot;,&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,..: 1 2 3 4 5 6 7 8 9 10 ...
##  $ holiday   : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...
##  $ workingday: logi  FALSE FALSE FALSE FALSE FALSE FALSE ...
##  $ weathersit: chr  &quot;Clear to partly cloudy&quot; &quot;Clear to partly cloudy&quot; &quot;Clear to partly cloudy&quot; &quot;Clear to partly cloudy&quot; ...
##  $ temp      : num  0.76 0.74 0.72 0.72 0.7 0.68 0.7 0.74 0.78 0.82 ...
##  $ atemp     : num  0.727 0.697 0.697 0.712 0.667 ...
##  $ hum       : num  0.66 0.7 0.74 0.84 0.79 0.79 0.79 0.7 0.62 0.56 ...
##  $ windspeed : num  0 0.1343 0.0896 0.1343 0.194 ...
##  $ cnt       : int  149 93 90 33 4 10 27 50 142 219 ...
##  $ instant   : int  13004 13005 13006 13007 13008 13009 13010 13011 13012 13013 ...
##  $ mnth      : int  7 7 7 7 7 7 7 7 7 7 ...
##  $ yr        : int  1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<p>Should you use poisson or quasipoisson regression?</p>
<div class="sourceCode" id="cb2860"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2860-1"><a href="supervised-learning-regression.html#cb2860-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the mean and variance of the outcome</span></span>
<span id="cb2860-2"><a href="supervised-learning-regression.html#cb2860-2" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">mean_bike =</span> <span class="fu">mean</span>(bikesJuly<span class="sc">$</span>cnt), <span class="at">var_bike =</span> <span class="fu">var</span>(bikesJuly<span class="sc">$</span>cnt))</span></code></pre></div>
<pre><code>## mean_bike  var_bike 
##       274     45864</code></pre>
<p>Since mean and var are much different, use quasipoisson.</p>
<div class="sourceCode" id="cb2862"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2862-1"><a href="supervised-learning-regression.html#cb2862-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model</span></span>
<span id="cb2862-2"><a href="supervised-learning-regression.html#cb2862-2" aria-hidden="true" tabindex="-1"></a>bike_model <span class="ot">&lt;-</span> <span class="fu">glm</span>(cnt <span class="sc">~</span> hr <span class="sc">+</span> holiday <span class="sc">+</span> workingday <span class="sc">+</span> weathersit <span class="sc">+</span> temp <span class="sc">+</span> atemp <span class="sc">+</span> hum <span class="sc">+</span> windspeed, </span>
<span id="cb2862-3"><a href="supervised-learning-regression.html#cb2862-3" aria-hidden="true" tabindex="-1"></a>                  bikesJuly, </span>
<span id="cb2862-4"><a href="supervised-learning-regression.html#cb2862-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">family =</span> <span class="st">&quot;quasipoisson&quot;</span>)</span>
<span id="cb2862-5"><a href="supervised-learning-regression.html#cb2862-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2862-6"><a href="supervised-learning-regression.html#cb2862-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Call glance</span></span>
<span id="cb2862-7"><a href="supervised-learning-regression.html#cb2862-7" aria-hidden="true" tabindex="-1"></a>(perf <span class="ot">&lt;-</span> <span class="fu">glance</span>(bike_model))</span></code></pre></div>
<pre><code>## # A tibble: 1 × 8
##   null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs
##           &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;
## 1       133365.     743     NA    NA    NA   28775.         712   744</code></pre>
<div class="sourceCode" id="cb2864"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2864-1"><a href="supervised-learning-regression.html#cb2864-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate pseudo-R-squared</span></span>
<span id="cb2864-2"><a href="supervised-learning-regression.html#cb2864-2" aria-hidden="true" tabindex="-1"></a>(pseudoR2 <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> (perf<span class="sc">$</span>deviance <span class="sc">/</span> perf<span class="sc">$</span>null.deviance))</span></code></pre></div>
<pre><code>## [1] 0.784</code></pre>
<p>As with a logistic model, you hope for a <span class="math inline">\(pseudoR^2\)</span> near 1.</p>
</div>
<div id="predict-on-new-data" class="section level4 hasAnchor" number="20.4.2.2">
<h4><span class="header-section-number">20.4.2.2</span> Predict on new data<a href="supervised-learning-regression.html#predict-on-new-data" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>You will use the model you built in the previous exercise to make predictions for the month of August. The dataset <code>bikesAugust</code> has the same columns as <code>bikesJuly</code>.</p>
<div class="sourceCode" id="cb2866"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2866-1"><a href="supervised-learning-regression.html#cb2866-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(bikesAugust)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    744 obs. of  12 variables:
##  $ hr        : Factor w/ 24 levels &quot;0&quot;,&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,..: 1 2 3 4 5 6 7 8 9 10 ...
##  $ holiday   : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...
##  $ workingday: logi  TRUE TRUE TRUE TRUE TRUE TRUE ...
##  $ weathersit: chr  &quot;Clear to partly cloudy&quot; &quot;Clear to partly cloudy&quot; &quot;Clear to partly cloudy&quot; &quot;Clear to partly cloudy&quot; ...
##  $ temp      : num  0.68 0.66 0.64 0.64 0.64 0.64 0.64 0.64 0.66 0.68 ...
##  $ atemp     : num  0.636 0.606 0.576 0.576 0.591 ...
##  $ hum       : num  0.79 0.83 0.83 0.83 0.78 0.78 0.78 0.83 0.78 0.74 ...
##  $ windspeed : num  0.1642 0.0896 0.1045 0.1045 0.1343 ...
##  $ cnt       : int  47 33 13 7 4 49 185 487 681 350 ...
##  $ instant   : int  13748 13749 13750 13751 13752 13753 13754 13755 13756 13757 ...
##  $ mnth      : int  8 8 8 8 8 8 8 8 8 8 ...
##  $ yr        : int  1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<p>Recall that you must specify <code>type = "response"</code> with <code>predict()</code> when predicting counts from a <code>glm</code> poisson or quasipoisson model.</p>
<div class="sourceCode" id="cb2868"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2868-1"><a href="supervised-learning-regression.html#cb2868-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on August data</span></span>
<span id="cb2868-2"><a href="supervised-learning-regression.html#cb2868-2" aria-hidden="true" tabindex="-1"></a>bikesAugust<span class="sc">$</span>pred  <span class="ot">&lt;-</span> <span class="fu">predict</span>(bike_model, </span>
<span id="cb2868-3"><a href="supervised-learning-regression.html#cb2868-3" aria-hidden="true" tabindex="-1"></a>                             <span class="at">newdata =</span> bikesAugust, </span>
<span id="cb2868-4"><a href="supervised-learning-regression.html#cb2868-4" aria-hidden="true" tabindex="-1"></a>                             <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb2868-5"><a href="supervised-learning-regression.html#cb2868-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2868-6"><a href="supervised-learning-regression.html#cb2868-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the RMSE</span></span>
<span id="cb2868-7"><a href="supervised-learning-regression.html#cb2868-7" aria-hidden="true" tabindex="-1"></a>bikesAugust <span class="sc">%&gt;%</span> </span>
<span id="cb2868-8"><a href="supervised-learning-regression.html#cb2868-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">residual =</span> cnt <span class="sc">-</span> pred) <span class="sc">%&gt;%</span></span>
<span id="cb2868-9"><a href="supervised-learning-regression.html#cb2868-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">rmse  =</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(residual<span class="sc">^</span><span class="dv">2</span>)))</span></code></pre></div>
<pre><code>##   rmse
## 1  113</code></pre>
<div class="sourceCode" id="cb2870"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2870-1"><a href="supervised-learning-regression.html#cb2870-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot predictions vs cnt (pred on x-axis)</span></span>
<span id="cb2870-2"><a href="supervised-learning-regression.html#cb2870-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(bikesAugust, <span class="fu">aes</span>(<span class="at">x =</span> pred, <span class="at">y =</span> cnt)) <span class="sc">+</span></span>
<span id="cb2870-3"><a href="supervised-learning-regression.html#cb2870-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb2870-4"><a href="supervised-learning-regression.html#cb2870-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">color =</span> <span class="st">&quot;darkblue&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-1102-1.png" width="672" /></p>
<p>(Quasi)poisson models predict non-negative rates, making them useful for count or frequency data.</p>
</div>
<div id="visualize-the-predictions" class="section level4 hasAnchor" number="20.4.2.3">
<h4><span class="header-section-number">20.4.2.3</span> Visualize the predictions<a href="supervised-learning-regression.html#visualize-the-predictions" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Since the bike rental data is <em>time series data</em>, you might be interested in how the model performs as a function of time. In this exercise, you will compare the predictions and actual rentals on an hourly basis, for the first 14 days of August.</p>
<div class="sourceCode" id="cb2871"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2871-1"><a href="supervised-learning-regression.html#cb2871-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(bikesAugust)</span></code></pre></div>
<pre><code>##   hr holiday workingday             weathersit temp atemp  hum windspeed cnt
## 1  0   FALSE       TRUE Clear to partly cloudy 0.68 0.636 0.79    0.1642  47
## 2  1   FALSE       TRUE Clear to partly cloudy 0.66 0.606 0.83    0.0896  33
## 3  2   FALSE       TRUE Clear to partly cloudy 0.64 0.576 0.83    0.1045  13
## 4  3   FALSE       TRUE Clear to partly cloudy 0.64 0.576 0.83    0.1045   7
## 5  4   FALSE       TRUE                  Misty 0.64 0.591 0.78    0.1343   4
## 6  5   FALSE       TRUE                  Misty 0.64 0.591 0.78    0.1343  49
##   instant mnth yr  pred
## 1   13748    8  1 94.96
## 2   13749    8  1 51.74
## 3   13750    8  1 37.98
## 4   13751    8  1 17.58
## 5   13752    8  1  9.36
## 6   13753    8  1 33.20</code></pre>
<p>The time index, <code>instant</code> counts the number of observations since the beginning of data collection. The sample code converts the instants to daily units, starting from 0.</p>
<div class="sourceCode" id="cb2873"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2873-1"><a href="supervised-learning-regression.html#cb2873-1" aria-hidden="true" tabindex="-1"></a>bikesAugust <span class="sc">%&gt;%</span> </span>
<span id="cb2873-2"><a href="supervised-learning-regression.html#cb2873-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># set start to 0, convert unit to days</span></span>
<span id="cb2873-3"><a href="supervised-learning-regression.html#cb2873-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">instant =</span> (instant <span class="sc">-</span> <span class="fu">min</span>(instant))<span class="sc">/</span><span class="dv">24</span>) <span class="sc">%&gt;%</span>  </span>
<span id="cb2873-4"><a href="supervised-learning-regression.html#cb2873-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># gather cnt and pred into a value column</span></span>
<span id="cb2873-5"><a href="supervised-learning-regression.html#cb2873-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather</span>(<span class="at">key =</span> valuetype, <span class="at">value =</span> value, cnt, pred) <span class="sc">%&gt;%</span></span>
<span id="cb2873-6"><a href="supervised-learning-regression.html#cb2873-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(instant <span class="sc">&lt;</span> <span class="dv">14</span>) <span class="sc">%&gt;%</span></span>
<span id="cb2873-7"><a href="supervised-learning-regression.html#cb2873-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(instant, valuetype, value) <span class="sc">%&gt;%</span></span>
<span id="cb2873-8"><a href="supervised-learning-regression.html#cb2873-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">head</span>()</span></code></pre></div>
<pre><code>##   instant valuetype value
## 1  0.0000       cnt    47
## 2  0.0417       cnt    33
## 3  0.0833       cnt    13
## 4  0.1250       cnt     7
## 5  0.1667       cnt     4
## 6  0.2083       cnt    49</code></pre>
<div class="sourceCode" id="cb2875"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2875-1"><a href="supervised-learning-regression.html#cb2875-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot predictions and cnt by date/time</span></span>
<span id="cb2875-2"><a href="supervised-learning-regression.html#cb2875-2" aria-hidden="true" tabindex="-1"></a>quasipoisson_plot <span class="ot">&lt;-</span> bikesAugust <span class="sc">%&gt;%</span> </span>
<span id="cb2875-3"><a href="supervised-learning-regression.html#cb2875-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">instant =</span> (instant <span class="sc">-</span> <span class="fu">min</span>(instant))<span class="sc">/</span><span class="dv">24</span>) <span class="sc">%&gt;%</span>  </span>
<span id="cb2875-4"><a href="supervised-learning-regression.html#cb2875-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather</span>(<span class="at">key =</span> valuetype, <span class="at">value =</span> value, cnt, pred) <span class="sc">%&gt;%</span></span>
<span id="cb2875-5"><a href="supervised-learning-regression.html#cb2875-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># restric to first 14 days</span></span>
<span id="cb2875-6"><a href="supervised-learning-regression.html#cb2875-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(instant <span class="sc">&lt;</span> <span class="dv">14</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb2875-7"><a href="supervised-learning-regression.html#cb2875-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># plot value by instant</span></span>
<span id="cb2875-8"><a href="supervised-learning-regression.html#cb2875-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> instant, <span class="at">y =</span> value, </span>
<span id="cb2875-9"><a href="supervised-learning-regression.html#cb2875-9" aria-hidden="true" tabindex="-1"></a>             <span class="at">color =</span> valuetype, <span class="at">linetype =</span> valuetype)) <span class="sc">+</span> </span>
<span id="cb2875-10"><a href="supervised-learning-regression.html#cb2875-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb2875-11"><a href="supervised-learning-regression.html#cb2875-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span> </span>
<span id="cb2875-12"><a href="supervised-learning-regression.html#cb2875-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="st">&quot;Day&quot;</span>, <span class="at">breaks =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">14</span>, <span class="at">labels =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">14</span>) <span class="sc">+</span> </span>
<span id="cb2875-13"><a href="supervised-learning-regression.html#cb2875-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_brewer</span>(<span class="at">palette =</span> <span class="st">&quot;Dark2&quot;</span>) <span class="sc">+</span> </span>
<span id="cb2875-14"><a href="supervised-learning-regression.html#cb2875-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Predicted August bike rentals, Quasipoisson model&quot;</span>)</span>
<span id="cb2875-15"><a href="supervised-learning-regression.html#cb2875-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2875-16"><a href="supervised-learning-regression.html#cb2875-16" aria-hidden="true" tabindex="-1"></a>quasipoisson_plot</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-1105-1.png" width="672" /></p>
<p>This model mostly identifies the slow and busy hours of the day, although it often underestimates peak demand.</p>
</div>
</div>
<div id="gam-to-learn-non-linear-transforms" class="section level3 hasAnchor" number="20.4.3">
<h3><span class="header-section-number">20.4.3</span> GAM to learn non-linear transforms<a href="supervised-learning-regression.html#gam-to-learn-non-linear-transforms" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Generalized Additive Models (GAMs)</strong></p>
<p>With GAM, the outcome depends additively on unknown smooth functions of the input variables. Automatically learn input variable transformations.</p>
<p>Using GAM to learn the transformations is useful when you don’t have the domain knowledge to tell you the correct transform.</p>
<p><code>mgcv</code> package:</p>
<p><code>gam(y ~ s(x1) + x2..., family, data)</code></p>
<ul>
<li><p>family</p>
<ul>
<li><p>gaussian (default): “regular” regression</p></li>
<li><p>binomial: probabilities</p></li>
<li><p>poisson/quasipoisson: counts</p></li>
</ul></li>
<li><p><code>s()</code> designates that variable should be non-linear</p>
<ul>
<li>Use <code>s()</code> with <em>continuous variables</em></li>
</ul></li>
<li><p>Best for larger datasets</p></li>
</ul>
<div id="model-with-gam" class="section level4 hasAnchor" number="20.4.3.1">
<h4><span class="header-section-number">20.4.3.1</span> Model with GAM<a href="supervised-learning-regression.html#model-with-gam" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>You will model the average leaf weight on a soybean plant as a function of time (after planting). As you will see, the soybean plant doesn’t grow at a steady rate, but rather has a “growth spurt” that eventually tapers off. Hence, leaf weight is not well described by a linear model.</p>
<div class="sourceCode" id="cb2876"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2876-1"><a href="supervised-learning-regression.html#cb2876-1" aria-hidden="true" tabindex="-1"></a>soybean <span class="ot">&lt;-</span> <span class="fu">load</span>(<span class="st">&quot;data/Soybean.RData&quot;</span>)</span>
<span id="cb2876-2"><a href="supervised-learning-regression.html#cb2876-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2876-3"><a href="supervised-learning-regression.html#cb2876-3" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(soybean_train)</span></code></pre></div>
<pre><code>## Rows: 330
## Columns: 5
## $ Plot    &lt;ord&gt; 1988F1, 1988F1, 1988F1, 1988F1, 1988F1, 1988F1, 1988F1, 1988F2…
## $ Variety &lt;fct&gt; F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F,…
## $ Year    &lt;fct&gt; 1988, 1988, 1988, 1988, 1988, 1988, 1988, 1988, 1988, 1988, 19…
## $ Time    &lt;dbl&gt; 14, 21, 28, 35, 49, 63, 77, 21, 28, 35, 49, 56, 70, 14, 21, 28…
## $ weight  &lt;dbl&gt; 0.106, 0.261, 0.666, 2.110, 6.230, 13.350, 17.751, 0.269, 0.77…</code></pre>
<p>Does the relationship look linear?</p>
<div class="sourceCode" id="cb2878"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2878-1"><a href="supervised-learning-regression.html#cb2878-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot weight vs Time (Time on x axis)</span></span>
<span id="cb2878-2"><a href="supervised-learning-regression.html#cb2878-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(soybean_train, <span class="fu">aes</span>(<span class="at">x =</span> Time, <span class="at">y =</span> weight)) <span class="sc">+</span> </span>
<span id="cb2878-3"><a href="supervised-learning-regression.html#cb2878-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() </span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-1107-1.png" width="672" /></p>
<p>Fit a generalized additive model.</p>
<div class="sourceCode" id="cb2879"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2879-1"><a href="supervised-learning-regression.html#cb2879-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the package mgcv</span></span>
<span id="cb2879-2"><a href="supervised-learning-regression.html#cb2879-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mgcv)</span>
<span id="cb2879-3"><a href="supervised-learning-regression.html#cb2879-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2879-4"><a href="supervised-learning-regression.html#cb2879-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the GAM Model</span></span>
<span id="cb2879-5"><a href="supervised-learning-regression.html#cb2879-5" aria-hidden="true" tabindex="-1"></a>model.gam <span class="ot">&lt;-</span> <span class="fu">gam</span>(weight <span class="sc">~</span> <span class="fu">s</span>(Time), <span class="at">data =</span> soybean_train, <span class="at">family =</span> gaussian)</span>
<span id="cb2879-6"><a href="supervised-learning-regression.html#cb2879-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2879-7"><a href="supervised-learning-regression.html#cb2879-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Call summary() on model.gam and look for R-squared</span></span>
<span id="cb2879-8"><a href="supervised-learning-regression.html#cb2879-8" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model.gam)</span></code></pre></div>
<pre><code>## 
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## weight ~ s(Time)
## 
## Parametric coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)    6.164      0.114    53.9 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##         edf Ref.df   F             p-value    
## s(Time) 8.5   8.93 338 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.902   Deviance explained = 90.4%
## GCV = 4.4395  Scale est. = 4.3117    n = 330</code></pre>
<p>The “deviance explained” reports the model’s unadjusted <span class="math inline">\(R^2\)</span></p>
<div class="sourceCode" id="cb2881"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2881-1"><a href="supervised-learning-regression.html#cb2881-1" aria-hidden="true" tabindex="-1"></a><span class="co"># linear model</span></span>
<span id="cb2881-2"><a href="supervised-learning-regression.html#cb2881-2" aria-hidden="true" tabindex="-1"></a>model.lin <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">formula =</span> weight <span class="sc">~</span> Time, soybean_train)</span>
<span id="cb2881-3"><a href="supervised-learning-regression.html#cb2881-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2881-4"><a href="supervised-learning-regression.html#cb2881-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Call summary() on model.lin and look for R-squared</span></span>
<span id="cb2881-5"><a href="supervised-learning-regression.html#cb2881-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model.lin)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = weight ~ Time, data = soybean_train)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -9.393 -1.710 -0.391  1.906 11.438 
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept) -6.55928    0.35853   -18.3 &lt;0.0000000000000002 ***
## Time         0.29209    0.00744    39.2 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.78 on 328 degrees of freedom
## Multiple R-squared:  0.824,  Adjusted R-squared:  0.824 
## F-statistic: 1.54e+03 on 1 and 328 DF,  p-value: &lt;0.0000000000000002</code></pre>
<p>For this data, the GAM appears to fit the data better than a linear model, as measured by the R-squared.</p>
<p>See the derived relationship between <code>Time</code> and <code>weight</code>.</p>
<div class="sourceCode" id="cb2883"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2883-1"><a href="supervised-learning-regression.html#cb2883-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Call plot() on model.gam</span></span>
<span id="cb2883-2"><a href="supervised-learning-regression.html#cb2883-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model.gam)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-1110-1.png" width="672" /></p>
</div>
<div id="predict-with-on-test-data" class="section level4 hasAnchor" number="20.4.3.2">
<h4><span class="header-section-number">20.4.3.2</span> Predict with on test data<a href="supervised-learning-regression.html#predict-with-on-test-data" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb2884"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2884-1"><a href="supervised-learning-regression.html#cb2884-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(soybean_test)</span></code></pre></div>
<pre><code>## Rows: 82
## Columns: 5
## $ Plot    &lt;ord&gt; 1988F1, 1988F1, 1988F1, 1988F2, 1988F2, 1988F2, 1988F3, 1988F3…
## $ Variety &lt;fct&gt; F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, P, P, P, P, P,…
## $ Year    &lt;fct&gt; 1988, 1988, 1988, 1988, 1988, 1988, 1988, 1988, 1988, 1988, 19…
## $ Time    &lt;dbl&gt; 42, 56, 70, 14, 42, 77, 49, 63, 14, 35, 63, 42, 14, 21, 28, 70…
## $ weight  &lt;dbl&gt; 3.560, 8.710, 16.342, 0.104, 2.930, 17.747, 6.130, 18.080, 0.1…</code></pre>
<p>For GAM models, the <code>predict()</code> method returns a matrix, so use <code>as.numeric()</code> to convert the matrix to a vector.</p>
<div class="sourceCode" id="cb2886"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2886-1"><a href="supervised-learning-regression.html#cb2886-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get predictions from linear model</span></span>
<span id="cb2886-2"><a href="supervised-learning-regression.html#cb2886-2" aria-hidden="true" tabindex="-1"></a>soybean_test<span class="sc">$</span>pred.lin <span class="ot">&lt;-</span> <span class="fu">predict</span>(model.lin, <span class="at">newdata =</span> soybean_test)</span>
<span id="cb2886-3"><a href="supervised-learning-regression.html#cb2886-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2886-4"><a href="supervised-learning-regression.html#cb2886-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get predictions from gam model</span></span>
<span id="cb2886-5"><a href="supervised-learning-regression.html#cb2886-5" aria-hidden="true" tabindex="-1"></a>soybean_test<span class="sc">$</span>pred.gam <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">predict</span>(model.gam, <span class="at">newdata =</span> soybean_test))</span>
<span id="cb2886-6"><a href="supervised-learning-regression.html#cb2886-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2886-7"><a href="supervised-learning-regression.html#cb2886-7" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(soybean_test)</span></code></pre></div>
<pre><code>## Grouped Data: weight ~ Time | Plot
##      Plot Variety Year Time weight pred.lin pred.gam
## 5  1988F1       F 1988   42  3.560     5.71     3.94
## 7  1988F1       F 1988   56  8.710     9.80     9.96
## 9  1988F1       F 1988   70 16.342    13.89    16.55
## 11 1988F2       F 1988   14  0.104    -2.47     0.13
## 15 1988F2       F 1988   42  2.930     5.71     3.94
## 19 1988F2       F 1988   77 17.747    15.93    18.68</code></pre>
<div class="sourceCode" id="cb2888"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2888-1"><a href="supervised-learning-regression.html#cb2888-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Gather the predictions into a &quot;long&quot; dataset</span></span>
<span id="cb2888-2"><a href="supervised-learning-regression.html#cb2888-2" aria-hidden="true" tabindex="-1"></a>soybean_long <span class="ot">&lt;-</span> soybean_test <span class="sc">%&gt;%</span></span>
<span id="cb2888-3"><a href="supervised-learning-regression.html#cb2888-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather</span>(<span class="at">key =</span> modeltype, <span class="at">value =</span> pred, pred.lin, pred.gam)</span>
<span id="cb2888-4"><a href="supervised-learning-regression.html#cb2888-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2888-5"><a href="supervised-learning-regression.html#cb2888-5" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(soybean_long)</span></code></pre></div>
<pre><code>##     Plot Variety Year Time weight modeltype  pred
## 1 1988F1       F 1988   42  3.560  pred.lin  5.71
## 2 1988F1       F 1988   56  8.710  pred.lin  9.80
## 3 1988F1       F 1988   70 16.342  pred.lin 13.89
## 4 1988F2       F 1988   14  0.104  pred.lin -2.47
## 5 1988F2       F 1988   42  2.930  pred.lin  5.71
## 6 1988F2       F 1988   77 17.747  pred.lin 15.93</code></pre>
<p>Calculate and compare the RMSE of both models.</p>
<div class="sourceCode" id="cb2890"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2890-1"><a href="supervised-learning-regression.html#cb2890-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the rmse</span></span>
<span id="cb2890-2"><a href="supervised-learning-regression.html#cb2890-2" aria-hidden="true" tabindex="-1"></a>soybean_long <span class="sc">%&gt;%</span></span>
<span id="cb2890-3"><a href="supervised-learning-regression.html#cb2890-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">residual =</span> weight <span class="sc">-</span> pred) <span class="sc">%&gt;%</span>     <span class="co"># residuals</span></span>
<span id="cb2890-4"><a href="supervised-learning-regression.html#cb2890-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(modeltype) <span class="sc">%&gt;%</span>                  <span class="co"># group by modeltype</span></span>
<span id="cb2890-5"><a href="supervised-learning-regression.html#cb2890-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">rmse =</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(residual<span class="sc">^</span><span class="dv">2</span>))) <span class="co"># calculate the RMSE</span></span></code></pre></div>
<pre><code>## # A tibble: 2 × 2
##   modeltype  rmse
##   &lt;chr&gt;     &lt;dbl&gt;
## 1 pred.gam   2.29
## 2 pred.lin   3.19</code></pre>
<p>Compare the predictions of each model against the actual average leaf weights.</p>
<div class="sourceCode" id="cb2892"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2892-1"><a href="supervised-learning-regression.html#cb2892-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare the predictions against actual weights on the test data</span></span>
<span id="cb2892-2"><a href="supervised-learning-regression.html#cb2892-2" aria-hidden="true" tabindex="-1"></a>soybean_long <span class="sc">%&gt;%</span></span>
<span id="cb2892-3"><a href="supervised-learning-regression.html#cb2892-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># the column for the x axis</span></span>
<span id="cb2892-4"><a href="supervised-learning-regression.html#cb2892-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Time)) <span class="sc">+</span></span>
<span id="cb2892-5"><a href="supervised-learning-regression.html#cb2892-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># the y-column for the scatterplot</span></span>
<span id="cb2892-6"><a href="supervised-learning-regression.html#cb2892-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> weight)) <span class="sc">+</span></span>
<span id="cb2892-7"><a href="supervised-learning-regression.html#cb2892-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># the y-column for the point-and-line plot</span></span>
<span id="cb2892-8"><a href="supervised-learning-regression.html#cb2892-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> pred, <span class="at">color =</span> modeltype)) <span class="sc">+</span>   </span>
<span id="cb2892-9"><a href="supervised-learning-regression.html#cb2892-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># the y-column for the point-and-line plot</span></span>
<span id="cb2892-10"><a href="supervised-learning-regression.html#cb2892-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> pred, <span class="at">color =</span> modeltype, <span class="at">linetype =</span> modeltype)) <span class="sc">+</span> </span>
<span id="cb2892-11"><a href="supervised-learning-regression.html#cb2892-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_brewer</span>(<span class="at">palette =</span> <span class="st">&quot;Dark2&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-1115-1.png" width="672" /></p>
<p>Notice that the linear model sometimes predicts negative weights! But GAM doesn’t.</p>
<p>The GAM learns the non-linear growth function of the soybean plants, including the fact that weight is never negative.</p>
</div>
</div>
</div>
<div id="tree-based-methods" class="section level2 hasAnchor" number="20.5">
<h2><span class="header-section-number">20.5</span> Tree-Based Methods<a href="supervised-learning-regression.html#tree-based-methods" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="random-forests" class="section level3 hasAnchor" number="20.5.1">
<h3><span class="header-section-number">20.5.1</span> Random forests<a href="supervised-learning-regression.html#random-forests" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>You will again build a model to predict the number of bikes rented in an hour as a function of the weather, the type of day (holiday, working day, or weekend), and the time of day. You will train the model on data from the month of July.</p>
<p>You will use the <code>ranger</code> package to fit the random forest model.</p>
<p><code>ranger(fmla, data, num.trees, respect.unordered.factors = "order")</code></p>
<ul>
<li><code>respect.unordered.factors</code>: specifies how to treat unordered factor variables.</li>
</ul>
<div class="sourceCode" id="cb2893"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2893-1"><a href="supervised-learning-regression.html#cb2893-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(bikesJuly)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    744 obs. of  12 variables:
##  $ hr        : Factor w/ 24 levels &quot;0&quot;,&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,..: 1 2 3 4 5 6 7 8 9 10 ...
##  $ holiday   : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...
##  $ workingday: logi  FALSE FALSE FALSE FALSE FALSE FALSE ...
##  $ weathersit: chr  &quot;Clear to partly cloudy&quot; &quot;Clear to partly cloudy&quot; &quot;Clear to partly cloudy&quot; &quot;Clear to partly cloudy&quot; ...
##  $ temp      : num  0.76 0.74 0.72 0.72 0.7 0.68 0.7 0.74 0.78 0.82 ...
##  $ atemp     : num  0.727 0.697 0.697 0.712 0.667 ...
##  $ hum       : num  0.66 0.7 0.74 0.84 0.79 0.79 0.79 0.7 0.62 0.56 ...
##  $ windspeed : num  0 0.1343 0.0896 0.1343 0.194 ...
##  $ cnt       : int  149 93 90 33 4 10 27 50 142 219 ...
##  $ instant   : int  13004 13005 13006 13007 13008 13009 13010 13011 13012 13013 ...
##  $ mnth      : int  7 7 7 7 7 7 7 7 7 7 ...
##  $ yr        : int  1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<p>Set up</p>
<div class="sourceCode" id="cb2895"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2895-1"><a href="supervised-learning-regression.html#cb2895-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Random seed to reproduce results</span></span>
<span id="cb2895-2"><a href="supervised-learning-regression.html#cb2895-2" aria-hidden="true" tabindex="-1"></a>seed <span class="ot">&lt;-</span> <span class="dv">423563</span></span>
<span id="cb2895-3"><a href="supervised-learning-regression.html#cb2895-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2895-4"><a href="supervised-learning-regression.html#cb2895-4" aria-hidden="true" tabindex="-1"></a><span class="co"># The outcome column</span></span>
<span id="cb2895-5"><a href="supervised-learning-regression.html#cb2895-5" aria-hidden="true" tabindex="-1"></a>outcome <span class="ot">&lt;-</span> <span class="st">&quot;cnt&quot;</span></span>
<span id="cb2895-6"><a href="supervised-learning-regression.html#cb2895-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2895-7"><a href="supervised-learning-regression.html#cb2895-7" aria-hidden="true" tabindex="-1"></a><span class="co"># The input variables</span></span>
<span id="cb2895-8"><a href="supervised-learning-regression.html#cb2895-8" aria-hidden="true" tabindex="-1"></a>vars <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;hr&quot;</span>, <span class="st">&quot;holiday&quot;</span>, <span class="st">&quot;workingday&quot;</span>, <span class="st">&quot;weathersit&quot;</span>, <span class="st">&quot;temp&quot;</span>, <span class="st">&quot;atemp&quot;</span>, <span class="st">&quot;hum&quot;</span>, <span class="st">&quot;windspeed&quot;</span>)</span>
<span id="cb2895-9"><a href="supervised-learning-regression.html#cb2895-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2895-10"><a href="supervised-learning-regression.html#cb2895-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the formula string for bikes rented as a function of the inputs</span></span>
<span id="cb2895-11"><a href="supervised-learning-regression.html#cb2895-11" aria-hidden="true" tabindex="-1"></a>(fmla <span class="ot">&lt;-</span> <span class="fu">paste</span>(outcome, <span class="st">&quot;~&quot;</span>, <span class="fu">paste</span>(vars, <span class="at">collapse =</span> <span class="st">&quot; + &quot;</span>)))</span></code></pre></div>
<pre><code>## [1] &quot;cnt ~ hr + holiday + workingday + weathersit + temp + atemp + hum + windspeed&quot;</code></pre>
<div class="sourceCode" id="cb2897"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2897-1"><a href="supervised-learning-regression.html#cb2897-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the package ranger</span></span>
<span id="cb2897-2"><a href="supervised-learning-regression.html#cb2897-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ranger)</span></code></pre></div>
<pre><code>## 
## Attaching package: &#39;ranger&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:randomForest&#39;:
## 
##     importance</code></pre>
<div class="sourceCode" id="cb2900"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2900-1"><a href="supervised-learning-regression.html#cb2900-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit and print the random forest model</span></span>
<span id="cb2900-2"><a href="supervised-learning-regression.html#cb2900-2" aria-hidden="true" tabindex="-1"></a>(bike_model_rf <span class="ot">&lt;-</span> <span class="fu">ranger</span>(fmla, <span class="co"># formula </span></span>
<span id="cb2900-3"><a href="supervised-learning-regression.html#cb2900-3" aria-hidden="true" tabindex="-1"></a>                         bikesJuly, <span class="co"># data</span></span>
<span id="cb2900-4"><a href="supervised-learning-regression.html#cb2900-4" aria-hidden="true" tabindex="-1"></a>                         <span class="at">num.trees =</span> <span class="dv">500</span>, </span>
<span id="cb2900-5"><a href="supervised-learning-regression.html#cb2900-5" aria-hidden="true" tabindex="-1"></a>                         <span class="at">respect.unordered.factors =</span> <span class="st">&quot;order&quot;</span>, </span>
<span id="cb2900-6"><a href="supervised-learning-regression.html#cb2900-6" aria-hidden="true" tabindex="-1"></a>                         <span class="at">seed =</span> seed))</span></code></pre></div>
<pre><code>## Ranger result
## 
## Call:
##  ranger(fmla, bikesJuly, num.trees = 500, respect.unordered.factors = &quot;order&quot;,      seed = seed) 
## 
## Type:                             Regression 
## Number of trees:                  500 
## Sample size:                      744 
## Number of independent variables:  8 
## Mtry:                             2 
## Target node size:                 5 
## Variable importance mode:         none 
## Splitrule:                        variance 
## OOB prediction error (MSE):       8231 
## R squared (OOB):                  0.821</code></pre>
<p>Now, predict bike rentals for the month of August.</p>
<p>The <code>predict()</code> function for a <code>ranger</code> model produces a list. One of the elements of this list is <code>predictions</code>, a vector of predicted values. Access <code>predictions</code> with the <code>$</code> notation.</p>
<div class="sourceCode" id="cb2902"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2902-1"><a href="supervised-learning-regression.html#cb2902-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the August data</span></span>
<span id="cb2902-2"><a href="supervised-learning-regression.html#cb2902-2" aria-hidden="true" tabindex="-1"></a>bikesAugust<span class="sc">$</span>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(bike_model_rf, bikesAugust)<span class="sc">$</span>predictions</span>
<span id="cb2902-3"><a href="supervised-learning-regression.html#cb2902-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2902-4"><a href="supervised-learning-regression.html#cb2902-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the RMSE of the predictions</span></span>
<span id="cb2902-5"><a href="supervised-learning-regression.html#cb2902-5" aria-hidden="true" tabindex="-1"></a>bikesAugust <span class="sc">%&gt;%</span> </span>
<span id="cb2902-6"><a href="supervised-learning-regression.html#cb2902-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">residual =</span> cnt <span class="sc">-</span> pred)  <span class="sc">%&gt;%</span> <span class="co"># calculate the residual</span></span>
<span id="cb2902-7"><a href="supervised-learning-regression.html#cb2902-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">rmse  =</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(residual<span class="sc">^</span><span class="dv">2</span>)))      <span class="co"># calculate rmse</span></span></code></pre></div>
<pre><code>##   rmse
## 1 97.2</code></pre>
<p>The poisson model you built for this data gave an RMSE of about 112.6. How does this model compare?</p>
<div class="sourceCode" id="cb2904"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2904-1"><a href="supervised-learning-regression.html#cb2904-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot actual outcome vs predictions (predictions on x-axis)</span></span>
<span id="cb2904-2"><a href="supervised-learning-regression.html#cb2904-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(bikesAugust, <span class="fu">aes</span>(<span class="at">x =</span> pred, <span class="at">y =</span> cnt)) <span class="sc">+</span> </span>
<span id="cb2904-3"><a href="supervised-learning-regression.html#cb2904-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb2904-4"><a href="supervised-learning-regression.html#cb2904-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-1120-1.png" width="672" /></p>
<p>This random forest model outperforms the poisson count model on the same data; it is discovering more complex non-linear or non-additive relationships in the data.</p>
<p><em>Visualize random forest bike model predictions</em></p>
<p>Recall that the quasipoisson model mostly identified the pattern of slow and busy hours in the day, but it somewhat underestimated peak demands. You would like to see how the random forest model compares.</p>
<div class="sourceCode" id="cb2905"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2905-1"><a href="supervised-learning-regression.html#cb2905-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(bikesAugust)</span></code></pre></div>
<pre><code>##   hr holiday workingday             weathersit temp atemp  hum windspeed cnt
## 1  0   FALSE       TRUE Clear to partly cloudy 0.68 0.636 0.79    0.1642  47
## 2  1   FALSE       TRUE Clear to partly cloudy 0.66 0.606 0.83    0.0896  33
## 3  2   FALSE       TRUE Clear to partly cloudy 0.64 0.576 0.83    0.1045  13
## 4  3   FALSE       TRUE Clear to partly cloudy 0.64 0.576 0.83    0.1045   7
## 5  4   FALSE       TRUE                  Misty 0.64 0.591 0.78    0.1343   4
## 6  5   FALSE       TRUE                  Misty 0.64 0.591 0.78    0.1343  49
##   instant mnth yr pred
## 1   13748    8  1 77.4
## 2   13749    8  1 36.2
## 3   13750    8  1 38.3
## 4   13751    8  1 28.2
## 5   13752    8  1 42.2
## 6   13753    8  1 52.4</code></pre>
<div class="sourceCode" id="cb2907"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2907-1"><a href="supervised-learning-regression.html#cb2907-1" aria-hidden="true" tabindex="-1"></a>first_two_weeks <span class="ot">&lt;-</span> bikesAugust <span class="sc">%&gt;%</span> </span>
<span id="cb2907-2"><a href="supervised-learning-regression.html#cb2907-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Set start to 0, convert unit to days</span></span>
<span id="cb2907-3"><a href="supervised-learning-regression.html#cb2907-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">instant =</span> (instant <span class="sc">-</span> <span class="fu">min</span>(instant)) <span class="sc">/</span> <span class="dv">24</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb2907-4"><a href="supervised-learning-regression.html#cb2907-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Gather cnt and pred into a column named value with key valuetype</span></span>
<span id="cb2907-5"><a href="supervised-learning-regression.html#cb2907-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather</span>(<span class="at">key =</span> valuetype, <span class="at">value =</span> value, cnt, pred) <span class="sc">%&gt;%</span></span>
<span id="cb2907-6"><a href="supervised-learning-regression.html#cb2907-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Filter for rows in the first two</span></span>
<span id="cb2907-7"><a href="supervised-learning-regression.html#cb2907-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(instant <span class="sc">&lt;</span> <span class="dv">14</span>)</span>
<span id="cb2907-8"><a href="supervised-learning-regression.html#cb2907-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2907-9"><a href="supervised-learning-regression.html#cb2907-9" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(first_two_weeks)</span></code></pre></div>
<pre><code>##   hr holiday workingday             weathersit temp atemp  hum windspeed
## 1  0   FALSE       TRUE Clear to partly cloudy 0.68 0.636 0.79    0.1642
## 2  1   FALSE       TRUE Clear to partly cloudy 0.66 0.606 0.83    0.0896
## 3  2   FALSE       TRUE Clear to partly cloudy 0.64 0.576 0.83    0.1045
## 4  3   FALSE       TRUE Clear to partly cloudy 0.64 0.576 0.83    0.1045
## 5  4   FALSE       TRUE                  Misty 0.64 0.591 0.78    0.1343
## 6  5   FALSE       TRUE                  Misty 0.64 0.591 0.78    0.1343
##   instant mnth yr valuetype value
## 1  0.0000    8  1       cnt    47
## 2  0.0417    8  1       cnt    33
## 3  0.0833    8  1       cnt    13
## 4  0.1250    8  1       cnt     7
## 5  0.1667    8  1       cnt     4
## 6  0.2083    8  1       cnt    49</code></pre>
<p>Plot the predictions and actual counts by hour for the first 14 days of August.</p>
<div class="sourceCode" id="cb2909"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2909-1"><a href="supervised-learning-regression.html#cb2909-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot predictions and cnt by date/time </span></span>
<span id="cb2909-2"><a href="supervised-learning-regression.html#cb2909-2" aria-hidden="true" tabindex="-1"></a>randomforest_plot <span class="ot">&lt;-</span> </span>
<span id="cb2909-3"><a href="supervised-learning-regression.html#cb2909-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(first_two_weeks, <span class="fu">aes</span>(<span class="at">x =</span> instant, <span class="at">y =</span> value, </span>
<span id="cb2909-4"><a href="supervised-learning-regression.html#cb2909-4" aria-hidden="true" tabindex="-1"></a>                                <span class="at">color =</span> valuetype, <span class="at">linetype =</span> valuetype)) <span class="sc">+</span> </span>
<span id="cb2909-5"><a href="supervised-learning-regression.html#cb2909-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb2909-6"><a href="supervised-learning-regression.html#cb2909-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>() <span class="sc">+</span> </span>
<span id="cb2909-7"><a href="supervised-learning-regression.html#cb2909-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_continuous</span>(<span class="st">&quot;Day&quot;</span>, <span class="at">breaks =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">14</span>, <span class="at">labels =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">14</span>) <span class="sc">+</span> </span>
<span id="cb2909-8"><a href="supervised-learning-regression.html#cb2909-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_color_brewer</span>(<span class="at">palette =</span> <span class="st">&quot;Dark2&quot;</span>) <span class="sc">+</span> </span>
<span id="cb2909-9"><a href="supervised-learning-regression.html#cb2909-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggtitle</span>(<span class="st">&quot;Predicted August bike rentals, Random Forest model&quot;</span>)</span>
<span id="cb2909-10"><a href="supervised-learning-regression.html#cb2909-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2909-11"><a href="supervised-learning-regression.html#cb2909-11" aria-hidden="true" tabindex="-1"></a>randomforest_plot</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-1123-1.png" width="672" /></p>
<p>The random forest model captured the day-to-day variations in peak demand better than the quasipoisson model, but it still underestmates peak demand, and also overestimates minimum demand. So there is still room for improvement.</p>
</div>
<div id="one-hot-encoding" class="section level3 hasAnchor" number="20.5.2">
<h3><span class="header-section-number">20.5.2</span> One-Hot-Encoding<a href="supervised-learning-regression.html#one-hot-encoding" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="vtreat" class="section level4 hasAnchor" number="20.5.2.1">
<h4><span class="header-section-number">20.5.2.1</span> vtreat<a href="supervised-learning-regression.html#vtreat" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><code>vtreat</code> creates a <em>treatment plan</em> to transform categorical variables into indicator variables (coded <code>"lev"</code>), and to clean bad values out of numerical variables (coded <code>"clean"</code>).</p>
<p>To design a treatment plan:</p>
<p><code>treatplan &lt;- designTreatmentsZ(data, varlist)</code></p>
<ul>
<li><p><code>data</code>: the original training data frame</p></li>
<li><p><code>varlist</code>: a vector of input variables to be treated (as strings).</p></li>
</ul>
<p><code>designTreatmentsZ()</code> returns a list with an element <code>scoreFrame</code>: a data frame that includes the names and types of the new variables:</p>
<div class="sourceCode" id="cb2910"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2910-1"><a href="supervised-learning-regression.html#cb2910-1" aria-hidden="true" tabindex="-1"></a>scoreFrame <span class="ot">&lt;-</span> treatplan <span class="sc">%&gt;%</span> </span>
<span id="cb2910-2"><a href="supervised-learning-regression.html#cb2910-2" aria-hidden="true" tabindex="-1"></a>            magrittr<span class="sc">::</span><span class="fu">use_series</span>(scoreFrame) <span class="sc">%&gt;%</span> </span>
<span id="cb2910-3"><a href="supervised-learning-regression.html#cb2910-3" aria-hidden="true" tabindex="-1"></a>            <span class="fu">select</span>(varName, origName, code)</span></code></pre></div>
<ul>
<li><p><code>varName</code>: the name of the new treated variable</p></li>
<li><p><code>origName</code>: the name of the original variable that the treated variable comes from</p></li>
<li><p><code>code</code>: the type of the new variable.</p>
<ul>
<li><p><code>"clean"</code>: a numerical variable with no NAs or NaNs</p></li>
<li><p><code>"lev"</code>: an indicator variable for a specific level of the original categorical variable.</p></li>
</ul></li>
</ul>
<p>For these exercises, we want <code>varName</code> where <code>code</code> is either <code>"clean"</code> or <code>"lev"</code>:</p>
<div class="sourceCode" id="cb2911"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2911-1"><a href="supervised-learning-regression.html#cb2911-1" aria-hidden="true" tabindex="-1"></a>newvarlist <span class="ot">&lt;-</span> scoreFrame <span class="sc">%&gt;%</span> </span>
<span id="cb2911-2"><a href="supervised-learning-regression.html#cb2911-2" aria-hidden="true" tabindex="-1"></a>             <span class="fu">filter</span>(code <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;clean&quot;</span>, <span class="st">&quot;lev&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb2911-3"><a href="supervised-learning-regression.html#cb2911-3" aria-hidden="true" tabindex="-1"></a>             magrittr<span class="sc">::</span><span class="fu">use_series</span>(varName)</span></code></pre></div>
<p>To transform the dataset into all numerical and one-hot-encoded variables:</p>
<p><code>data.treat &lt;- prepare(treatplan, data, varRestrictions = newvarlist)</code></p>
<ul>
<li><p><code>treatplan</code>: the treatment plan</p></li>
<li><p><code>data</code>: the data frame to be treated</p></li>
<li><p><code>varRestrictions</code>: the variables desired in the treated data</p></li>
</ul>
<p>Assume that <code>color</code> and <code>size</code> are input variables, and <code>popularity</code> is the outcome to be predicted.</p>
<div class="sourceCode" id="cb2912"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2912-1"><a href="supervised-learning-regression.html#cb2912-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(magrittr)</span>
<span id="cb2912-2"><a href="supervised-learning-regression.html#cb2912-2" aria-hidden="true" tabindex="-1"></a>dframe <span class="ot">&lt;-</span> <span class="fu">read_tsv</span>(<span class="st">&quot;data/dframe_vtreat.txt&quot;</span>)</span>
<span id="cb2912-3"><a href="supervised-learning-regression.html#cb2912-3" aria-hidden="true" tabindex="-1"></a>dframe</span></code></pre></div>
<pre><code>## # A tibble: 10 × 3
##    color  size popularity
##    &lt;chr&gt; &lt;dbl&gt;      &lt;dbl&gt;
##  1 r        11      1.40 
##  2 b        15      0.922
##  3 g        14      1.20 
##  4 b        13      1.08 
##  5 r        11      0.804
##  6 r         9      1.10 
##  7 g        12      0.875
##  8 b         7      0.695
##  9 g        12      0.883
## 10 g        11      1.02</code></pre>
<div class="sourceCode" id="cb2914"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2914-1"><a href="supervised-learning-regression.html#cb2914-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a vector of variable names</span></span>
<span id="cb2914-2"><a href="supervised-learning-regression.html#cb2914-2" aria-hidden="true" tabindex="-1"></a>vars <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;color&quot;</span>, <span class="st">&quot;size&quot;</span>)</span>
<span id="cb2914-3"><a href="supervised-learning-regression.html#cb2914-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2914-4"><a href="supervised-learning-regression.html#cb2914-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the treatment plan</span></span>
<span id="cb2914-5"><a href="supervised-learning-regression.html#cb2914-5" aria-hidden="true" tabindex="-1"></a>treatplan <span class="ot">&lt;-</span> <span class="fu">designTreatmentsZ</span>(dframe, vars)</span></code></pre></div>
<pre><code>## [1] &quot;vtreat 1.6.4 inspecting inputs Mon Jan 15 16:10:00 2024&quot;
## [1] &quot;designing treatments Mon Jan 15 16:10:00 2024&quot;
## [1] &quot; have initial level statistics Mon Jan 15 16:10:00 2024&quot;
## [1] &quot; scoring treatments Mon Jan 15 16:10:00 2024&quot;
## [1] &quot;have treatment plan Mon Jan 15 16:10:00 2024&quot;</code></pre>
<div class="sourceCode" id="cb2916"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2916-1"><a href="supervised-learning-regression.html#cb2916-1" aria-hidden="true" tabindex="-1"></a>treatplan</span></code></pre></div>
<pre><code>## [1] &quot;treatmentplan&quot;
##   origName       varName  code rsq sig extraModelDegrees
## 1    color    color_catP  catP   0   1                 2
## 2     size          size clean   0   1                 0
## 3    color color_lev_x_b   lev   0   1                 0
## 4    color color_lev_x_g   lev   0   1                 0
## 5    color color_lev_x_r   lev   0   1                 0</code></pre>
<div class="sourceCode" id="cb2918"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2918-1"><a href="supervised-learning-regression.html#cb2918-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Examine the scoreFrame</span></span>
<span id="cb2918-2"><a href="supervised-learning-regression.html#cb2918-2" aria-hidden="true" tabindex="-1"></a>(scoreFrame <span class="ot">&lt;-</span> treatplan <span class="sc">%&gt;%</span></span>
<span id="cb2918-3"><a href="supervised-learning-regression.html#cb2918-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">use_series</span>(scoreFrame) <span class="sc">%&gt;%</span></span>
<span id="cb2918-4"><a href="supervised-learning-regression.html#cb2918-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">select</span>(varName, origName, code))</span></code></pre></div>
<pre><code>##         varName origName  code
## 1    color_catP    color  catP
## 2          size     size clean
## 3 color_lev_x_b    color   lev
## 4 color_lev_x_g    color   lev
## 5 color_lev_x_r    color   lev</code></pre>
<div class="sourceCode" id="cb2920"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2920-1"><a href="supervised-learning-regression.html#cb2920-1" aria-hidden="true" tabindex="-1"></a><span class="co"># We only want the rows with codes &quot;clean&quot; or &quot;lev&quot;</span></span>
<span id="cb2920-2"><a href="supervised-learning-regression.html#cb2920-2" aria-hidden="true" tabindex="-1"></a>(newvars <span class="ot">&lt;-</span> scoreFrame <span class="sc">%&gt;%</span></span>
<span id="cb2920-3"><a href="supervised-learning-regression.html#cb2920-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(code <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;clean&quot;</span>, <span class="st">&quot;lev&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb2920-4"><a href="supervised-learning-regression.html#cb2920-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">use_series</span>(varName))</span></code></pre></div>
<pre><code>## [1] &quot;size&quot;          &quot;color_lev_x_b&quot; &quot;color_lev_x_g&quot; &quot;color_lev_x_r&quot;</code></pre>
<div class="sourceCode" id="cb2922"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2922-1"><a href="supervised-learning-regression.html#cb2922-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the treated training data</span></span>
<span id="cb2922-2"><a href="supervised-learning-regression.html#cb2922-2" aria-hidden="true" tabindex="-1"></a>(dframe.treat <span class="ot">&lt;-</span> <span class="fu">prepare</span>(treatplan, dframe, <span class="at">varRestriction =</span> newvars))</span></code></pre></div>
<pre><code>##    size color_lev_x_b color_lev_x_g color_lev_x_r
## 1    11             0             0             1
## 2    15             1             0             0
## 3    14             0             1             0
## 4    13             1             0             0
## 5    11             0             0             1
## 6     9             0             0             1
## 7    12             0             1             0
## 8     7             1             0             0
## 9    12             0             1             0
## 10   11             0             1             0</code></pre>
</div>
<div id="novel-levels" class="section level4 hasAnchor" number="20.5.2.2">
<h4><span class="header-section-number">20.5.2.2</span> Novel levels<a href="supervised-learning-regression.html#novel-levels" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>When a level of a categorical variable is rare, sometimes it will fail to show up in training data. If that rare level then appears in future data, downstream models may not know what to do with it. When such <em>novel levels</em> appear, using <code>model.matrix</code> or <code>caret::dummyVars</code> to one-hot-encode will not work correctly.</p>
<p><code>vtreat</code> is a “safer” alternative to <code>model.matrix</code> for one-hot-encoding, because it can manage novel levels safely. <code>vtreat</code> also manages missing values in the data (both categorical and continuous).</p>
<p>In this exercise, you will see how <code>vtreat</code> handles categorical values that did not appear in the training set.</p>
<p>Are there colors in <code>testframe</code> that didn’t appear in <code>dframe</code>?</p>
<div class="sourceCode" id="cb2924"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2924-1"><a href="supervised-learning-regression.html#cb2924-1" aria-hidden="true" tabindex="-1"></a>testframe <span class="ot">&lt;-</span> <span class="fu">read_tsv</span>(<span class="st">&quot;data/testframe_vtreat.txt&quot;</span>)</span>
<span id="cb2924-2"><a href="supervised-learning-regression.html#cb2924-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2924-3"><a href="supervised-learning-regression.html#cb2924-3" aria-hidden="true" tabindex="-1"></a><span class="fu">list</span>(<span class="at">testframe =</span> <span class="fu">unique</span>(testframe<span class="sc">$</span>color), <span class="at">dframe =</span> <span class="fu">unique</span>(dframe<span class="sc">$</span>color))</span></code></pre></div>
<pre><code>## $testframe
## [1] &quot;g&quot; &quot;y&quot; &quot;b&quot; &quot;r&quot;
## 
## $dframe
## [1] &quot;r&quot; &quot;b&quot; &quot;g&quot;</code></pre>
<div class="sourceCode" id="cb2926"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2926-1"><a href="supervised-learning-regression.html#cb2926-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use prepare() to one-hot-encode testframe</span></span>
<span id="cb2926-2"><a href="supervised-learning-regression.html#cb2926-2" aria-hidden="true" tabindex="-1"></a>(testframe.treat <span class="ot">&lt;-</span> <span class="fu">prepare</span>(treatplan, testframe, <span class="at">varRestriction =</span> newvars))</span></code></pre></div>
<pre><code>##    size color_lev_x_b color_lev_x_g color_lev_x_r
## 1     7             0             1             0
## 2     8             0             1             0
## 3    10             0             0             0
## 4    12             1             0             0
## 5     6             0             0             0
## 6     8             0             0             1
## 7    12             0             1             0
## 8    12             1             0             0
## 9    12             0             0             0
## 10    8             1             0             0</code></pre>
<p>As you saw, vtreat encodes novel colors like yellow that were not present in the data as all zeros: ‘none of the known colors’. This allows downstream models to accept these novel values without crashing.</p>
</div>
<div id="vtreat-the-bike-rental-data" class="section level4 hasAnchor" number="20.5.2.3">
<h4><span class="header-section-number">20.5.2.3</span> vtreat the bike rental data<a href="supervised-learning-regression.html#vtreat-the-bike-rental-data" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In this exercise, you will create one-hot-encoded data frames of the July/August bike data, for use with <code>xgboost</code> later on.</p>
<p>Set the flag <code>verbose=FALSE</code> to prevent the function from printing too many messages.</p>
<div class="sourceCode" id="cb2928"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2928-1"><a href="supervised-learning-regression.html#cb2928-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The outcome column</span></span>
<span id="cb2928-2"><a href="supervised-learning-regression.html#cb2928-2" aria-hidden="true" tabindex="-1"></a>outcome <span class="ot">&lt;-</span> <span class="st">&quot;cnt&quot;</span></span>
<span id="cb2928-3"><a href="supervised-learning-regression.html#cb2928-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2928-4"><a href="supervised-learning-regression.html#cb2928-4" aria-hidden="true" tabindex="-1"></a><span class="co"># The input columns</span></span>
<span id="cb2928-5"><a href="supervised-learning-regression.html#cb2928-5" aria-hidden="true" tabindex="-1"></a>vars <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;hr&quot;</span>, <span class="st">&quot;holiday&quot;</span>, <span class="st">&quot;workingday&quot;</span>, <span class="st">&quot;weathersit&quot;</span>, <span class="st">&quot;temp&quot;</span>, <span class="st">&quot;atemp&quot;</span>, <span class="st">&quot;hum&quot;</span>, <span class="st">&quot;windspeed&quot;</span>)</span>
<span id="cb2928-6"><a href="supervised-learning-regression.html#cb2928-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2928-7"><a href="supervised-learning-regression.html#cb2928-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the treatment plan from bikesJuly (the training data)</span></span>
<span id="cb2928-8"><a href="supervised-learning-regression.html#cb2928-8" aria-hidden="true" tabindex="-1"></a>treatplan <span class="ot">&lt;-</span> <span class="fu">designTreatmentsZ</span>(bikesJuly, vars, <span class="at">verbose =</span> <span class="cn">FALSE</span>)</span>
<span id="cb2928-9"><a href="supervised-learning-regression.html#cb2928-9" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(treatplan)</span></code></pre></div>
<pre><code>##               Length Class           Mode     
## treatments    9      -none-          list     
## scoreFrame    8      data.frame      list     
## outcomename   1      -none-          character
## vtreatVersion 1      package_version list     
## outcomeType   1      -none-          character
## outcomeTarget 1      -none-          character
## meanY         1      -none-          logical  
## splitmethod   1      -none-          character</code></pre>
<div class="sourceCode" id="cb2930"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2930-1"><a href="supervised-learning-regression.html#cb2930-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the &quot;clean&quot; and &quot;lev&quot; variables from the scoreFrame</span></span>
<span id="cb2930-2"><a href="supervised-learning-regression.html#cb2930-2" aria-hidden="true" tabindex="-1"></a>(newvars <span class="ot">&lt;-</span> treatplan <span class="sc">%&gt;%</span></span>
<span id="cb2930-3"><a href="supervised-learning-regression.html#cb2930-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">use_series</span>(scoreFrame) <span class="sc">%&gt;%</span>        </span>
<span id="cb2930-4"><a href="supervised-learning-regression.html#cb2930-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># get the rows you care about</span></span>
<span id="cb2930-5"><a href="supervised-learning-regression.html#cb2930-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(code <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;clean&quot;</span>, <span class="st">&quot;lev&quot;</span>)) <span class="sc">%&gt;%</span>  </span>
<span id="cb2930-6"><a href="supervised-learning-regression.html#cb2930-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># get the varName column</span></span>
<span id="cb2930-7"><a href="supervised-learning-regression.html#cb2930-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">use_series</span>(varName))           </span></code></pre></div>
<pre><code>##  [1] &quot;holiday&quot;                                
##  [2] &quot;workingday&quot;                             
##  [3] &quot;temp&quot;                                   
##  [4] &quot;atemp&quot;                                  
##  [5] &quot;hum&quot;                                    
##  [6] &quot;windspeed&quot;                              
##  [7] &quot;hr_lev_x_0&quot;                             
##  [8] &quot;hr_lev_x_1&quot;                             
##  [9] &quot;hr_lev_x_10&quot;                            
## [10] &quot;hr_lev_x_11&quot;                            
## [11] &quot;hr_lev_x_12&quot;                            
## [12] &quot;hr_lev_x_13&quot;                            
## [13] &quot;hr_lev_x_14&quot;                            
## [14] &quot;hr_lev_x_15&quot;                            
## [15] &quot;hr_lev_x_16&quot;                            
## [16] &quot;hr_lev_x_17&quot;                            
## [17] &quot;hr_lev_x_18&quot;                            
## [18] &quot;hr_lev_x_19&quot;                            
## [19] &quot;hr_lev_x_2&quot;                             
## [20] &quot;hr_lev_x_20&quot;                            
## [21] &quot;hr_lev_x_21&quot;                            
## [22] &quot;hr_lev_x_22&quot;                            
## [23] &quot;hr_lev_x_23&quot;                            
## [24] &quot;hr_lev_x_3&quot;                             
## [25] &quot;hr_lev_x_4&quot;                             
## [26] &quot;hr_lev_x_5&quot;                             
## [27] &quot;hr_lev_x_6&quot;                             
## [28] &quot;hr_lev_x_7&quot;                             
## [29] &quot;hr_lev_x_8&quot;                             
## [30] &quot;hr_lev_x_9&quot;                             
## [31] &quot;weathersit_lev_x_Clear_to_partly_cloudy&quot;
## [32] &quot;weathersit_lev_x_Light_Precipitation&quot;   
## [33] &quot;weathersit_lev_x_Misty&quot;</code></pre>
<div class="sourceCode" id="cb2932"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2932-1"><a href="supervised-learning-regression.html#cb2932-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare the training data</span></span>
<span id="cb2932-2"><a href="supervised-learning-regression.html#cb2932-2" aria-hidden="true" tabindex="-1"></a>bikesJuly.treat <span class="ot">&lt;-</span> <span class="fu">prepare</span>(treatplan, bikesJuly,  <span class="at">varRestriction =</span> newvars)</span>
<span id="cb2932-3"><a href="supervised-learning-regression.html#cb2932-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2932-4"><a href="supervised-learning-regression.html#cb2932-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare the test data</span></span>
<span id="cb2932-5"><a href="supervised-learning-regression.html#cb2932-5" aria-hidden="true" tabindex="-1"></a>bikesAugust.treat <span class="ot">&lt;-</span> <span class="fu">prepare</span>(treatplan, bikesAugust,  <span class="at">varRestriction =</span> newvars)</span>
<span id="cb2932-6"><a href="supervised-learning-regression.html#cb2932-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2932-7"><a href="supervised-learning-regression.html#cb2932-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Call str() on the treated data</span></span>
<span id="cb2932-8"><a href="supervised-learning-regression.html#cb2932-8" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(bikesJuly.treat)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    744 obs. of  33 variables:
##  $ holiday                                : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ workingday                             : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ temp                                   : num  0.76 0.74 0.72 0.72 0.7 0.68 0.7 0.74 0.78 0.82 ...
##  $ atemp                                  : num  0.727 0.697 0.697 0.712 0.667 ...
##  $ hum                                    : num  0.66 0.7 0.74 0.84 0.79 0.79 0.79 0.7 0.62 0.56 ...
##  $ windspeed                              : num  0 0.1343 0.0896 0.1343 0.194 ...
##  $ hr_lev_x_0                             : num  1 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_1                             : num  0 1 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_10                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_11                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_12                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_13                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_14                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_15                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_16                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_17                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_18                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_19                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_2                             : num  0 0 1 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_20                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_21                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_22                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_23                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_3                             : num  0 0 0 1 0 0 0 0 0 0 ...
##  $ hr_lev_x_4                             : num  0 0 0 0 1 0 0 0 0 0 ...
##  $ hr_lev_x_5                             : num  0 0 0 0 0 1 0 0 0 0 ...
##  $ hr_lev_x_6                             : num  0 0 0 0 0 0 1 0 0 0 ...
##  $ hr_lev_x_7                             : num  0 0 0 0 0 0 0 1 0 0 ...
##  $ hr_lev_x_8                             : num  0 0 0 0 0 0 0 0 1 0 ...
##  $ hr_lev_x_9                             : num  0 0 0 0 0 0 0 0 0 1 ...
##  $ weathersit_lev_x_Clear_to_partly_cloudy: num  1 1 1 1 1 1 1 1 1 1 ...
##  $ weathersit_lev_x_Light_Precipitation   : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ weathersit_lev_x_Misty                 : num  0 0 0 0 0 0 0 0 0 0 ...</code></pre>
<div class="sourceCode" id="cb2934"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2934-1"><a href="supervised-learning-regression.html#cb2934-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(bikesAugust.treat)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    744 obs. of  33 variables:
##  $ holiday                                : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ workingday                             : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ temp                                   : num  0.68 0.66 0.64 0.64 0.64 0.64 0.64 0.64 0.66 0.68 ...
##  $ atemp                                  : num  0.636 0.606 0.576 0.576 0.591 ...
##  $ hum                                    : num  0.79 0.83 0.83 0.83 0.78 0.78 0.78 0.83 0.78 0.74 ...
##  $ windspeed                              : num  0.1642 0.0896 0.1045 0.1045 0.1343 ...
##  $ hr_lev_x_0                             : num  1 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_1                             : num  0 1 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_10                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_11                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_12                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_13                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_14                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_15                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_16                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_17                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_18                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_19                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_2                             : num  0 0 1 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_20                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_21                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_22                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_23                            : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ hr_lev_x_3                             : num  0 0 0 1 0 0 0 0 0 0 ...
##  $ hr_lev_x_4                             : num  0 0 0 0 1 0 0 0 0 0 ...
##  $ hr_lev_x_5                             : num  0 0 0 0 0 1 0 0 0 0 ...
##  $ hr_lev_x_6                             : num  0 0 0 0 0 0 1 0 0 0 ...
##  $ hr_lev_x_7                             : num  0 0 0 0 0 0 0 1 0 0 ...
##  $ hr_lev_x_8                             : num  0 0 0 0 0 0 0 0 1 0 ...
##  $ hr_lev_x_9                             : num  0 0 0 0 0 0 0 0 0 1 ...
##  $ weathersit_lev_x_Clear_to_partly_cloudy: num  1 1 1 1 0 0 1 0 0 0 ...
##  $ weathersit_lev_x_Light_Precipitation   : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ weathersit_lev_x_Misty                 : num  0 0 0 0 1 1 0 1 1 1 ...</code></pre>
<p>The bike data is now in completely numeric form, ready to use with xgboost. Note that the treated data does not include the outcome column.</p>
</div>
</div>
<div id="gradient-boosting" class="section level3 hasAnchor" number="20.5.3">
<h3><span class="header-section-number">20.5.3</span> Gradient boosting<a href="supervised-learning-regression.html#gradient-boosting" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><em>Gradient boosting</em> is an ensemble method that builds up a model by incrementally improving the existing one. Repeat until either the residuals are small enough, or the maximum number of iterations is reached.</p>
<p><strong>Regularization: learning rate</strong></p>
<p><em>η</em> ∈ (0, 1)</p>
<ul>
<li><p>Larger <em>η</em> : faster learning</p></li>
<li><p>Smaller <em>η</em> : less risk of over</p></li>
</ul>
<p><strong><code>xgboost</code> package:</strong></p>
<ol style="list-style-type: decimal">
<li><p>Run <code>xgb.cv()</code> with a large number of rounds (trees).</p></li>
<li><p><code>xgb.cv()$evaluation_log</code> : records estimated RMSE for each round.</p>
<ul>
<li>Find the number of trees that minimizes estimated RMSE: <span class="math inline">\(n_{best}\)</span></li>
</ul></li>
<li><p>Run <code>xgboost()</code>, setting <code>nrounds</code> = <span class="math inline">\(n_{best}\)</span></p></li>
</ol>
<div id="find-the-right-number-of-trees" class="section level4 hasAnchor" number="20.5.3.1">
<h4><span class="header-section-number">20.5.3.1</span> Find the right number of trees<a href="supervised-learning-regression.html#find-the-right-number-of-trees" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In this exercise, you will get ready to build a gradient boosting model to predict the number of bikes rented in an hour as a function of the weather and the type and time of day. You will train the model on data from the month of July.</p>
<p>Remember that <code>bikesJuly.treat</code> no longer has the outcome column, so you must get it from the untreated data: <code>bikesJuly$cnt</code>.</p>
<p>You will use the <code>xgboost</code> package to fit the random forest model.</p>
<ul>
<li><p><code>xgb.cv()</code> uses cross-validation to estimate the out-of-sample learning error as each new tree is added to the model.</p></li>
<li><p>The appropriate number of trees to use in the final model is the number that <em>minimizes the holdout RMSE</em>.</p></li>
</ul>
<p>The key arguments to the <code>xgb.cv()</code> call are:</p>
<ul>
<li><p><code>data</code>: a numeric matrix.</p></li>
<li><p><code>label</code>: vector of outcomes (also numeric).</p></li>
<li><p><code>nrounds</code>: the maximum number of rounds (trees to build).</p></li>
<li><p><code>nfold</code>: the number of folds for the cross-validation. 5 is a good number.</p></li>
<li><p><code>objective</code>: <code>"reg:squarederror"</code> for continuous outcomes.</p></li>
<li><p><code>eta</code>: the learning rate.</p></li>
<li><p><code>max_depth</code>: maximum depth of trees.</p></li>
<li><p><code>early_stopping_rounds</code>: after this many rounds without improvement, stop.</p></li>
<li><p><code>verbose</code>: <code>FALSE</code> to stay silent.</p></li>
</ul>
<div class="sourceCode" id="cb2936"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2936-1"><a href="supervised-learning-regression.html#cb2936-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb2936-2"><a href="supervised-learning-regression.html#cb2936-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2936-3"><a href="supervised-learning-regression.html#cb2936-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the package xgboost</span></span>
<span id="cb2936-4"><a href="supervised-learning-regression.html#cb2936-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(xgboost)</span></code></pre></div>
<pre><code>## 
## Attaching package: &#39;xgboost&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     slice</code></pre>
<div class="sourceCode" id="cb2939"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2939-1"><a href="supervised-learning-regression.html#cb2939-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Run xgb.cv</span></span>
<span id="cb2939-2"><a href="supervised-learning-regression.html#cb2939-2" aria-hidden="true" tabindex="-1"></a>cv <span class="ot">&lt;-</span> <span class="fu">xgb.cv</span>(<span class="at">data =</span> <span class="fu">as.matrix</span>(bikesJuly.treat), </span>
<span id="cb2939-3"><a href="supervised-learning-regression.html#cb2939-3" aria-hidden="true" tabindex="-1"></a>            <span class="at">label =</span> bikesJuly<span class="sc">$</span>cnt,</span>
<span id="cb2939-4"><a href="supervised-learning-regression.html#cb2939-4" aria-hidden="true" tabindex="-1"></a>            <span class="at">nrounds =</span> <span class="dv">50</span>,</span>
<span id="cb2939-5"><a href="supervised-learning-regression.html#cb2939-5" aria-hidden="true" tabindex="-1"></a>            <span class="at">nfold =</span> <span class="dv">5</span>,</span>
<span id="cb2939-6"><a href="supervised-learning-regression.html#cb2939-6" aria-hidden="true" tabindex="-1"></a>            <span class="at">objective =</span> <span class="st">&quot;reg:squarederror&quot;</span>,</span>
<span id="cb2939-7"><a href="supervised-learning-regression.html#cb2939-7" aria-hidden="true" tabindex="-1"></a>            <span class="at">eta =</span> <span class="fl">0.75</span>,</span>
<span id="cb2939-8"><a href="supervised-learning-regression.html#cb2939-8" aria-hidden="true" tabindex="-1"></a>            <span class="at">max_depth =</span> <span class="dv">5</span>,</span>
<span id="cb2939-9"><a href="supervised-learning-regression.html#cb2939-9" aria-hidden="true" tabindex="-1"></a>            <span class="at">early_stopping_rounds =</span> <span class="dv">5</span>,</span>
<span id="cb2939-10"><a href="supervised-learning-regression.html#cb2939-10" aria-hidden="true" tabindex="-1"></a>            <span class="at">verbose =</span> <span class="cn">FALSE</span>   <span class="co"># silent</span></span>
<span id="cb2939-11"><a href="supervised-learning-regression.html#cb2939-11" aria-hidden="true" tabindex="-1"></a>); cv</span></code></pre></div>
<pre><code>## ##### xgb.cv 5-folds
##  iter train_rmse_mean train_rmse_std test_rmse_mean test_rmse_std
##     1           161.5          1.255          168.8          6.00
##     2           121.2          1.156          134.6          4.69
##     3           105.4          2.290          120.9          8.65
##     4            92.3          1.555          107.1          6.42
##     5            81.0          4.094          101.4          3.83
##     6            70.4          4.588           96.1          4.49
##     7            65.1          4.510           92.9          3.76
##     8            59.8          4.005           90.1          2.85
##     9            56.6          4.103           89.3          3.80
##    10            52.7          4.536           88.2          4.51
##    11            49.1          2.629           87.4          2.48
##    12            46.1          2.230           87.0          2.87
##    13            43.3          2.285           86.1          3.00
##    14            41.5          2.421           85.7          2.98
##    15            39.3          2.870           84.7          2.67
##    16            37.2          2.554           84.4          2.72
##    17            35.7          2.733           84.7          3.29
##    18            33.8          2.237           84.1          3.43
##    19            32.1          1.887           84.4          3.93
##    20            30.9          2.122           84.2          3.63
##    21            29.6          2.054           83.8          3.28
##    22            28.1          1.892           83.7          3.65
##    23            27.2          1.968           83.6          3.81
##    24            26.4          2.126           83.5          3.84
##    25            25.5          2.208           83.3          3.97
##    26            24.5          2.143           83.5          4.10
##    27            23.2          2.056           83.3          3.76
##    28            22.4          1.767           83.2          3.82
##    29            21.4          1.618           83.2          3.96
##    30            20.7          1.415           83.4          4.08
##    31            20.0          1.348           83.5          4.07
##    32            19.2          1.164           83.4          4.24
##    33            18.6          0.933           83.1          4.50
##    34            18.1          0.766           83.4          4.56
##    35            17.6          0.839           83.6          4.61
##    36            17.1          0.800           83.6          4.44
##    37            16.6          0.843           83.7          4.27
##    38            16.0          0.717           83.6          4.06
##  iter train_rmse_mean train_rmse_std test_rmse_mean test_rmse_std
## Best iteration:
##  iter train_rmse_mean train_rmse_std test_rmse_mean test_rmse_std
##    33            18.6          0.933           83.1           4.5</code></pre>
<div class="sourceCode" id="cb2941"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2941-1"><a href="supervised-learning-regression.html#cb2941-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(cv)</span></code></pre></div>
<pre><code>##                 Length Class      Mode   
## call            10     -none-     call   
## params           4     -none-     list   
## callbacks        2     -none-     list   
## evaluation_log   5     data.table list   
## niter            1     -none-     numeric
## nfeatures        1     -none-     numeric
## folds            5     -none-     list   
## best_iteration   1     -none-     numeric
## best_ntreelimit  1     -none-     numeric</code></pre>
<p>Each row of the <code>evaluation_log</code> corresponds to an additional tree, so the row number tells you the number of trees in the model.</p>
<div class="sourceCode" id="cb2943"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2943-1"><a href="supervised-learning-regression.html#cb2943-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the evaluation log </span></span>
<span id="cb2943-2"><a href="supervised-learning-regression.html#cb2943-2" aria-hidden="true" tabindex="-1"></a>elog <span class="ot">&lt;-</span> cv<span class="sc">$</span>evaluation_log</span>
<span id="cb2943-3"><a href="supervised-learning-regression.html#cb2943-3" aria-hidden="true" tabindex="-1"></a>elog</span></code></pre></div>
<pre><code>##     iter train_rmse_mean train_rmse_std test_rmse_mean test_rmse_std
##  1:    1           161.5          1.255          168.8          6.00
##  2:    2           121.2          1.156          134.6          4.69
##  3:    3           105.4          2.290          120.9          8.65
##  4:    4            92.3          1.555          107.1          6.42
##  5:    5            81.0          4.094          101.4          3.83
##  6:    6            70.4          4.588           96.1          4.49
##  7:    7            65.1          4.510           92.9          3.76
##  8:    8            59.8          4.005           90.1          2.85
##  9:    9            56.6          4.103           89.3          3.80
## 10:   10            52.7          4.536           88.2          4.51
## 11:   11            49.1          2.629           87.4          2.48
## 12:   12            46.1          2.230           87.0          2.87
## 13:   13            43.3          2.285           86.1          3.00
## 14:   14            41.5          2.421           85.7          2.98
## 15:   15            39.3          2.870           84.7          2.67
## 16:   16            37.2          2.554           84.4          2.72
## 17:   17            35.7          2.733           84.7          3.29
## 18:   18            33.8          2.237           84.1          3.43
## 19:   19            32.1          1.887           84.4          3.93
## 20:   20            30.9          2.122           84.2          3.63
## 21:   21            29.6          2.054           83.8          3.28
## 22:   22            28.1          1.892           83.7          3.65
## 23:   23            27.2          1.968           83.6          3.81
## 24:   24            26.4          2.126           83.5          3.84
## 25:   25            25.5          2.208           83.3          3.97
## 26:   26            24.5          2.143           83.5          4.10
## 27:   27            23.2          2.056           83.3          3.76
## 28:   28            22.4          1.767           83.2          3.82
## 29:   29            21.4          1.618           83.2          3.96
## 30:   30            20.7          1.415           83.4          4.08
## 31:   31            20.0          1.348           83.5          4.07
## 32:   32            19.2          1.164           83.4          4.24
## 33:   33            18.6          0.933           83.1          4.50
## 34:   34            18.1          0.766           83.4          4.56
## 35:   35            17.6          0.839           83.6          4.61
## 36:   36            17.1          0.800           83.6          4.44
## 37:   37            16.6          0.843           83.7          4.27
## 38:   38            16.0          0.717           83.6          4.06
##     iter train_rmse_mean train_rmse_std test_rmse_mean test_rmse_std</code></pre>
<div class="sourceCode" id="cb2945"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2945-1"><a href="supervised-learning-regression.html#cb2945-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Determine and print how many trees minimize training and test error</span></span>
<span id="cb2945-2"><a href="supervised-learning-regression.html#cb2945-2" aria-hidden="true" tabindex="-1"></a>elog <span class="sc">%&gt;%</span> </span>
<span id="cb2945-3"><a href="supervised-learning-regression.html#cb2945-3" aria-hidden="true" tabindex="-1"></a>   <span class="co"># find the index of min(train_rmse_mean)</span></span>
<span id="cb2945-4"><a href="supervised-learning-regression.html#cb2945-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">summarize</span>(<span class="at">ntrees.train =</span> <span class="fu">which.min</span>(train_rmse_mean),</span>
<span id="cb2945-5"><a href="supervised-learning-regression.html#cb2945-5" aria-hidden="true" tabindex="-1"></a>             <span class="co"># find the index of min(test_rmse_mean)</span></span>
<span id="cb2945-6"><a href="supervised-learning-regression.html#cb2945-6" aria-hidden="true" tabindex="-1"></a>             <span class="at">ntrees.test  =</span> <span class="fu">which.min</span>(test_rmse_mean))   </span></code></pre></div>
<pre><code>##   ntrees.train ntrees.test
## 1           38          33</code></pre>
<p>In most cases, <code>ntrees.test</code> is less than <code>ntrees.train</code>. The training error keeps decreasing even after the test error starts to increase. It’s important to use cross-validation to find the right number of trees (as determined by ntrees.test) and avoid an overfit model.</p>
</div>
<div id="fit-xgboost-model-and-predict" class="section level4 hasAnchor" number="20.5.3.2">
<h4><span class="header-section-number">20.5.3.2</span> Fit xgboost model and predict<a href="supervised-learning-regression.html#fit-xgboost-model-and-predict" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>You will fit a gradient boosting model using <code>xgboost()</code> to predict the number of bikes rented in an hour as a function of the weather and the type and time of day. You will train the model on data from the month of July and predict on data for the month of August.</p>
<div class="sourceCode" id="cb2947"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2947-1"><a href="supervised-learning-regression.html#cb2947-1" aria-hidden="true" tabindex="-1"></a><span class="co"># best number of trees</span></span>
<span id="cb2947-2"><a href="supervised-learning-regression.html#cb2947-2" aria-hidden="true" tabindex="-1"></a>ntrees <span class="ot">&lt;-</span> <span class="dv">30</span></span>
<span id="cb2947-3"><a href="supervised-learning-regression.html#cb2947-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2947-4"><a href="supervised-learning-regression.html#cb2947-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb2947-5"><a href="supervised-learning-regression.html#cb2947-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2947-6"><a href="supervised-learning-regression.html#cb2947-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Run xgboost on training data</span></span>
<span id="cb2947-7"><a href="supervised-learning-regression.html#cb2947-7" aria-hidden="true" tabindex="-1"></a>bike_model_xgb <span class="ot">&lt;-</span> <span class="fu">xgboost</span>(</span>
<span id="cb2947-8"><a href="supervised-learning-regression.html#cb2947-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> <span class="fu">as.matrix</span>(bikesJuly.treat), <span class="co"># training data as matrix</span></span>
<span id="cb2947-9"><a href="supervised-learning-regression.html#cb2947-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">label =</span> bikesJuly<span class="sc">$</span>cnt,             <span class="co"># column of outcomes</span></span>
<span id="cb2947-10"><a href="supervised-learning-regression.html#cb2947-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">nrounds =</span> ntrees,                  <span class="co"># number of trees to build</span></span>
<span id="cb2947-11"><a href="supervised-learning-regression.html#cb2947-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">objective =</span> <span class="st">&quot;reg:squarederror&quot;</span>,    <span class="co"># objective</span></span>
<span id="cb2947-12"><a href="supervised-learning-regression.html#cb2947-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">eta =</span> <span class="fl">0.75</span>,                        <span class="co"># learning rate</span></span>
<span id="cb2947-13"><a href="supervised-learning-regression.html#cb2947-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">max_depth =</span> <span class="dv">5</span>,</span>
<span id="cb2947-14"><a href="supervised-learning-regression.html#cb2947-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">verbose =</span> <span class="cn">FALSE</span>  <span class="co"># silent</span></span>
<span id="cb2947-15"><a href="supervised-learning-regression.html#cb2947-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2947-16"><a href="supervised-learning-regression.html#cb2947-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2947-17"><a href="supervised-learning-regression.html#cb2947-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on testing data</span></span>
<span id="cb2947-18"><a href="supervised-learning-regression.html#cb2947-18" aria-hidden="true" tabindex="-1"></a>bikesAugust<span class="sc">$</span>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(bike_model_xgb, <span class="fu">as.matrix</span>(bikesAugust.treat))</span>
<span id="cb2947-19"><a href="supervised-learning-regression.html#cb2947-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2947-20"><a href="supervised-learning-regression.html#cb2947-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot predictions (on x axis) vs actual bike rental count</span></span>
<span id="cb2947-21"><a href="supervised-learning-regression.html#cb2947-21" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(bikesAugust, <span class="fu">aes</span>(<span class="at">x =</span> pred, <span class="at">y =</span> cnt)) <span class="sc">+</span> </span>
<span id="cb2947-22"><a href="supervised-learning-regression.html#cb2947-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb2947-23"><a href="supervised-learning-regression.html#cb2947-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-1137-1.png" width="672" /></p>
<p>Overall, the scatterplot looked pretty good, but did you notice that the model made some negative predictions?</p>
</div>
<div id="evaluate-the-xgboost-model" class="section level4 hasAnchor" number="20.5.3.3">
<h4><span class="header-section-number">20.5.3.3</span> Evaluate the xgboost model<a href="supervised-learning-regression.html#evaluate-the-xgboost-model" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>You will evaluate the gradient boosting model <code>bike_model_xgb</code> that you fit in the last exercise, using data from the month of August.</p>
<p>You’ll compare this model’s RMSE for August to the RMSE of previous models that you’ve built.</p>
<div class="sourceCode" id="cb2948"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2948-1"><a href="supervised-learning-regression.html#cb2948-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(bikesAugust)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    744 obs. of  13 variables:
##  $ hr        : Factor w/ 24 levels &quot;0&quot;,&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,..: 1 2 3 4 5 6 7 8 9 10 ...
##  $ holiday   : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...
##  $ workingday: logi  TRUE TRUE TRUE TRUE TRUE TRUE ...
##  $ weathersit: chr  &quot;Clear to partly cloudy&quot; &quot;Clear to partly cloudy&quot; &quot;Clear to partly cloudy&quot; &quot;Clear to partly cloudy&quot; ...
##  $ temp      : num  0.68 0.66 0.64 0.64 0.64 0.64 0.64 0.64 0.66 0.68 ...
##  $ atemp     : num  0.636 0.606 0.576 0.576 0.591 ...
##  $ hum       : num  0.79 0.83 0.83 0.83 0.78 0.78 0.78 0.83 0.78 0.74 ...
##  $ windspeed : num  0.1642 0.0896 0.1045 0.1045 0.1343 ...
##  $ cnt       : int  47 33 13 7 4 49 185 487 681 350 ...
##  $ instant   : int  13748 13749 13750 13751 13752 13753 13754 13755 13756 13757 ...
##  $ mnth      : int  8 8 8 8 8 8 8 8 8 8 ...
##  $ yr        : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ pred      : num  52.38 40.3 6.55 12.72 -22.96 ...</code></pre>
<p>Compare to the RMSE from the:</p>
<p>poisson model (approx. 112.6) &amp; random forest model (approx. 96.7).</p>
<div class="sourceCode" id="cb2950"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2950-1"><a href="supervised-learning-regression.html#cb2950-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate RMSE</span></span>
<span id="cb2950-2"><a href="supervised-learning-regression.html#cb2950-2" aria-hidden="true" tabindex="-1"></a>bikesAugust <span class="sc">%&gt;%</span></span>
<span id="cb2950-3"><a href="supervised-learning-regression.html#cb2950-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">residuals =</span> cnt <span class="sc">-</span> pred) <span class="sc">%&gt;%</span></span>
<span id="cb2950-4"><a href="supervised-learning-regression.html#cb2950-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">rmse =</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(residuals<span class="sc">^</span><span class="dv">2</span>)))</span></code></pre></div>
<pre><code>##   rmse
## 1 84.4</code></pre>
<p>Even though this gradient boosting made some negative predictions, overall it makes smaller errors than the previous two models. Perhaps rounding negative predictions up to zero is a reasonable tradeoff.</p>
</div>
<div id="visualize-the-xgboost-model" class="section level4 hasAnchor" number="20.5.3.4">
<h4><span class="header-section-number">20.5.3.4</span> Visualize the xgboost model<a href="supervised-learning-regression.html#visualize-the-xgboost-model" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>You’ve now seen three different ways to model the bike rental data. Let’s compare the gradient boosting model’s predictions to the other two models as a function of time.</p>
<div class="sourceCode" id="cb2952"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2952-1"><a href="supervised-learning-regression.html#cb2952-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot predictions and actual bike rentals as a function of time (days)</span></span>
<span id="cb2952-2"><a href="supervised-learning-regression.html#cb2952-2" aria-hidden="true" tabindex="-1"></a>bikesAugust <span class="sc">%&gt;%</span> </span>
<span id="cb2952-3"><a href="supervised-learning-regression.html#cb2952-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># set start to 0, convert unit to days</span></span>
<span id="cb2952-4"><a href="supervised-learning-regression.html#cb2952-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">instant =</span> (instant <span class="sc">-</span> <span class="fu">min</span>(instant))<span class="sc">/</span><span class="dv">24</span>) <span class="sc">%&gt;%</span>  </span>
<span id="cb2952-5"><a href="supervised-learning-regression.html#cb2952-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather</span>(<span class="at">key =</span> valuetype, <span class="at">value =</span> value, cnt, pred) <span class="sc">%&gt;%</span></span>
<span id="cb2952-6"><a href="supervised-learning-regression.html#cb2952-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(instant <span class="sc">&lt;</span> <span class="dv">14</span>) <span class="sc">%&gt;%</span> <span class="co"># first two weeks</span></span>
<span id="cb2952-7"><a href="supervised-learning-regression.html#cb2952-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> instant, <span class="at">y =</span> value, </span>
<span id="cb2952-8"><a href="supervised-learning-regression.html#cb2952-8" aria-hidden="true" tabindex="-1"></a>             <span class="at">color =</span> valuetype, <span class="at">linetype =</span> valuetype)) <span class="sc">+</span> </span>
<span id="cb2952-9"><a href="supervised-learning-regression.html#cb2952-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb2952-10"><a href="supervised-learning-regression.html#cb2952-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span> </span>
<span id="cb2952-11"><a href="supervised-learning-regression.html#cb2952-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="st">&quot;Day&quot;</span>, <span class="at">breaks =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">14</span>, <span class="at">labels =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">14</span>) <span class="sc">+</span> </span>
<span id="cb2952-12"><a href="supervised-learning-regression.html#cb2952-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_brewer</span>(<span class="at">palette =</span> <span class="st">&quot;Dark2&quot;</span>) <span class="sc">+</span> </span>
<span id="cb2952-13"><a href="supervised-learning-regression.html#cb2952-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Predicted August bike rentals, Gradient Boosting model&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-1140-1.png" width="672" /></p>
<p>The gradient boosting pattern captures rental variations due to time of day and other factors better than the previous models.</p>
<div class="sourceCode" id="cb2953"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2953-1"><a href="supervised-learning-regression.html#cb2953-1" aria-hidden="true" tabindex="-1"></a>gridExtra<span class="sc">::</span><span class="fu">grid.arrange</span>(quasipoisson_plot, randomforest_plot, <span class="at">nrow =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-1141-1.png" width="672" /></p>

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="supervised-learning-classification.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="unsupervised-learning.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": true,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "github"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/20-Supervised-Learning-in-R-Regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
